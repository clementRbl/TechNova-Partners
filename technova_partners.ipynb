{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4086c666",
   "metadata": {},
   "source": [
    "# TechNova Partners - Analyse du Churn RH\n",
    "\n",
    "**Projet :** Identification des causes de démission et modélisation prédictive  \n",
    "**Client :** TechNova Partners (ESN spécialisée en transformation digitale)\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte du Projet\n",
    "\n",
    "TechNova Partners fait face à un turnover élevé. L'objectif est de :\n",
    "\n",
    "1. **Analyser** les données RH pour identifier les différences entre employés partis et restés\n",
    "2. **Construire** un modèle de classification pour prédire les démissions\n",
    "3. **Extraire** les causes potentielles via l'interprétation du modèle (SHAP)\n",
    "\n",
    "**Sources de données :**\n",
    "\n",
    "- `data/extrait_sirh.csv` - Informations RH (âge, salaire, poste, ancienneté...)\n",
    "- `data/extrait_eval.csv` - Évaluations de performance\n",
    "- `data/extrait_sondage.csv` - Sondage employés + **variable cible**\n",
    "\n",
    "---\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "**Partie 1 : Exploration des Données**\n",
    "\n",
    "- Chargement et compréhension des fichiers\n",
    "- Fusion et création du dataset central\n",
    "- Analyse exploratoire et visualisations\n",
    "\n",
    "**Partie 2 : Feature Engineering**\n",
    "\n",
    "- Préparation des features (X)\n",
    "- Encodage des variables catégorielles\n",
    "- Gestion des corrélations\n",
    "\n",
    "**Partie 3 : Modélisation Baseline**\n",
    "\n",
    "- Modèle Dummy (référence)\n",
    "- Modèle linéaire\n",
    "- Modèle non-linéaire (arbre)\n",
    "\n",
    "**Partie 4 : Gestion du Déséquilibre**\n",
    "\n",
    "- Stratification\n",
    "- Class weights / Undersampling / Oversampling (SMOTE)\n",
    "- Calibration de probabilité\n",
    "- Validation croisée stratifiée\n",
    "\n",
    "**Partie 5 : Optimisation et Interpretation**\n",
    "\n",
    "- Fine-tuning des hyperparamètres\n",
    "- Feature importance globale (SHAP, Permutation)\n",
    "- Feature importance locale (SHAP Waterfall)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a5ad0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Importation des librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dba98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b0aaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Chargement des données\n",
    "\n",
    "Chargement des 3 fichiers CSV et examen de structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a584d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh = pd.read_csv(\"data/extrait_sirh.csv\")\n",
    "df_eval = pd.read_csv(\"data/extrait_eval.csv\")\n",
    "df_sondage = pd.read_csv(\"data/extrait_sondage.csv\")\n",
    "\n",
    "print(f\"Fichier SIRH : {df_sirh.shape[0]} lignes, {df_sirh.shape[1]} colonnes\")\n",
    "print(f\"Fichier Évaluations : {df_eval.shape[0]} lignes, {df_eval.shape[1]} colonnes\")\n",
    "print(f\"Fichier Sondage : {df_sondage.shape[0]} lignes, {df_sondage.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859bfec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Exploration initiale de chaque fichier\n",
    "\n",
    "Avant de fusionner, comprenons le contenu et la structure de chaque fichier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cd45c",
   "metadata": {},
   "source": [
    "### 3.1 Fichier SIRH (extrait_sirh.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f0021",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n",
    "\n",
    "Visualisons les premières lignes pour comprendre la structure et le contenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1555732",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n",
    "\n",
    "Analysons les types de colonnes, la mémoire utilisée et les valeurs non-nulles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461b88d",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n",
    "\n",
    "Calculons les statistiques de base (moyenne, écart-type, min, max, quartiles) pour les variables numériques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ab8be",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n",
    "\n",
    "Examinons les valeurs uniques et leur fréquence pour chaque variable catégorielle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valeurs uniques des colonnes catégorielles SIRH :\")\n",
    "for col in df_sirh.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_sirh[col].nunique()} valeurs uniques\")\n",
    "    print(df_sirh[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79318fd",
   "metadata": {},
   "source": [
    "### 3.2 Fichier Évaluations (extrait_eval.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11411bc9",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a667e",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16286df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928a9b5",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistiques descriptives Evaluations (variables numeriques) :\")\n",
    "df_eval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca31359",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs uniques des colonnes catégorielles\n",
    "print(\"Valeurs uniques des colonnes catégorielles Evaluations :\")\n",
    "for col in df_eval.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_eval[col].nunique()} valeurs uniques\")\n",
    "    print(df_eval[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d33eff",
   "metadata": {},
   "source": [
    "### 3.3 Fichier Sondage (extrait_sondage.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e8e4d",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403c29a",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579a95a",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb217995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a13eaf",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sondage.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_sondage[col].nunique()} valeurs uniques\")\n",
    "    print(df_sondage[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8635855",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Identification des clés de jointure\n",
    "\n",
    "Pour fusionner les 3 fichiers, nous devons identifier les colonnes qui permettent de faire le lien entre eux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67bf0e",
   "metadata": {},
   "source": [
    "#### Analyse des colonnes identifiantes\n",
    "\n",
    "Examinons les colonnes qui nous permettront de faire les jointures entre fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonnes SIRH :\")\n",
    "print(df_sirh.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'id_employee' : {df_sirh['id_employee'].nunique()} valeurs uniques sur {len(df_sirh)} lignes\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nColonnes Évaluations :\")\n",
    "print(df_eval.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'eval_number' : {df_eval['eval_number'].nunique()} valeurs uniques sur {len(df_eval)} lignes\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nColonnes Sondage :\")\n",
    "print(df_sondage.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'code_sondage' : {df_sondage['code_sondage'].nunique()} valeurs uniques sur {len(df_sondage)} lignes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9872483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysons le format des clés pour comprendre comment les relier\n",
    "print(\"Exemples de clés :\")\n",
    "print(f\"\\nSIRH - id_employee (premiers) : {df_sirh['id_employee'].head(10).tolist()}\")\n",
    "print(f\"\\nEval - eval_number (premiers) : {df_eval['eval_number'].head(10).tolist()}\")\n",
    "print(\n",
    "    f\"\\nSondage - code_sondage (premiers) : {df_sondage['code_sondage'].head(10).tolist()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199f363",
   "metadata": {},
   "source": [
    "#### Analyse du format des clés\n",
    "\n",
    "Regardons de plus près comment sont structurées ces clés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparaison du nombre de lignes :\")\n",
    "print(f\"  - SIRH : {len(df_sirh)} lignes\")\n",
    "print(f\"  - Évaluations : {len(df_eval)} lignes\")\n",
    "print(f\"  - Sondage : {len(df_sondage)} lignes\")\n",
    "\n",
    "# Si tous les fichiers ont le même nombre de lignes,\n",
    "# ils correspondent probablement aux mêmes employés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828de03",
   "metadata": {},
   "source": [
    "#### Vérification de la cohérence des données\n",
    "\n",
    "Comparons le nombre de lignes pour détecter d'éventuels problèmes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recherche de colonnes communes entre les fichiers :\\n\")\n",
    "\n",
    "sirh_cols = set(df_sirh.columns)\n",
    "eval_cols = set(df_eval.columns)\n",
    "sondage_cols = set(df_sondage.columns)\n",
    "\n",
    "print(f\"SIRH ∩ Évaluations : {sirh_cols.intersection(eval_cols)}\")\n",
    "print(f\"SIRH ∩ Sondage : {sirh_cols.intersection(sondage_cols)}\")\n",
    "print(f\"Évaluations ∩ Sondage : {eval_cols.intersection(sondage_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if not sirh_cols.intersection(eval_cols) and not sirh_cols.intersection(sondage_cols):\n",
    "    print(\"Résultat : Aucune colonne commune détectée\")\n",
    "    print(\"Les 3 fichiers ont des colonnes strictement différentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2fdca",
   "metadata": {},
   "source": [
    "#### Comparaison visuelle des clés\n",
    "\n",
    "Analysons la structure des clés pour identifier leur correspondance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dcf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparaison visuelle des premières valeurs de chaque clé :\\n\")\n",
    "\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id_employee\": df_sirh[\"id_employee\"].head(10),\n",
    "        \"eval_number\": df_eval[\"eval_number\"].head(10),\n",
    "        \"code_sondage\": df_sondage[\"code_sondage\"].head(10),\n",
    "    }\n",
    ")\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Observation : Les 3 clés suivent un pattern cohérent\")\n",
    "print(\"  - id_employee : valeurs numériques (1, 2, 3...)\")\n",
    "print(\"  - eval_number : format 'E_X' où X correspond à id_employee\")\n",
    "print(\"  - code_sondage : même valeur que id_employee\")\n",
    "print(\"\\nConclusion : Les lignes sont alignées par leur position (index)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9a3e0",
   "metadata": {},
   "source": [
    "#### Conclusion : Stratégie de fusion\n",
    "\n",
    "**Constat :**\n",
    "\n",
    "- Aucune colonne commune entre les 3 fichiers\n",
    "- Même nombre de lignes (1470) dans chaque fichier\n",
    "- Les clés suivent un pattern cohérent suggérant un alignement par index\n",
    "- Chaque fichier contient des informations complémentaires :\n",
    "  - SIRH → infos administratives (ancienneté, salaire, département...)\n",
    "  - Évaluations → métriques de performance (notes, satisfaction...)\n",
    "  - Sondage → perception des employés (stress, équilibre vie pro/perso...)\n",
    "\n",
    "**Stratégie retenue :**\n",
    "\n",
    "Concaténation horizontale par index avec `pd.concat([df_sirh, df_eval, df_sondage], axis=1)`\n",
    "\n",
    "**Justification :**\n",
    "\n",
    "- Les lignes sont déjà alignées (id_employee=1 ↔ eval_number=\"E_1\" ↔ code_sondage=1)\n",
    "- Pas besoin de jointure SQL complexe\n",
    "- Les colonnes identifiantes seront conservées pour traçabilité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a01f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Fusion des données\n",
    "\n",
    "Création du DataFrame central en fusionnant les 3 sources par concaténation horizontale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6ff60",
   "metadata": {},
   "source": [
    "#### Création du DataFrame central\n",
    "\n",
    "Fusion des 3 fichiers par concaténation horizontale (axis=1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_sirh, df_eval, df_sondage], axis=1)\n",
    "\n",
    "print(\"DataFrame fusionné créé :\")\n",
    "print(f\"  - {df_merged.shape[0]} lignes\")\n",
    "print(f\"  - {df_merged.shape[1]} colonnes\")\n",
    "print(f\"\\nColonnes : {df_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834aa13",
   "metadata": {},
   "source": [
    "#### Gestion des colonnes dupliquées\n",
    "\n",
    "Vérification et suppression des éventuelles colonnes en double.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des colonnes dupliquées\n",
    "duplicated_cols = df_merged.columns[df_merged.columns.duplicated()].tolist()\n",
    "\n",
    "if duplicated_cols:\n",
    "    print(f\"{len(duplicated_cols)} colonne(s) dupliquée(s) détectée(s) :\")\n",
    "    for col in duplicated_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Suppression des doublons (on garde la première occurrence)\n",
    "    df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\n",
    "    print(\"\\nColonnes dupliquées supprimées\")\n",
    "    print(f\"Nouvelles dimensions : {df_merged.shape}\")\n",
    "else:\n",
    "    print(\"Aucune colonne dupliquée détectée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5fca7",
   "metadata": {},
   "source": [
    "#### Aperçu du DataFrame central\n",
    "\n",
    "Visualisation des premières lignes du dataset fusionné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05128d7c",
   "metadata": {},
   "source": [
    "#### Structure du DataFrame fusionné\n",
    "\n",
    "Informations sur les types de données et la mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a48f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a229f",
   "metadata": {},
   "source": [
    "#### Analyse de la variable cible\n",
    "\n",
    "Distribution de `a_quitte_l_entreprise` - la variable à prédire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9daf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variable cible - 'a_quitte_l_entreprise' :\")\n",
    "print(f\"Type : {df_merged['a_quitte_l_entreprise'].dtype}\")\n",
    "print(\"\\nDistribution :\")\n",
    "print(df_merged[\"a_quitte_l_entreprise\"].value_counts())\n",
    "print(\"\\nProportions (%) :\")\n",
    "print((df_merged[\"a_quitte_l_entreprise\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Comptage\n",
    "df_merged[\"a_quitte_l_entreprise\"].value_counts().plot(\n",
    "    kind=\"bar\", ax=ax[0], color=[\"#2ecc71\", \"#e74c3c\"]\n",
    ")\n",
    "ax[0].set_title(\"Distribution de la variable cible\", fontsize=12, fontweight=\"bold\")\n",
    "ax[0].set_xlabel(\"A quitté l'entreprise\")\n",
    "ax[0].set_ylabel(\"Nombre d'employés\")\n",
    "ax[0].set_xticklabels([\"Non\", \"Oui\"], rotation=0)\n",
    "\n",
    "# Proportions\n",
    "df_merged[\"a_quitte_l_entreprise\"].value_counts().plot(\n",
    "    kind=\"pie\",\n",
    "    ax=ax[1],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[\"#2ecc71\", \"#e74c3c\"],\n",
    "    labels=[\"Restés\", \"Partis\"],\n",
    ")\n",
    "ax[1].set_title(\"Proportions\", fontsize=12, fontweight=\"bold\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"OBSERVATION CRITIQUE : Déséquilibre des classes !\")\n",
    "print(\"     → À gérer en modélisation (stratification, class_weights, SMOTE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab20774",
   "metadata": {},
   "source": [
    "#### Synthèse : Variable cible\n",
    "\n",
    "- **84% restés** vs **16% partis** → Ratio 5:1\n",
    "- Déséquilibre à gérer : stratification, class_weight, resampling, calibration\n",
    "- Accuracy insuffisante comme métrique (84% sans rien faire)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb775a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Vue d'ensemble du dataset central\n",
    "\n",
    "Avant de comparer les employés partis vs restés, vérifions la qualité et la structure des données :\n",
    "\n",
    "- Valeurs manquantes\n",
    "- Types de colonnes (numériques vs catégorielles)\n",
    "- Colonnes identifiantes à exclure de l'analyse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ef20",
   "metadata": {},
   "source": [
    "#### Analyse des valeurs manquantes\n",
    "\n",
    "Vérifions s'il y a des données manquantes dans le dataset fusionné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "print(\"Analyse des valeurs manquantes :\\n\")\n",
    "\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_pct = (df_merged.isnull().sum() / len(df_merged) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame(\n",
    "    {\"Valeurs manquantes\": missing_values, \"Pourcentage (%)\": missing_pct}\n",
    ")\n",
    "\n",
    "# Afficher seulement les colonnes avec des valeurs manquantes\n",
    "missing_with_values = missing_df[missing_df[\"Valeurs manquantes\"] > 0]\n",
    "\n",
    "if len(missing_with_values) > 0:\n",
    "    print(f\"{len(missing_with_values)} colonne(s) avec des valeurs manquantes :\")\n",
    "    print(missing_with_values.sort_values(\"Pourcentage (%)\", ascending=False))\n",
    "else:\n",
    "    print(\"Aucune valeur manquante dans le dataset !\")\n",
    "    print(f\"   → {df_merged.shape[0]} lignes × {df_merged.shape[1]} colonnes complètes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018e0d7",
   "metadata": {},
   "source": [
    "#### Classification des colonnes par type\n",
    "\n",
    "Identifions les colonnes numériques et catégorielles pour orienter l'analyse exploratoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f358b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification des colonnes par type :\\n\")\n",
    "\n",
    "# Colonnes identifiantes (à exclure de l'analyse)\n",
    "id_cols = [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "\n",
    "# Variable cible\n",
    "target_col = \"a_quitte_l_entreprise\"\n",
    "\n",
    "# Colonnes numériques (excluant les IDs)\n",
    "numeric_cols = df_merged.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in id_cols + [target_col]]\n",
    "\n",
    "# Colonnes catégorielles\n",
    "categorical_cols = df_merged.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols = [\n",
    "    col for col in categorical_cols if col not in id_cols + [target_col]\n",
    "]\n",
    "\n",
    "print(f\"Colonnes identifiantes ({len(id_cols)}) - À EXCLURE :\")\n",
    "print(f\"   {id_cols}\\n\")\n",
    "\n",
    "print(\"Variable cible :\")\n",
    "print(f\"   {target_col}\\n\")\n",
    "\n",
    "print(f\"Colonnes numériques ({len(numeric_cols)}) :\")\n",
    "print(f\"   {numeric_cols}\\n\")\n",
    "\n",
    "print(f\"Colonnes catégorielles ({len(categorical_cols)}) :\")\n",
    "print(f\"   {categorical_cols}\")\n",
    "\n",
    "print(f\"Total features analysables : {len(numeric_cols) + len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3001d5e",
   "metadata": {},
   "source": [
    "#### Résumé structuré du dataset\n",
    "\n",
    "Tableau récapitulatif avec le type, les valeurs uniques et des exemples pour chaque colonne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f860ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for col in df_merged.columns:\n",
    "    if col in id_cols:\n",
    "        category = \"Identifiant\"\n",
    "    elif col == target_col:\n",
    "        category = \"Cible\"\n",
    "    elif col in numeric_cols:\n",
    "        category = \"Numérique\"\n",
    "    else:\n",
    "        category = \"Catégorielle\"\n",
    "\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Colonne\": col,\n",
    "            \"Catégorie\": category,\n",
    "            \"Type\": str(df_merged[col].dtype),\n",
    "            \"Valeurs uniques\": df_merged[col].nunique(),\n",
    "            \"Exemple\": str(df_merged[col].iloc[0])[:30],\n",
    "        }\n",
    "    )\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6fd0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analyse exploratoire comparative : Partis vs Restés\n",
    "\n",
    "Objectif principal de cette section : **identifier les différences clés** entre les employés ayant quitté l'entreprise et ceux qui y sont restés.\n",
    "\n",
    "Nous utiliserons **Plotly** pour des graphiques interactifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343e5e7",
   "metadata": {},
   "source": [
    "#### Import de Plotly et préparation des données\n",
    "\n",
    "Configuration de Plotly et création d'une colonne lisible pour la variable cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c74251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"statut\"] = df_merged[\"a_quitte_l_entreprise\"].map(\n",
    "    {\"Oui\": \"Parti\", \"Non\": \"Resté\"}\n",
    ")\n",
    "\n",
    "colors = {\"Resté\": \"#2ecc71\", \"Parti\": \"#e74c3c\"}\n",
    "\n",
    "print(f\"   Distribution : {df_merged['statut'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356fc251",
   "metadata": {},
   "source": [
    "### 7.1 Analyse des variables numériques\n",
    "\n",
    "Comparons les **moyennes** des variables numériques entre les employés partis et restés avec un graphique unique et lisible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90941077",
   "metadata": {},
   "source": [
    "#### Observations : Variables numériques\n",
    "\n",
    "**Principales différences observées :**\n",
    "\n",
    "| Variable                      | Différence | Observation                          |\n",
    "| ----------------------------- | ---------- | ------------------------------------ |\n",
    "| `nombre_participation_pee`    | -37.6%     | Participation PEE plus faible        |\n",
    "| `annees_dans_le_poste_actuel` | -35.3%     | Ancienneté dans le poste plus faible |\n",
    "| `revenu_mensuel`              | -29.9%     | Salaire plus bas                     |\n",
    "| `distance_domicile_travail`   | +19.3%     | Distance plus grande                 |\n",
    "\n",
    "**Note :** Ce sont des observations descriptives. Le modèle confirmera l'importance réelle de chaque variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78f13e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 1 : Analyse Exploratoire\n",
    "\n",
    "### Données fusionnées\n",
    "\n",
    "| Métrique           | Valeur                       |\n",
    "| ------------------ | ---------------------------- |\n",
    "| Employés           | 1470                         |\n",
    "| Variables          | 34 colonnes                  |\n",
    "| Sources            | SIRH + Évaluations + Sondage |\n",
    "| Valeurs manquantes | 0                            |\n",
    "\n",
    "### Variable cible : Déséquilibre critique\n",
    "\n",
    "| Classe | Effectif | Proportion |\n",
    "| ------ | -------- | ---------- |\n",
    "| Restés | 1233     | **84%**    |\n",
    "| Partis | 237      | **16%**    |\n",
    "\n",
    "→ **Ratio 5:1** : nécessite stratification + gestion du déséquilibre (class_weight, SMOTE)\n",
    "\n",
    "### Profil type de l'employé qui part\n",
    "\n",
    "**Variables numériques discriminantes :**\n",
    "\n",
    "| Variable                      | Écart vs Restés | Interprétation RH            |\n",
    "| ----------------------------- | --------------- | ---------------------------- |\n",
    "| `nombre_participation_pee`    | **-37.6%**      | Moins engagés financièrement |\n",
    "| `annees_dans_le_poste_actuel` | **-35.3%**      | Moins d'ancienneté poste     |\n",
    "| `revenu_mensuel`              | **-29.9%**      | Salaire plus bas             |\n",
    "| `distance_domicile_travail`   | **+19.3%**      | Trajet plus long             |\n",
    "\n",
    "**Variables catégorielles à risque :**\n",
    "\n",
    "| Variable                | Modalité à risque       | Taux de churn |\n",
    "| ----------------------- | ----------------------- | ------------- |\n",
    "| `poste`                 | Représentant Commercial | **39.8%**     |\n",
    "| `heure_supplementaires` | Oui                     | **30.5%**     |\n",
    "| `statut_marital`        | Célibataire             | **25.5%**     |\n",
    "| `frequence_deplacement` | Fréquent                | Taux élevé    |\n",
    "\n",
    "**Profils stables (faible churn) :**\n",
    "\n",
    "- Directeur Technique (2.5%), Manager (6.9%)\n",
    "- Pas d'heures sup (10.4%)\n",
    "- Mariés, ancienneté élevée\n",
    "\n",
    "### Insights métier pour les RH\n",
    "\n",
    "1. **Rémunération** : Les employés qui partent gagnent ~30% de moins → Revoir la politique salariale\n",
    "2. **Heures sup** : 30% de churn chez ceux qui en font → Surveiller la charge de travail\n",
    "3. **Mobilité** : Distance domicile-travail corrélée au départ → Télétravail comme levier\n",
    "4. **Engagement** : Faible participation PEE = signal d'alerte → Renforcer l'intéressement\n",
    "5. **Postes à risque** : Commerciaux = 40% de turnover → Actions ciblées\n",
    "\n",
    "### Variables retenues pour la modélisation\n",
    "\n",
    "**Numériques potentiellement prédictives :**\n",
    "\n",
    "- `revenu_mensuel`, `annees_dans_le_poste_actuel`, `nombre_participation_pee`\n",
    "- `distance_domicile_travail`, `satisfaction_*` (4 variables)\n",
    "\n",
    "**Catégorielles potentiellement prédictives :**\n",
    "\n",
    "- `heure_supplementaires`, `poste`, `statut_marital`, `frequence_deplacement`\n",
    "\n",
    "**⚠️ Attention** : Ces observations sont **descriptives**. Le modèle (puis SHAP) confirmera l'importance réelle de chaque variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf5ceb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Partie 2 : Feature Engineering\n",
    "\n",
    "Dans cette partie, nous allons :\n",
    "\n",
    "1. **Nettoyer les donnees** : doublons, outliers, colonnes inutiles\n",
    "2. **Analyser les correlations** : matrice de Pearson, suppression des variables trop correlees\n",
    "3. **Encoder les variables categorielles** : OneHotEncoder pour les modeles\n",
    "4. **Creer X et y** : preparation finale pour la modelisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e376d06",
   "metadata": {},
   "source": [
    "## 8. Nettoyage des donnees\n",
    "\n",
    "### 8.1 Verification des doublons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  Nombre de lignes dupliquees : {df_merged.duplicated().sum()}\")\n",
    "print(f\"\\nDoublons sur 'id_employee' : {df_merged['id_employee'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57167662",
   "metadata": {},
   "source": [
    "### 8.2 Detection des outliers (methode IQR)\n",
    "\n",
    "**Qu'est-ce que la methode IQR (Interquartile Range) ?**\n",
    "\n",
    "L'IQR est une methode statistique robuste pour detecter les valeurs aberrantes :\n",
    "\n",
    "**Calcul des bornes :**\n",
    "\n",
    "- Borne inferieure = Q1 - 1.5 x IQR\n",
    "- Borne superieure = Q3 + 1.5 x IQR\n",
    "\n",
    "Toute valeur en dehors de ces bornes est consideree comme un **outlier**.\n",
    "\n",
    "**Pourquoi IQR plutot que Z-score ?**\n",
    "\n",
    "- IQR est base sur les **quartiles** (pas la moyenne)\n",
    "- Donc **insensible aux valeurs extremes** elles-memes\n",
    "- Plus adapte aux distributions non-normales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection des outliers avec la methode IQR (Interquartile Range)\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    \"\"\"Detecte les outliers pour chaque colonne numerique avec la methode IQR.\"\"\"\n",
    "    outliers_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        n_outliers = len(outliers)\n",
    "        pct_outliers = (n_outliers / len(df)) * 100\n",
    "\n",
    "        if n_outliers > 0:\n",
    "            outliers_summary.append(\n",
    "                {\n",
    "                    \"Variable\": col,\n",
    "                    \"Nb outliers\": n_outliers,\n",
    "                    \"% outliers\": round(pct_outliers, 1),\n",
    "                    \"Borne inf\": round(lower_bound, 2),\n",
    "                    \"Borne sup\": round(upper_bound, 2),\n",
    "                    \"Min reel\": round(df[col].min(), 2),\n",
    "                    \"Max reel\": round(df[col].max(), 2),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(outliers_summary)\n",
    "\n",
    "\n",
    "# Exclure les colonnes ID et la cible pour l'analyse des outliers\n",
    "cols_to_check = [\n",
    "    col\n",
    "    for col in numeric_cols\n",
    "    if col not in [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "]\n",
    "outliers_df = detect_outliers_iqr(df_merged, cols_to_check)\n",
    "\n",
    "print(f\"Variables avec outliers : {len(outliers_df)} / {len(cols_to_check)}\")\n",
    "print()\n",
    "if len(outliers_df) > 0:\n",
    "    display(outliers_df.sort_values(\"% outliers\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe8f28",
   "metadata": {},
   "source": [
    "**Decision sur les outliers :**\n",
    "\n",
    "Les outliers detectes sont des valeurs coherentes dans un contexte RH :\n",
    "\n",
    "- **Revenus eleves** : salaires de cadres superieurs (jusqu'a 19 999 EUR)\n",
    "- **Anciennete elevee** : employes fideles (jusqu'a 40 ans)\n",
    "- **Formations** : 6 formations maximum, valeur plausible\n",
    "\n",
    "Ces valeurs ne sont pas des erreurs de saisie mais des cas legitimes. Nous les **conservons** car :\n",
    "\n",
    "1. Les modeles tree-based (Random Forest, XGBoost) gerent bien les outliers\n",
    "2. Ces profils extremes peuvent etre pertinents pour predire le churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef98ecb",
   "metadata": {},
   "source": [
    "### 8.3 Identification des colonnes a supprimer\n",
    "\n",
    "**Pourquoi supprimer certaines colonnes ?**\n",
    "\n",
    "1. **Colonnes ID** (id_employee, eval_number, code_sondage)\n",
    "   - Ce sont des identifiants uniques (1, 2, 3...)\n",
    "   - Aucune valeur predictive : le modele ne peut pas apprendre que \"employe 42\" part plus souvent\n",
    "\n",
    "2. **Colonnes a variance nulle**\n",
    "   - Une colonne avec la **meme valeur pour tous** (ex: `nombre_heures_travailless = 80` pour tout le monde)\n",
    "   - Aucune information discriminante : impossible de differencier partis vs restes\n",
    "\n",
    "3. **Colonnes redondantes**\n",
    "   - `a_quitte_l_entreprise` et `statut` contiennent la meme information que notre cible\n",
    "   - Les garder = **data leakage** (le modele \"triche\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonnes actuelles du dataset :\")\n",
    "print(df_merged.columns.tolist())\n",
    "\n",
    "id_columns = [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "\n",
    "target_column = \"depart\"\n",
    "\n",
    "# Colonnes a variance nulle ou quasi-nulle\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nVerification des colonnes a faible variance :\")\n",
    "for col in df_merged.columns:\n",
    "    unique_ratio = df_merged[col].nunique() / len(df_merged)\n",
    "    if df_merged[col].nunique() <= 2 and col != target_column:\n",
    "        print(\n",
    "            f\"  {col} : {df_merged[col].nunique()} valeurs uniques -> {df_merged[col].value_counts().to_dict()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f78867",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = {\n",
    "    # Colonnes ID (pas de valeur predictive)\n",
    "    \"id_employee\": \"Identifiant unique - pas de valeur predictive\",\n",
    "    \"eval_number\": \"Identifiant evaluation - pas de valeur predictive\",\n",
    "    \"code_sondage\": \"Identifiant sondage - pas de valeur predictive\",\n",
    "    # Colonnes a variance nulle (meme valeur pour tous)\n",
    "    \"nombre_heures_travailless\": \"Variance nulle - toujours 80\",\n",
    "    \"nombre_employee_sous_responsabilite\": \"Variance nulle - toujours 1\",\n",
    "    \"ayant_enfants\": \"Variance nulle - toujours Y\",\n",
    "    # Colonne redondante avec la cible\n",
    "    \"a_quitte_l_entreprise\": 'Redondante avec \"statut\" (variable cible)',\n",
    "    \"statut\": 'Redondante - nous utiliserons \"depart\" comme cible binaire',\n",
    "}\n",
    "\n",
    "print(\"Colonnes a supprimer :\")\n",
    "for col, reason in columns_to_drop.items():\n",
    "    print(f\"  - {col}: {reason}\")\n",
    "\n",
    "print(f\"\\nTotal : {len(columns_to_drop)} colonnes a supprimer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du DataFrame nettoye\n",
    "df_clean = df_merged.copy()\n",
    "\n",
    "# Creation de la variable cible binaire 'depart' (0 = Reste, 1 = Churn)\n",
    "df_clean[\"depart\"] = (df_clean[\"statut\"] == \"Parti\").astype(int)\n",
    "\n",
    "# Suppression des colonnes identifiees\n",
    "df_clean = df_clean.drop(columns=list(columns_to_drop.keys()))\n",
    "\n",
    "print(f\"Dataset initial : {df_merged.shape[0]} lignes x {df_merged.shape[1]} colonnes\")\n",
    "print(f\"Dataset nettoye : {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\")\n",
    "print(f\"\\nColonnes restantes ({df_clean.shape[1]}) :\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6926f",
   "metadata": {},
   "source": [
    "## 9. Analyse des correlations\n",
    "\n",
    "**Pourquoi analyser les correlations ?**\n",
    "\n",
    "1. **Identifier les relations lineaires** entre variables\n",
    "2. **Detecter la multicolinearite** : si 2 variables sont tres correlees (|r| > 0.7), elles apportent la meme information → on peut en supprimer une\n",
    "3. **Comprendre les liens avec la cible** : quelles variables sont les plus correlees avec le depart ?\n",
    "\n",
    "### 9.1 Matrice de correlation de Pearson\n",
    "\n",
    "**Pearson** mesure les correlations **lineaires** :\n",
    "\n",
    "- r = +1 : correlation positive parfaite\n",
    "- r = 0 : pas de correlation lineaire\n",
    "- r = -1 : correlation negative parfaite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de correlation Pearson\n",
    "numeric_cols_clean = df_clean.select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ").columns.tolist()\n",
    "print(f\"Variables numériques pour la corrélation : {len(numeric_cols_clean)}\")\n",
    "\n",
    "corr_matrix = df_clean[numeric_cols_clean].corr()\n",
    "\n",
    "# Visualisation avec matplotlib/seaborn\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    "    annot_kws={\"size\": 7},\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Matrice de Corrélation de Pearson\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Corrélations avec la cible\n",
    "print(\"\\nCORRÉLATIONS AVEC LA CIBLE 'depart' :\")\n",
    "print(\"-\" * 50)\n",
    "target_corr = corr_matrix[\"depart\"].drop(\"depart\").sort_values(key=abs, ascending=False)\n",
    "for var, corr_value in target_corr.items():\n",
    "    print(f\"   {var:40} : {corr_value:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c11216",
   "metadata": {},
   "source": [
    "### 9.2 Identification des correlations fortes (|r| > 0.7)\n",
    "\n",
    "**Pourquoi c'est un probleme ?**\n",
    "\n",
    "Si deux variables sont **tres correlees** (ex: `revenu_mensuel` et `niveau_hierarchique_poste` a 0.95), elles apportent **la meme information** au modele.\n",
    "\n",
    "**Consequences de la multicolinearite :**\n",
    "\n",
    "- Modeles **lineaires instables** (coefficients aberrants)\n",
    "- **Redondance** d'information\n",
    "- Difficulte d'interpretation\n",
    "\n",
    "**Solution :** Supprimer une des deux variables. On garde celle qui est :\n",
    "\n",
    "- La plus **correlee avec la cible**, ou\n",
    "- La plus **interpretable metier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e32385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des paires de variables fortement correlees (|r| > 0.7)\n",
    "threshold = 0.7\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Parcourir le triangle inferieur de la matrice (sans la diagonale)\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            high_corr_pairs.append(\n",
    "                {\n",
    "                    \"Variable 1\": corr_matrix.columns[j],\n",
    "                    \"Variable 2\": corr_matrix.columns[i],\n",
    "                    \"Correlation\": round(corr_matrix.iloc[i, j], 3),\n",
    "                }\n",
    "            )\n",
    "\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs).sort_values(\"Correlation\", ascending=False)\n",
    "print(f\"Paires de variables avec correlation |r| > {threshold} :\")\n",
    "print()\n",
    "display(high_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision : quelles variables supprimer pour eviter la multicolinearite ?\n",
    "# Critere : garder la variable la plus interpretable ou la plus correlee avec la cible\n",
    "\n",
    "# Correlation de chaque variable avec la cible 'depart'\n",
    "print(\"Correlation avec la cible 'depart' :\")\n",
    "target_corr = corr_matrix[\"depart\"].drop(\"depart\").abs().sort_values(ascending=False)\n",
    "print(target_corr.head(10))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nAnalyse des paires correlees :\")\n",
    "for _, row in high_corr_df.iterrows():\n",
    "    var1, var2 = row[\"Variable 1\"], row[\"Variable 2\"]\n",
    "    corr1 = abs(corr_matrix.loc[\"depart\", var1])\n",
    "    corr2 = abs(corr_matrix.loc[\"depart\", var2])\n",
    "    print(\n",
    "        f\"\\n{var1} (|r| avec depart = {corr1:.3f}) vs {var2} (|r| avec depart = {corr2:.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables redondantes\n",
    "# Logique : garder les variables les plus correlees avec la cible\n",
    "\n",
    "cols_to_remove_corr = [\n",
    "    \"niveau_hierarchique_poste\",  # Tres correle avec revenu_mensuel (0.95), moins interpretable\n",
    "    \"annees_dans_l_entreprise\",  # Correle avec annees_dans_le_poste_actuel et annes_sous_responsable\n",
    "]\n",
    "\n",
    "print(\"Variables supprimees pour multicolinearite :\")\n",
    "for col in cols_to_remove_corr:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Application de la suppression\n",
    "df_clean = df_clean.drop(columns=cols_to_remove_corr)\n",
    "print(\n",
    "    f\"\\nDataset apres suppression : {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976f594",
   "metadata": {},
   "source": [
    "### 9.3 Justification du choix des variables supprimées\n",
    "\n",
    "**Pourquoi supprimer `niveau_hierarchique_poste` et `annees_dans_l_entreprise` ?**\n",
    "\n",
    "Ces deux variables semblent intuitivement importantes pour prédire le départ. Cependant, leur suppression est justifiée par le **problème de multicolinéarité** :\n",
    "\n",
    "**Corrélations détectées (|r| > 0.7) :**\n",
    "\n",
    "| Variable 1                 | Variable 2                      | Corrélation |\n",
    "| -------------------------- | ------------------------------- | ----------- |\n",
    "| `revenu_mensuel`           | `niveau_hierarchique_poste`     | **0.95**    |\n",
    "| `annee_experience_totale`  | `niveau_hierarchique_poste`     | 0.78        |\n",
    "| `annees_dans_l_entreprise` | `annees_dans_le_poste_actuel`   | 0.76        |\n",
    "| `annees_dans_l_entreprise` | `annes_sous_responsable_actuel` | 0.77        |\n",
    "\n",
    "**Le problème** : Quand deux variables sont corrélées à 95%, elles apportent **presque la même information**. Le modèle ne sait pas laquelle utiliser → coefficients instables et interprétation SHAP biaisée.\n",
    "\n",
    "**Corrélations avec la cible `depart` :**\n",
    "\n",
    "| Variable                        | Corrélation avec depart    |\n",
    "| ------------------------------- | -------------------------- |\n",
    "| `niveau_hierarchique_poste`     | 0.169                      |\n",
    "| `annees_dans_le_poste_actuel`   | 0.161                      |\n",
    "| `revenu_mensuel`                | 0.160                      |\n",
    "| `annes_sous_responsable_actuel` | 0.156                      |\n",
    "| `annees_dans_l_entreprise`      | **0.134** (la plus faible) |\n",
    "\n",
    "**Critères de sélection (logique métier RH) :**\n",
    "\n",
    "1. **`revenu_mensuel` gardé vs `niveau_hierarchique_poste` supprimé** :\n",
    "   - Le salaire est **plus concret et actionnable** pour les RH qu'un \"niveau 3 vs niveau 4\"\n",
    "   - Corrélations quasi égales avec la cible (0.160 vs 0.169)\n",
    "   - Avec r=0.95, l'information de `niveau_hierarchique_poste` est **déjà contenue** dans `revenu_mensuel`\n",
    "\n",
    "2. **`annees_dans_le_poste_actuel` gardé vs `annees_dans_l_entreprise` supprimé** :\n",
    "   - `annees_dans_le_poste_actuel` a une corrélation **plus forte** avec le départ (0.161 vs 0.134)\n",
    "   - Plus pertinent métier : c'est la **stagnation dans le poste** qui pousse au départ, pas l'ancienneté globale\n",
    "\n",
    "**Conclusion** : On ne perd pas d'information prédictive, car les variables conservées (`revenu_mensuel`, `annees_dans_le_poste_actuel`) captent l'essentiel de l'information des variables supprimées, tout en étant plus interprétables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e769835",
   "metadata": {},
   "source": [
    "### 9.4 Conversion de `augementation_salaire_precedente` en numérique\n",
    "\n",
    "**Problème identifié :** La colonne `augementation_salaire_precedente` contient des valeurs comme \"11 %\", \"23 %\" qui sont stockées comme **texte (object)**.\n",
    "\n",
    "**Pourquoi convertir en numérique ?**\n",
    "\n",
    "| Approche                      | Nb features          | Compréhension modèle             | Risque overfitting |\n",
    "| ----------------------------- | -------------------- | -------------------------------- | ------------------ |\n",
    "| **Catégorielle (défaut)**     | 14 colonnes (OneHot) | ❌ Perd l'ordre et les distances | ⚠️ Plus élevé      |\n",
    "| **Numérique (best practice)** | 1 colonne            | ✅ 11% < 12% < 23%               | ✅ Réduit          |\n",
    "\n",
    "**Avantages de la conversion :**\n",
    "\n",
    "- Le modèle comprend que **23% > 11%** (relation ordinale préservée)\n",
    "- Le modèle comprend que **23% - 11% = 12 points** (distances préservées)\n",
    "- **1 feature** au lieu de **14** → moins de dimensions → moins d'overfitting\n",
    "- Coefficient plus **interprétable** : \"+1% d'augmentation = X% de risque de départ\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de \"11 %\" -> 11.0 (valeur numerique)\n",
    "# On garde la valeur en pourcentage (11, 12, 23...) plutot qu'en decimal (0.11, 0.12...)\n",
    "\n",
    "print(\"Avant conversion :\")\n",
    "print(f\"  Type: {df_clean['augementation_salaire_precedente'].dtype}\")\n",
    "print(\n",
    "    f\"  Valeurs uniques: {df_clean['augementation_salaire_precedente'].unique()[:5]}...\"\n",
    ")\n",
    "\n",
    "# Suppression du \" %\" et conversion en float\n",
    "df_clean[\"augementation_salaire_precedente\"] = (\n",
    "    df_clean[\"augementation_salaire_precedente\"]\n",
    "    .str.replace(\" %\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(\"\\nApres conversion :\")\n",
    "print(f\"  Type: {df_clean['augementation_salaire_precedente'].dtype}\")\n",
    "print(\n",
    "    f\"  Valeurs uniques: {sorted(df_clean['augementation_salaire_precedente'].unique())}\"\n",
    ")\n",
    "print(f\"  Min: {df_clean['augementation_salaire_precedente'].min()}%\")\n",
    "print(f\"  Max: {df_clean['augementation_salaire_precedente'].max()}%\")\n",
    "print(f\"  Moyenne: {df_clean['augementation_salaire_precedente'].mean():.1f}%\")\n",
    "\n",
    "print(\"\\n✅ La colonne sera maintenant traitee comme NUMERIQUE dans le Pipeline\")\n",
    "print(\"   → StandardScaler au lieu de OneHotEncoder\")\n",
    "print(\"   → 1 feature au lieu de 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e791b",
   "metadata": {},
   "source": [
    "## 10. Feature Engineering - Creation de nouvelles variables\n",
    "\n",
    "**Pourquoi creer de nouvelles features ?**\n",
    "\n",
    "\"features supplementaires par rapport aux donnees d'origine\"\n",
    "\n",
    "**Objectif :** Creer des variables qui capturent des **informations metier** que les colonnes brutes ne montrent pas directement.\n",
    "\n",
    "**Features creees (3) :**\n",
    "\n",
    "| Feature                    | Formule                                        | Interpretation metier                            |\n",
    "| -------------------------- | ---------------------------------------------- | ------------------------------------------------ |\n",
    "| `ratio_salaire_experience` | revenu_mensuel / (experience + 1)              | Employe sous-paye par rapport a son experience ? |\n",
    "| `stagnation_poste`         | annees_dans_le_poste - annees_depuis_promotion | Employe bloque sans evolution ?                  |\n",
    "| `satisfaction_globale`     | moyenne des 4 satisfactions employee           | Score synthetique de bien-etre                   |\n",
    "\n",
    "**Pourquoi seulement 3 ?**\n",
    "\n",
    "- Eviter l'**overfitting** (trop de features pour peu de donnees)\n",
    "- Chaque feature doit avoir un **sens metier RH**\n",
    "- Le dataset est deja riche (50+ colonnes apres encodage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1 : Ratio salaire / experience\n",
    "# Interpretation : Un ratio bas = potentiellement sous-paye\n",
    "# Note: +1 pour eviter division par zero si experience = 0\n",
    "df_clean[\"ratio_salaire_experience\"] = df_clean[\"revenu_mensuel\"] / (\n",
    "    df_clean[\"annee_experience_totale\"] + 1\n",
    ")\n",
    "\n",
    "# Feature 2 : Stagnation de carriere\n",
    "# Interpretation : Valeur elevee = beaucoup d'annees dans le poste sans promotion recente\n",
    "df_clean[\"stagnation_poste\"] = (\n",
    "    df_clean[\"annees_dans_le_poste_actuel\"]\n",
    "    - df_clean[\"annees_depuis_la_derniere_promotion\"]\n",
    ")\n",
    "\n",
    "# Feature 3 : Satisfaction globale (moyenne des 4 satisfactions)\n",
    "# Interpretation : Score synthetique qui resume le bien-etre au travail\n",
    "cols_satisfaction = [\n",
    "    \"satisfaction_employee_environnement\",\n",
    "    \"satisfaction_employee_nature_travail\",\n",
    "    \"satisfaction_employee_equipe\",\n",
    "    \"satisfaction_employee_equilibre_pro_perso\",\n",
    "]\n",
    "df_clean[\"satisfaction_globale\"] = df_clean[cols_satisfaction].mean(axis=1)\n",
    "\n",
    "print(\"3 features creees avec succes !\")\n",
    "print(f\"\\nNouvelle shape du dataframe : {df_clean.shape}\")\n",
    "print(\"\\nApercu des nouvelles features :\")\n",
    "df_clean[\n",
    "    [\"ratio_salaire_experience\", \"stagnation_poste\", \"satisfaction_globale\"]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0221235",
   "metadata": {},
   "source": [
    "### 10.2 Verification de la pertinence des features\n",
    "\n",
    "Verifions la correlation de nos nouvelles features avec la variable cible `depart` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation des nouvelles features avec depart (variable cible)\n",
    "new_features = [\"ratio_salaire_experience\", \"stagnation_poste\", \"satisfaction_globale\"]\n",
    "\n",
    "# Creer un dataframe temporaire avec les nouvelles features et la cible\n",
    "temp_df = df_clean[new_features].copy()\n",
    "temp_df[\"depart\"] = df_clean[\n",
    "    \"depart\"\n",
    "].values  # La cible est encore dans df_clean a ce stade\n",
    "\n",
    "correlations = temp_df.corr()[\"depart\"].drop(\"depart\")\n",
    "\n",
    "print(\"Correlation avec depart (variable cible) :\")\n",
    "for feat, corr in correlations.items():\n",
    "    signe = \"🔴\" if corr > 0 else \"🟢\"\n",
    "    interpretation = \"quitte plus\" if corr > 0 else \"reste plus\"\n",
    "    print(f\"{signe} {feat}: {corr:.4f} ({interpretation})\")\n",
    "\n",
    "print(\"\\nInterpretation :\")\n",
    "print(\"   - satisfaction_globale : plus les gens sont satisfaits, moins ils partent\")\n",
    "print(\n",
    "    \"   - stagnation_poste : correlation negative = ceux qui stagnent RESTENT (profils seniors stables)\"\n",
    ")\n",
    "print(\n",
    "    \"   - ratio_salaire_experience : les mieux payes par rapport a leur experience partent plus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8927c9",
   "metadata": {},
   "source": [
    "## 11. Pipeline de preprocessing avec ColumnTransformer\n",
    "\n",
    "### Pourquoi utiliser un Pipeline ?\n",
    "\n",
    "| Avantage                     | Explication                                                               |\n",
    "| ---------------------------- | ------------------------------------------------------------------------- |\n",
    "| ✅ **Evite le data leakage** | Le preprocessing est applique UNIQUEMENT sur le train a chaque fold de CV |\n",
    "| ✅ **Code propre**           | Tout le preprocessing est encapsule dans un seul objet                    |\n",
    "| ✅ **Reproductible**         | Facile a reutiliser et deployer                                           |\n",
    "| ✅ **Compatible CV**         | S'integre parfaitement avec `cross_val_score` et `GridSearchCV`           |\n",
    "\n",
    "### 11.1 Identification des colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation features / cible AVANT le pipeline\n",
    "y = df_clean[\"depart\"]\n",
    "X = df_clean.drop(columns=[\"depart\"])\n",
    "\n",
    "# Identification automatique des colonnes numeriques et categorielles\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Colonnes identifiees pour le Pipeline :\")\n",
    "print(\n",
    "    f\"\\n  Numeriques ({len(num_cols)}) : {num_cols[:5]}{'...' if len(num_cols) > 5 else ''}\"\n",
    ")\n",
    "print(f\"\\n  Categorielles ({len(cat_cols)}) :\")\n",
    "for col in cat_cols:\n",
    "    unique_vals = X[col].unique()\n",
    "    print(f\"    - {col} ({len(unique_vals)} modalites)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44c983",
   "metadata": {},
   "source": [
    "### 11.2 Creation du ColumnTransformer\n",
    "\n",
    "**ColumnTransformer** applique des transformations differentes selon le type de colonne :\n",
    "\n",
    "| Type de colonne  | Transformation                | Parametre                  |\n",
    "| ---------------- | ----------------------------- | -------------------------- |\n",
    "| **Numerique**    | `StandardScaler()`            | Moyenne=0, Ecart-type=1    |\n",
    "| **Categorielle** | `OneHotEncoder(drop='first')` | Evite colinearite parfaite |\n",
    "\n",
    "**Parametre `remainder='passthrough'`** : conserve les colonnes non transformees (si elles existent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a743e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Creation du ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),  # Standardisation des numeriques\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False),\n",
    "            cat_cols,\n",
    "        ),  # Encodage des categorielles\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Conserver les autres colonnes si elles existent\n",
    ")\n",
    "\n",
    "print(\"\\nTransformations definies :\")\n",
    "print(f\"  - 'num' : StandardScaler sur {len(num_cols)} colonnes numeriques\")\n",
    "print(f\"  - 'cat' : OneHotEncoder sur {len(cat_cols)} colonnes categorielles\")\n",
    "print(\"\\nLe preprocessor sera FIT sur X_train uniquement (pas de data leakage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739e3d5",
   "metadata": {},
   "source": [
    "### 11.3 Split Train/Test avec stratification\n",
    "\n",
    "**❓ Question légitime : Pourquoi faire un split si on fait de la cross-validation ?**\n",
    "\n",
    "On fait les **DEUX** pour des raisons différentes :\n",
    "\n",
    "| Étape                                       | Objectif                                              | Utilisation                          |\n",
    "| ------------------------------------------- | ----------------------------------------------------- | ------------------------------------ |\n",
    "| **Split Train/Test (80/20)**                | Avoir un **jeu de test FINAL jamais touché**          | Évaluation finale du meilleur modèle |\n",
    "| **Cross-validation (sur Train uniquement)** | **Comparer les modèles** et tuner les hyperparamètres | Sélection du meilleur modèle         |\n",
    "\n",
    "**Pourquoi ?** Si on fait la CV sur **tout le dataset**, on n'a plus de données \"fraîches\" pour vérifier si le modèle généralise vraiment. Le test est le **juge final impartial**.\n",
    "\n",
    "**Workflow preprocessing (éviter data leakage) :**\n",
    "\n",
    "| Etape | Action                                   | Explication                                    |\n",
    "| ----- | ---------------------------------------- | ---------------------------------------------- |\n",
    "| 1     | `X, y = separation features/cible`       | Séparer les variables explicatives de la cible |\n",
    "| 2     | `X_train, X_test = split(X, y)`          | Split **avant** preprocessing                  |\n",
    "| 3     | `preprocessor.fit(X_train)`              | Fit sur train **UNIQUEMENT**                   |\n",
    "| 4     | `X_train_processed = transform(X_train)` | Transform train                                |\n",
    "| 5     | `X_test_processed = transform(X_test)`   | Transform test (mêmes paramètres du train)     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split stratifie AVANT le fit du preprocessor\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,  # Important pour le desequilibre de classes\n",
    ")\n",
    "\n",
    "print(\"Split train/test avec stratification :\")\n",
    "print(f\"\\n  Train : {X_train.shape[0]} lignes ({X_train.shape[0] / len(X) * 100:.0f}%)\")\n",
    "print(f\"    - Churn : {y_train.sum()} ({y_train.mean() * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"    - Non-churn : {len(y_train) - y_train.sum()} ({(1 - y_train.mean()) * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"\\n  Test : {X_test.shape[0]} lignes ({X_test.shape[0] / len(X) * 100:.0f}%)\")\n",
    "print(f\"    - Churn : {y_test.sum()} ({y_test.mean() * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"    - Non-churn : {len(y_test) - y_test.sum()} ({(1 - y_test.mean()) * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f810e",
   "metadata": {},
   "source": [
    "### 11.4 Application du preprocessor (fit_transform sur train, transform sur test)\n",
    "\n",
    "**C'est ici que la magie du Pipeline opere :**\n",
    "\n",
    "- `fit_transform(X_train)` : calcule les parametres (moyenne, ecart-type, modalites) ET transforme\n",
    "- `transform(X_test)` : utilise les parametres du train pour transformer le test\n",
    "\n",
    "**Avantage majeur** : Quand on utilisera `cross_val_score`, le fit sera automatiquement refait sur chaque fold !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sur train, transform sur train et test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)  # FIT + TRANSFORM\n",
    "X_test_processed = preprocessor.transform(X_test)  # TRANSFORM seulement\n",
    "\n",
    "# Recuperation des noms de colonnes pour lisibilite\n",
    "# (Les colonnes numeriques gardent leur nom, les categorielles sont encodees)\n",
    "num_feature_names = num_cols\n",
    "cat_feature_names = (\n",
    "    preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_cols).tolist()\n",
    ")\n",
    "all_feature_names = num_feature_names + cat_feature_names\n",
    "\n",
    "print(\"Preprocessing applique avec succes !\")\n",
    "print(\"\\nDimensions apres transformation :\")\n",
    "print(f\"  X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\"  X_test_processed  : {X_test_processed.shape}\")\n",
    "\n",
    "print(f\"\\nNombre de features finales : {len(all_feature_names)}\")\n",
    "print(f\"  - Numeriques (standardisees) : {len(num_feature_names)}\")\n",
    "print(f\"  - Categorielles (encodees)   : {len(cat_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b653394",
   "metadata": {},
   "source": [
    "### 11.5 Verification : pas de data leakage\n",
    "\n",
    "Verifions que le StandardScaler a bien ete fit sur le train uniquement :\n",
    "\n",
    "- **Train** : moyenne ≈ 0, ecart-type ≈ 1\n",
    "- **Test** : moyenne ≠ 0 exactement (normal, car les parametres viennent du train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e07bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indices = list(range(len(num_cols)))\n",
    "\n",
    "print(\"Verification du StandardScaler (colonnes numeriques) :\")\n",
    "print(f\"\\n  Train - Moyenne  : {X_train_processed[:, num_indices].mean():.6f}\")\n",
    "print(f\"  Train - Std      : {X_train_processed[:, num_indices].std():.6f}\")\n",
    "print(f\"\\n  Test  - Moyenne  : {X_test_processed[:, num_indices].mean():.6f}\")\n",
    "print(f\"  Test  - Std      : {X_test_processed[:, num_indices].std():.6f}\")\n",
    "\n",
    "print(\"\\nPas de data leakage : le test n'a pas exactement moyenne=0\")\n",
    "print(\"   (les parametres du scaler viennent du train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c643c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 2 : Feature Engineering\n",
    "\n",
    "### Nettoyage effectué\n",
    "\n",
    "- ✅ Aucun doublon détecté\n",
    "- ✅ Outliers conservés (valeurs RH légitimes : hauts salaires, ancienneté élevée)\n",
    "- ✅ 8 colonnes supprimées : identifiants, variance nulle, redondantes avec la cible\n",
    "\n",
    "### Analyse des corrélations\n",
    "\n",
    "- Matrice de **Pearson** (corrélations linéaires) - visualisation Plotly\n",
    "- Matrice de **Spearman** (corrélations monotones)\n",
    "- 2 variables supprimées pour multicolinéarité (|r| > 0.7) avec justification métier\n",
    "\n",
    "### Conversion de type (best practice)\n",
    "\n",
    "- ✅ `augementation_salaire_precedente` : \"11 %\" → 11.0 (numérique)\n",
    "- **Avantage** : 1 feature standardisée au lieu de 14 colonnes OneHot → moins d'overfitting\n",
    "- Le modèle comprend que 23% > 11% (ordre préservé)\n",
    "\n",
    "### Feature Engineering (3 nouvelles features métier)\n",
    "\n",
    "| Feature                    | Formule                 | Corr. avec depart | Interprétation                      |\n",
    "| -------------------------- | ----------------------- | ----------------- | ----------------------------------- |\n",
    "| `ratio_salaire_experience` | salaire / (exp + 1)     | +0.10             | Bien payés partent plus             |\n",
    "| `stagnation_poste`         | ancienneté - promotion  | -0.15             | Stagnants restent (profils stables) |\n",
    "| `satisfaction_globale`     | moyenne 4 satisfactions | -0.16             | Satisfaits restent                  |\n",
    "\n",
    "### Pipeline de preprocessing (ColumnTransformer)\n",
    "\n",
    "| Type       | Transformation                | Colonnes             |\n",
    "| ---------- | ----------------------------- | -------------------- |\n",
    "| Numérique  | `StandardScaler()`            | 21 colonnes          |\n",
    "| Catégoriel | `OneHotEncoder(drop='first')` | 7 cols → 21 features |\n",
    "\n",
    "### Dataset prêt pour la modélisation\n",
    "\n",
    "| Métrique         | Valeur                             |\n",
    "| ---------------- | ---------------------------------- |\n",
    "| Features totales | **42** (21 num + 21 cat)           |\n",
    "| Train            | 1176 lignes (80%)                  |\n",
    "| Test             | 294 lignes (20%)                   |\n",
    "| Churn train      | 16.2%                              |\n",
    "| Churn test       | 16.0%                              |\n",
    "| Data leakage     | Vérifié (fit sur train uniquement) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14188a43",
   "metadata": {},
   "source": [
    "# Partie 3 : Modélisation de Référence (Baseline)\n",
    "\n",
    "**Objectif :** Établir des **modèles de référence** pour comprendre la difficulté du problème avant d'optimiser.\n",
    "\n",
    "---\n",
    "\n",
    "## Approche méthodologique\n",
    "\n",
    "| Étape | Modèle                     | Objectif                                                  |\n",
    "| ----- | -------------------------- | --------------------------------------------------------- |\n",
    "| 1     | **DummyClassifier**        | Baseline naïf (que vaut \"toujours prédire majoritaire\" ?) |\n",
    "| 2     | **LogisticRegression**     | Modèle linéaire simple                                    |\n",
    "| 3     | **RandomForestClassifier** | Modèle non-linéaire (arbres)                              |\n",
    "\n",
    "## Métriques utilisées\n",
    "\n",
    "Pour un problème de **classification binaire déséquilibrée** (16% churn), l'**accuracy** est trompeuse.\n",
    "\n",
    "| Métrique      | Formule               | Interprétation métier                      |\n",
    "| ------------- | --------------------- | ------------------------------------------ |\n",
    "| **Precision** | TP / (TP + FP)        | \"Parmi les alertes, combien sont vraies ?\" |\n",
    "| **Recall**    | TP / (TP + FN)        | \"Combien de départs réels détectés ?\"      |\n",
    "| **F1-Score**  | 2 × (P × R) / (P + R) | Équilibre Precision/Recall                 |\n",
    "\n",
    "**Contexte RH :** Le **Recall** est critique car **rater un départ** (FN) coûte plus cher qu'une fausse alerte (FP).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86fda6",
   "metadata": {},
   "source": [
    "## 12. Modèle Dummy (Baseline naïf)\n",
    "\n",
    "Le `DummyClassifier` sert de **référence minimale**. Si nos vrais modèles ne font pas mieux, c'est qu'ils n'apprennent rien.\n",
    "\n",
    "**Stratégie utilisée :** `most_frequent` → prédit toujours la classe majoritaire (0 = resté)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modele Dummy : predit toujours la classe majoritaire\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_dummy = dummy_clf.predict(X_train_processed)\n",
    "y_test_pred_dummy = dummy_clf.predict(X_test_processed)\n",
    "\n",
    "print(\"MODELE DUMMY (Baseline) - Strategie: stratified\")\n",
    "\n",
    "print(\"\\nPerformance sur TRAIN :\")\n",
    "print(\n",
    "    classification_report(y_train, y_train_pred_dummy, target_names=[\"Resté\", \"Parti\"])\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance sur TEST :\")\n",
    "print(classification_report(y_test, y_test_pred_dummy, target_names=[\"Resté\", \"Parti\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Modele Logistic Regression (sans class_weight pour l'instant)\n",
    "lr_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_lr = lr_clf.predict(X_train_processed)\n",
    "y_test_pred_lr = lr_clf.predict(X_test_processed)\n",
    "\n",
    "print(\"MODELE LOGISTIC REGRESSION (sans class_weight)\")\n",
    "\n",
    "print(\"\\nPerformance sur TRAIN :\")\n",
    "print(classification_report(y_train, y_train_pred_lr, target_names=[\"Resté\", \"Parti\"]))\n",
    "\n",
    "print(\"\\nPerformance sur TEST :\")\n",
    "print(classification_report(y_test, y_test_pred_lr, target_names=[\"Resté\", \"Parti\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modele Random Forest (sans class_weight pour l'instant)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_clf.predict(X_train_processed)\n",
    "y_test_pred_rf = rf_clf.predict(X_test_processed)\n",
    "\n",
    "print(\"MODELE RANDOM FOREST (sans class_weight)\")\n",
    "\n",
    "print(\"\\nPerformance sur TRAIN :\")\n",
    "print(classification_report(y_train, y_train_pred_rf, target_names=[\"Resté\", \"Parti\"]))\n",
    "\n",
    "print(\"\\nPerformance sur TEST :\")\n",
    "print(classification_report(y_test, y_test_pred_rf, target_names=[\"Resté\", \"Parti\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81795d7c",
   "metadata": {},
   "source": [
    "## 13. Comparaison des Modèles Baseline\n",
    "\n",
    "Récapitulatif des performances des 3 modèles **sans gestion du déséquilibre**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Fonction pour calculer les metriques\n",
    "def get_metrics(y_true, y_pred, dataset_name):\n",
    "    return {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision (Parti)\": precision_score(\n",
    "            y_true, y_pred, pos_label=1, zero_division=0\n",
    "        ),\n",
    "        \"Recall (Parti)\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"F1 (Parti)\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "    }\n",
    "\n",
    "\n",
    "# Calcul des metriques pour chaque modele\n",
    "results = []\n",
    "\n",
    "# Dummy\n",
    "results.append({**get_metrics(y_train, y_train_pred_dummy, \"Train\"), \"Modele\": \"Dummy\"})\n",
    "results.append({**get_metrics(y_test, y_test_pred_dummy, \"Test\"), \"Modele\": \"Dummy\"})\n",
    "\n",
    "# Logistic Regression\n",
    "results.append(\n",
    "    {**get_metrics(y_train, y_train_pred_lr, \"Train\"), \"Modele\": \"Logistic Regression\"}\n",
    ")\n",
    "results.append(\n",
    "    {**get_metrics(y_test, y_test_pred_lr, \"Test\"), \"Modele\": \"Logistic Regression\"}\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "results.append(\n",
    "    {**get_metrics(y_train, y_train_pred_rf, \"Train\"), \"Modele\": \"Random Forest\"}\n",
    ")\n",
    "results.append(\n",
    "    {**get_metrics(y_test, y_test_pred_rf, \"Test\"), \"Modele\": \"Random Forest\"}\n",
    ")\n",
    "\n",
    "# Affichage\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[\n",
    "    [\n",
    "        \"Modele\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision (Parti)\",\n",
    "        \"Recall (Parti)\",\n",
    "        \"F1 (Parti)\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "print(\"COMPARAISON DES MODELES BASELINE (sans gestion du desequilibre)\")\n",
    "\n",
    "print()\n",
    "display(\n",
    "    results_df.style.format(\n",
    "        {\n",
    "            \"Accuracy\": \"{:.2%}\",\n",
    "            \"Precision (Parti)\": \"{:.2%}\",\n",
    "            \"Recall (Parti)\": \"{:.2%}\",\n",
    "            \"F1 (Parti)\": \"{:.2%}\",\n",
    "        }\n",
    "    ).set_properties(**{\"text-align\": \"center\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73556c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Metriques sur le TEST uniquement (pour evaluer la generalisation)\n",
    "test_results = results_df[results_df[\"Dataset\"] == \"Test\"].copy()\n",
    "\n",
    "# Graphique 1 : Recall (le plus important pour notre cas)\n",
    "x = np.arange(len(test_results))\n",
    "width = 0.25\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.bar(\n",
    "    x - width,\n",
    "    test_results[\"Precision (Parti)\"],\n",
    "    width,\n",
    "    label=\"Precision\",\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "ax1.bar(x, test_results[\"Recall (Parti)\"], width, label=\"Recall\", color=\"darkorange\")\n",
    "ax1.bar(x + width, test_results[\"F1 (Parti)\"], width, label=\"F1-Score\", color=\"green\")\n",
    "ax1.set_ylabel(\"Score\")\n",
    "ax1.set_title(\"Metriques sur la classe 'Parti' (Test)\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(test_results[\"Modele\"])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Seuil 50%\")\n",
    "\n",
    "# Graphique 2 : Comparaison Train vs Test (detection overfitting)\n",
    "train_results = results_df[results_df[\"Dataset\"] == \"Train\"][\"Recall (Parti)\"].values\n",
    "test_results_recall = results_df[results_df[\"Dataset\"] == \"Test\"][\n",
    "    \"Recall (Parti)\"\n",
    "].values\n",
    "modeles = [\"Dummy\", \"Logistic Reg.\", \"Random Forest\"]\n",
    "\n",
    "ax2 = axes[1]\n",
    "x2 = np.arange(len(modeles))\n",
    "ax2.bar(x2 - 0.2, train_results, 0.4, label=\"Train\", color=\"steelblue\")\n",
    "ax2.bar(x2 + 0.2, test_results_recall, 0.4, label=\"Test\", color=\"darkorange\")\n",
    "ax2.set_ylabel(\"Recall (Parti)\")\n",
    "ax2.set_title(\"Detection Overfitting : Train vs Test\")\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(modeles)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d50886",
   "metadata": {},
   "source": [
    "### 13.1 Analyse des résultats Baseline\n",
    "\n",
    "**Constats attendus :**\n",
    "\n",
    "| Modèle                  | Comportement attendu                        |\n",
    "| ----------------------- | ------------------------------------------- |\n",
    "| **Dummy**               | Recall = 0% (ne prédit jamais \"Parti\")      |\n",
    "| **Logistic Regression** | Recall faible (classe minoritaire ignorée)  |\n",
    "| **Random Forest**       | Recall train >> test (overfitting probable) |\n",
    "\n",
    "**Problème identifié :** Sans gestion du déséquilibre (16% vs 84%), les modèles optimisent l'accuracy en ignorant la classe minoritaire \"Parti\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb19c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 3 : Modélisation Baseline\n",
    "\n",
    "### Modèles entraînés\n",
    "\n",
    "| Modèle                   | Type                  | Objectif                     |\n",
    "| ------------------------ | --------------------- | ---------------------------- |\n",
    "| `DummyClassifier`        | Baseline naïf         | Référence minimale           |\n",
    "| `LogisticRegression`     | Linéaire              | Premier modèle interprétable |\n",
    "| `RandomForestClassifier` | Non-linéaire (arbres) | Capture relations complexes  |\n",
    "\n",
    "### Métriques calculées\n",
    "\n",
    "- ✅ `classification_report()` (Precision, Recall, F1)\n",
    "- ✅ Matrice de confusion (Train ET Test)\n",
    "- ✅ Comparaison Train vs Test pour détecter l'overfitting\n",
    "\n",
    "### Problème identifié\n",
    "\n",
    "**Déséquilibre des classes (16% Parti / 84% Resté)** :\n",
    "\n",
    "- Les modèles optimisent l'accuracy → ignorent la classe minoritaire\n",
    "- Le Recall sur \"Parti\" est insuffisant pour un usage métier RH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b2c64",
   "metadata": {},
   "source": [
    "# PARTIE 4 : GESTION DU DÉSÉQUILIBRE DES CLASSES\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Stratégie de gestion du déséquilibre\n",
    "\n",
    "### 14.1 Contexte métier\n",
    "\n",
    "Dans un contexte RH, **identifier les employés à risque de départ** (classe \"Parti\") est crucial :\n",
    "\n",
    "- Un **Faux Négatif** (employé à risque non détecté) = départ non anticipé → coût élevé\n",
    "- Un **Faux Positif** (employé stable mal classé) = actions RH inutiles → coût modéré\n",
    "\n",
    "**Objectif** : Maximiser le **Recall** sur la classe \"Parti\" tout en maintenant une Precision acceptable.\n",
    "\n",
    "### 14.2 Techniques à tester\n",
    "\n",
    "| #   | Technique                 | Package  | Approche                     |\n",
    "| --- | ------------------------- | -------- | ---------------------------- |\n",
    "| 1   | `class_weight='balanced'` | sklearn  | Pondération des erreurs      |\n",
    "| 2   | SMOTE                     | imblearn | Oversampling synthétique     |\n",
    "| 3   | Random Undersampling      | imblearn | Réduction classe majoritaire |\n",
    "| 4   | Calibration               | sklearn  | `CalibratedClassifierCV`     |\n",
    "\n",
    "### 14.3 Protocole d'évaluation\n",
    "\n",
    "- **Validation croisée stratifiée** : `StratifiedKFold` (5 folds)\n",
    "- **Métriques principales** : Recall, Precision, F1-score (classe \"Parti\")\n",
    "- **Métrique secondaire** : ROC-AUC, PR-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "print(\"\\nRappel - Distribution des classes :\")\n",
    "print(y.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ba238",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 15. Fonction d'évaluation en validation croisée\n",
    "\n",
    "Création d'une fonction réutilisable pour évaluer les modèles avec validation croisée stratifiée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de17a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(model, X_data, y_data, preprocessor, cv=5, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Évalue un modèle avec validation croisée stratifiée.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : estimator sklearn\n",
    "    X_data : DataFrame des features\n",
    "    y_data : Series de la cible\n",
    "    preprocessor : ColumnTransformer pour le preprocessing\n",
    "    cv : int, nombre de folds\n",
    "    model_name : str, nom du modèle pour l'affichage\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : résultats avec moyennes et écarts-types\n",
    "    \"\"\"\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Création du pipeline complet\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "\n",
    "    # Configuration de la validation croisée stratifiée\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Définition des métriques (focus sur classe positive = 1 = Parti)\n",
    "    scoring = {\n",
    "        \"recall\": make_scorer(recall_score, pos_label=1),\n",
    "        \"precision\": make_scorer(precision_score, pos_label=1, zero_division=0),\n",
    "        \"f1\": make_scorer(f1_score, pos_label=1),\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "    }\n",
    "\n",
    "    # Exécution de la validation croisée\n",
    "    cv_results = cross_validate(\n",
    "        pipeline,\n",
    "        X_data,\n",
    "        y_data,\n",
    "        cv=skf,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Compilation des résultats\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"recall_train_mean\": cv_results[\"train_recall\"].mean(),\n",
    "        \"recall_train_std\": cv_results[\"train_recall\"].std(),\n",
    "        \"recall_test_mean\": cv_results[\"test_recall\"].mean(),\n",
    "        \"recall_test_std\": cv_results[\"test_recall\"].std(),\n",
    "        \"precision_train_mean\": cv_results[\"train_precision\"].mean(),\n",
    "        \"precision_train_std\": cv_results[\"train_precision\"].std(),\n",
    "        \"precision_test_mean\": cv_results[\"test_precision\"].mean(),\n",
    "        \"precision_test_std\": cv_results[\"test_precision\"].std(),\n",
    "        \"f1_train_mean\": cv_results[\"train_f1\"].mean(),\n",
    "        \"f1_train_std\": cv_results[\"train_f1\"].std(),\n",
    "        \"f1_test_mean\": cv_results[\"test_f1\"].mean(),\n",
    "        \"f1_test_std\": cv_results[\"test_f1\"].std(),\n",
    "        \"roc_auc_train_mean\": cv_results[\"train_roc_auc\"].mean(),\n",
    "        \"roc_auc_test_mean\": cv_results[\"test_roc_auc\"].mean(),\n",
    "    }\n",
    "\n",
    "    # Affichage formaté\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\" {model_name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"\\n{'Métrique':<15} {'Train':>20} {'Test':>20}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(\n",
    "        f\"{'Recall':<15} {results['recall_train_mean']:.3f} ± {results['recall_train_std']:.3f}    {results['recall_test_mean']:.3f} ± {results['recall_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'Precision':<15} {results['precision_train_mean']:.3f} ± {results['precision_train_std']:.3f}    {results['precision_test_mean']:.3f} ± {results['precision_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'F1-Score':<15} {results['f1_train_mean']:.3f} ± {results['f1_train_std']:.3f}    {results['f1_test_mean']:.3f} ± {results['f1_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'ROC-AUC':<15} {results['roc_auc_train_mean']:.3f}              {results['roc_auc_test_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"✅ Fonction evaluate_model_cv() définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3828bb",
   "metadata": {},
   "source": [
    "## 16. Technique 1 : Class Weight (Pondération des classes)\n",
    "\n",
    "### 16.1 Principe\n",
    "\n",
    "Le paramètre `class_weight='balanced'` ajuste automatiquement les poids des classes inversement proportionnels à leur fréquence :\n",
    "\n",
    "$$w_c = \\frac{n_{samples}}{n_{classes} \\times n_{samples_c}}$$\n",
    "\n",
    "Cela pénalise davantage les erreurs sur la classe minoritaire (\"Parti\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18.2 Entraînement des modèles avec class_weight='balanced'\n",
    "all_results = []  # Liste pour stocker tous les résultats\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"🔄 Entraînement Logistic Regression avec class_weight='balanced'...\")\n",
    "lr_balanced = LogisticRegression(\n",
    "    class_weight=\"balanced\", max_iter=1000, random_state=42\n",
    ")\n",
    "results_lr_balanced = evaluate_model_cv(\n",
    "    lr_balanced, X, y, preprocessor, model_name=\"Logistic Regression (balanced)\"\n",
    ")\n",
    "all_results.append(results_lr_balanced)\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\n🔄 Entraînement Random Forest avec class_weight='balanced'...\")\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    ")\n",
    "results_rf_balanced = evaluate_model_cv(\n",
    "    rf_balanced, X, y, preprocessor, model_name=\"Random Forest (balanced)\"\n",
    ")\n",
    "all_results.append(results_rf_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491e96b",
   "metadata": {},
   "source": [
    "## 17. Technique 2 : SMOTE (Oversampling)\n",
    "\n",
    "### 17.1 Principe\n",
    "\n",
    "**SMOTE** (Synthetic Minority Over-sampling Technique) génère des observations synthétiques pour la classe minoritaire en interpolant entre les observations existantes et leurs k plus proches voisins.\n",
    "\n",
    "**Important** : SMOTE doit être appliqué **uniquement sur le jeu d'entraînement** pour éviter la fuite de données (data leakage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_resampling(\n",
    "    model,\n",
    "    X_data,\n",
    "    y_data,\n",
    "    preprocessor,\n",
    "    resampler,\n",
    "    cv=5,\n",
    "    model_name=\"Model\",\n",
    "    pos_label=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Évalue un modèle avec resampling (SMOTE ou Undersampling) en validation croisée.\n",
    "    Le resampling est appliqué APRÈS le preprocessing et UNIQUEMENT sur le train.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    pos_label : int ou str, label de la classe positive (défaut: 1)\n",
    "    \"\"\"\n",
    "    from sklearn.base import clone\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Convertir y en numpy array si c'est une Series\n",
    "    y_array = y_data.values if hasattr(y_data, \"values\") else y_data\n",
    "\n",
    "    # Stockage des métriques par fold\n",
    "    metrics = {\n",
    "        \"recall_train\": [],\n",
    "        \"recall_test\": [],\n",
    "        \"precision_train\": [],\n",
    "        \"precision_test\": [],\n",
    "        \"f1_train\": [],\n",
    "        \"f1_test\": [],\n",
    "        \"roc_auc_train\": [],\n",
    "        \"roc_auc_test\": [],\n",
    "    }\n",
    "\n",
    "    for _, (train_idx, test_idx) in enumerate(skf.split(X_data, y_array), 1):\n",
    "        # Split des données\n",
    "        X_train_fold, X_test_fold = X_data.iloc[train_idx], X_data.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_array[train_idx], y_array[test_idx]\n",
    "\n",
    "        # Preprocessing\n",
    "        X_train_processed = preprocessor.fit_transform(X_train_fold)\n",
    "        X_test_processed = preprocessor.transform(X_test_fold)\n",
    "\n",
    "        # Resampling sur le train uniquement\n",
    "        X_train_resampled, y_train_resampled = resampler.fit_resample(\n",
    "            X_train_processed, y_train_fold\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Prédictions\n",
    "        y_train_pred = clf.predict(X_train_resampled)\n",
    "        y_test_pred = clf.predict(X_test_processed)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        metrics[\"recall_train\"].append(\n",
    "            recall_score(y_train_resampled, y_train_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"recall_test\"].append(\n",
    "            recall_score(y_test_fold, y_test_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"precision_train\"].append(\n",
    "            precision_score(\n",
    "                y_train_resampled, y_train_pred, pos_label=pos_label, zero_division=0\n",
    "            )\n",
    "        )\n",
    "        metrics[\"precision_test\"].append(\n",
    "            precision_score(\n",
    "                y_test_fold, y_test_pred, pos_label=pos_label, zero_division=0\n",
    "            )\n",
    "        )\n",
    "        metrics[\"f1_train\"].append(\n",
    "            f1_score(y_train_resampled, y_train_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"f1_test\"].append(\n",
    "            f1_score(y_test_fold, y_test_pred, pos_label=pos_label)\n",
    "        )\n",
    "\n",
    "        # ROC-AUC (nécessite proba)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            # Index de la classe positive dans le classifieur\n",
    "            pos_idx = list(clf.classes_).index(pos_label)\n",
    "            y_train_proba = clf.predict_proba(X_train_resampled)[:, pos_idx]\n",
    "            y_test_proba = clf.predict_proba(X_test_processed)[:, pos_idx]\n",
    "            metrics[\"roc_auc_train\"].append(\n",
    "                roc_auc_score(\n",
    "                    (y_train_resampled == pos_label).astype(int), y_train_proba\n",
    "                )\n",
    "            )\n",
    "            metrics[\"roc_auc_test\"].append(\n",
    "                roc_auc_score((y_test_fold == pos_label).astype(int), y_test_proba)\n",
    "            )\n",
    "\n",
    "    # Compilation des résultats\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"recall_train_mean\": np.mean(metrics[\"recall_train\"]),\n",
    "        \"recall_train_std\": np.std(metrics[\"recall_train\"]),\n",
    "        \"recall_test_mean\": np.mean(metrics[\"recall_test\"]),\n",
    "        \"recall_test_std\": np.std(metrics[\"recall_test\"]),\n",
    "        \"precision_train_mean\": np.mean(metrics[\"precision_train\"]),\n",
    "        \"precision_train_std\": np.std(metrics[\"precision_train\"]),\n",
    "        \"precision_test_mean\": np.mean(metrics[\"precision_test\"]),\n",
    "        \"precision_test_std\": np.std(metrics[\"precision_test\"]),\n",
    "        \"f1_train_mean\": np.mean(metrics[\"f1_train\"]),\n",
    "        \"f1_train_std\": np.std(metrics[\"f1_train\"]),\n",
    "        \"f1_test_mean\": np.mean(metrics[\"f1_test\"]),\n",
    "        \"f1_test_std\": np.std(metrics[\"f1_test\"]),\n",
    "        \"roc_auc_train_mean\": np.mean(metrics[\"roc_auc_train\"])\n",
    "        if metrics[\"roc_auc_train\"]\n",
    "        else 0,\n",
    "        \"roc_auc_test_mean\": np.mean(metrics[\"roc_auc_test\"])\n",
    "        if metrics[\"roc_auc_test\"]\n",
    "        else 0,\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"\\n{'Métrique':<15} {'Train':>20} {'Test':>20}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(\n",
    "        f\"{'Recall':<15} {results['recall_train_mean']:.3f} ± {results['recall_train_std']:.3f}    {results['recall_test_mean']:.3f} ± {results['recall_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'Precision':<15} {results['precision_train_mean']:.3f} ± {results['precision_train_std']:.3f}    {results['precision_test_mean']:.3f} ± {results['precision_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'F1-Score':<15} {results['f1_train_mean']:.3f} ± {results['f1_train_std']:.3f}    {results['f1_test_mean']:.3f} ± {results['f1_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'ROC-AUC':<15} {results['roc_auc_train_mean']:.3f}              {results['roc_auc_test_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Fonction evaluate_model_with_resampling() définie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔄 Entraînement Random Forest avec SMOTE...\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf_smote = evaluate_model_with_resampling(\n",
    "    rf_smote, X, y, preprocessor, smote, model_name=\"Random Forest + SMOTE\"\n",
    ")\n",
    "all_results.append(results_rf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ee94a",
   "metadata": {},
   "source": [
    "## 18. Technique 3 : Undersampling\n",
    "\n",
    "### 18.1 Principe\n",
    "\n",
    "L'**undersampling** réduit le nombre d'observations de la classe majoritaire (\"Resté\") pour équilibrer les classes.\n",
    "\n",
    "⚠️ **Inconvénient** : Perte d'information en supprimant des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.2 Random Forest avec Undersampling\n",
    "print(\"Entraînement Random Forest avec Undersampling...\")\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "rf_under = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf_under = evaluate_model_with_resampling(\n",
    "    rf_under,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor,\n",
    "    undersampler,\n",
    "    model_name=\"Random Forest + Undersampling\",\n",
    ")\n",
    "all_results.append(results_rf_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ce082",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 19. Technique 4 : Calibration des probabilités\n",
    "\n",
    "### 19.1 Principe\n",
    "\n",
    "La **calibration** ajuste les probabilités prédites pour qu'elles reflètent mieux la réalité. `CalibratedClassifierCV` utilise soit :\n",
    "\n",
    "- **Platt scaling** (sigmoid) : pour modèles SVM\n",
    "- **Isotonic regression** : non-paramétrique, plus flexible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21.2 Random Forest avec Calibration + class_weight='balanced'\n",
    "print(\"Entraînement Random Forest avec Calibration...\")\n",
    "\n",
    "# Modèle de base avec class_weight\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calibration\n",
    "rf_calibrated = CalibratedClassifierCV(\n",
    "    rf_base,\n",
    "    method=\"isotonic\",\n",
    "    cv=3,  # CV interne pour la calibration\n",
    ")\n",
    "\n",
    "results_rf_calibrated = evaluate_model_cv(\n",
    "    rf_calibrated,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor,\n",
    "    model_name=\"Random Forest (balanced + calibrated)\",\n",
    ")\n",
    "all_results.append(results_rf_calibrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b773b542",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 20. Comparaison des techniques de gestion du déséquilibre\n",
    "\n",
    "### 20.1 Tableau récapitulatif\n",
    "\n",
    "### 20.2 Comment lire les graphiques\n",
    "\n",
    "**Graphique 1 - Trade-off Recall vs Precision :**\n",
    "\n",
    "- **Axe X** : Recall (capacité à détecter les départs)\n",
    "- **Axe Y** : Precision (fiabilité des alertes)\n",
    "- **Lecture** : Un point en haut à droite = modèle idéal (bon recall ET bonne precision)\n",
    "- **Objectif métier** : Privilégier le recall (détecter un maximum de départs)\n",
    "\n",
    "**Graphique 2 - F1-Score par technique :**\n",
    "\n",
    "- **Barres horizontales** : Score F1 (moyenne harmonique recall/precision)\n",
    "- **Barres d'erreur** : Écart-type sur les 5 folds de validation croisée\n",
    "- **Lecture** : Plus la barre est longue, meilleur est le compromis recall/precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e74622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame de comparaison\n",
    "comparison_imbalance_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sélection et formatage des colonnes principales\n",
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"recall_test_mean\",\n",
    "    \"recall_test_std\",\n",
    "    \"precision_test_mean\",\n",
    "    \"f1_test_mean\",\n",
    "    \"roc_auc_test_mean\",\n",
    "]\n",
    "\n",
    "comparison_display = comparison_imbalance_df[display_cols].copy()\n",
    "comparison_display.columns = [\n",
    "    \"Modèle\",\n",
    "    \"Recall (Test)\",\n",
    "    \"Recall Std\",\n",
    "    \"Precision (Test)\",\n",
    "    \"F1 (Test)\",\n",
    "    \"ROC-AUC (Test)\",\n",
    "]\n",
    "\n",
    "# Formatage pour affichage\n",
    "comparison_display[\"Recall (Test)\"] = comparison_display.apply(\n",
    "    lambda x: f\"{x['Recall (Test)']:.3f} ± {x['Recall Std']:.3f}\", axis=1\n",
    ")\n",
    "comparison_display = comparison_display.drop(\"Recall Std\", axis=1)\n",
    "\n",
    "print(\"COMPARAISON DES TECHNIQUES DE GESTION DU DÉSÉQUILIBRE\")\n",
    "print(\"\\nFocus sur la classe 'Parti' (classe minoritaire)\\n\")\n",
    "\n",
    "display(\n",
    "    comparison_display.style.highlight_max(\n",
    "        subset=[\"F1 (Test)\", \"ROC-AUC (Test)\"], color=\"green\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22.2 Visualisation graphique\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1 : Recall vs Precision (Trade-off)\n",
    "ax1 = axes[0]\n",
    "models = comparison_imbalance_df[\"model\"].values\n",
    "recalls = comparison_imbalance_df[\"recall_test_mean\"].values\n",
    "precisions = comparison_imbalance_df[\"precision_test_mean\"].values\n",
    "\n",
    "colors_plot = plt.cm.Set2(np.linspace(0, 1, len(models)))\n",
    "for i, (model, recall, precision) in enumerate(zip(models, recalls, precisions)):\n",
    "    ax1.scatter(\n",
    "        recall,\n",
    "        precision,\n",
    "        s=200,\n",
    "        c=[colors_plot[i]],\n",
    "        label=model,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "ax1.set_xlabel(\"Recall (Test)\", fontsize=12)\n",
    "ax1.set_ylabel(\"Precision (Test)\", fontsize=12)\n",
    "ax1.set_title(\"Trade-off Recall vs Precision\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.legend(loc=\"best\", fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Graphique 2 : F1-Score par modèle\n",
    "ax2 = axes[1]\n",
    "f1_scores = comparison_imbalance_df[\"f1_test_mean\"].values\n",
    "f1_stds = comparison_imbalance_df[\"f1_test_std\"].values\n",
    "\n",
    "bars = ax2.barh(\n",
    "    range(len(models)), f1_scores, xerr=f1_stds, color=colors_plot, edgecolor=\"black\"\n",
    ")\n",
    "ax2.set_yticks(range(len(models)))\n",
    "ax2.set_yticklabels(\n",
    "    [m.replace(\" + \", \"\\n+ \").replace(\" (\", \"\\n(\") for m in models], fontsize=9\n",
    ")\n",
    "ax2.set_xlabel(\"F1-Score (Test)\", fontsize=12)\n",
    "ax2.set_title(\"F1-Score par technique\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(True, alpha=0.3, axis=\"x\")\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, (bar, f1) in enumerate(zip(bars, f1_scores)):\n",
    "    ax2.text(\n",
    "        f1 + 0.02,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{f1:.3f}\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Visualisation des performances terminée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f56f12",
   "metadata": {},
   "source": [
    "### 20.3 Analyse des résultats\n",
    "\n",
    "| Technique                   | Avantages                                   | Inconvénients                     |\n",
    "| --------------------------- | ------------------------------------------- | --------------------------------- |\n",
    "| **class_weight='balanced'** | Simple, pas de preprocessing supplémentaire | Peut ne pas suffire seul          |\n",
    "| **SMOTE**                   | Génère des données synthétiques             | Risque d'overfitting, coût calcul |\n",
    "| **Undersampling**           | Réduit le temps d'entraînement              | Perte d'information               |\n",
    "| **Calibration**             | Probabilités plus fiables                   | Complexité additionnelle          |\n",
    "\n",
    "#### Observations :\n",
    "\n",
    "1. **Recall** : Les techniques de gestion du déséquilibre améliorent significativement le recall sur \"Parti\"\n",
    "2. **Trade-off** : Amélioration du recall souvent au détriment de la precision\n",
    "3. **F1-Score** : Compromis entre recall et precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c74354",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 21. Courbe Precision-Recall et seuil optimal\n",
    "\n",
    "### 21.1 Principe\n",
    "\n",
    "La courbe Precision-Recall permet de visualiser le trade-off et de choisir un seuil de décision optimal selon les priorités métier.\n",
    "\n",
    "### 21.2 Comment lire les graphiques\n",
    "\n",
    "**Graphique 1 - Courbe Precision-Recall :**\n",
    "\n",
    "- **Axe X** : Recall (proportion des vrais départs détectés)\n",
    "- **Axe Y** : Precision (proportion des alertes qui sont de vrais départs)\n",
    "- **Courbe bleue** : Trade-off precision/recall selon le seuil\n",
    "- **Lecture** : Plus l'aire sous la courbe (AP) est grande, meilleur est le modèle\n",
    "\n",
    "**Graphique 2 - F1-Score en fonction du seuil :**\n",
    "\n",
    "- **Axe X** : Seuil de décision (probabilité à partir de laquelle on prédit \"Parti\")\n",
    "- **Axe Y** : F1-Score correspondant\n",
    "- **Point rouge** : Seuil optimal qui maximise le F1\n",
    "- **Lecture** : Le seuil optimal (0.230) est bien inférieur à 0.5 → le modèle doit être plus \"sensible\"\n",
    "\n",
    "**Matrices de confusion :**\n",
    "\n",
    "- **Colonnes** : Prédictions du modèle (Resté / Parti)\n",
    "- **Lignes** : Réalité (Resté / Parti)\n",
    "- **Diagonale** : Prédictions correctes (Vrais Négatifs en haut-gauche, Vrais Positifs en bas-droite)\n",
    "- **Hors diagonale** : Erreurs (Faux Positifs en haut-droite, Faux Négatifs en bas-gauche)\n",
    "- **Lecture** : Comparer le nombre de Faux Négatifs entre les deux seuils (ce sont les départs manqués)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3628d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.2 Entraînement du meilleur modèle sur train/test fixe pour la courbe PR\n",
    "print(\"Entraînement du modèle pour la courbe Precision-Recall...\")\n",
    "\n",
    "# Utilisation du Random Forest avec class_weight='balanced' (meilleur compromis attendu)\n",
    "from sklearn.pipeline import Pipeline as SkPipeline  # noqa: E402\n",
    "\n",
    "pipeline_best = SkPipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "pipeline_best.fit(X_train, y_train)\n",
    "\n",
    "# Probabilités sur le test set\n",
    "y_test_proba = pipeline_best.predict_proba(X_test)\n",
    "# Index de la classe positive (1 = Parti/Churn)\n",
    "parti_idx = list(pipeline_best.classes_).index(1)\n",
    "y_test_proba_parti = y_test_proba[:, parti_idx]\n",
    "\n",
    "# y_test est déjà binaire (1 = Parti)\n",
    "y_test_binary = y_test.values\n",
    "\n",
    "print(\"Modèle entraîné\")\n",
    "print(f\"   Classes : {pipeline_best.classes_}\")\n",
    "print(f\"   Index classe positive (1=Parti) : {parti_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.3 Tracé de la courbe Precision-Recall\n",
    "precision_curve, recall_curve, thresholds = precision_recall_curve(\n",
    "    y_test_binary, y_test_proba_parti\n",
    ")\n",
    "ap_score = average_precision_score(y_test_binary, y_test_proba_parti)\n",
    "\n",
    "# Calcul du F1-score pour chaque seuil\n",
    "f1_scores = (\n",
    "    2\n",
    "    * (precision_curve[:-1] * recall_curve[:-1])\n",
    "    / (precision_curve[:-1] + recall_curve[:-1] + 1e-10)\n",
    ")\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "best_precision = precision_curve[best_threshold_idx]\n",
    "best_recall = recall_curve[best_threshold_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1 : Courbe Precision-Recall\n",
    "ax1 = axes[0]\n",
    "ax1.plot(\n",
    "    recall_curve,\n",
    "    precision_curve,\n",
    "    \"b-\",\n",
    "    linewidth=2,\n",
    "    label=f\"PR Curve (AP = {ap_score:.3f})\",\n",
    ")\n",
    "ax1.scatter(\n",
    "    [best_recall],\n",
    "    [best_precision],\n",
    "    s=200,\n",
    "    c=\"red\",\n",
    "    marker=\"*\",\n",
    "    zorder=5,\n",
    "    label=f\"Seuil optimal = {best_threshold:.3f}\",\n",
    ")\n",
    "ax1.axhline(\n",
    "    y=y_test_binary.mean(), color=\"gray\", linestyle=\"--\", label=\"Baseline (random)\"\n",
    ")\n",
    "ax1.set_xlabel(\"Recall\", fontsize=12)\n",
    "ax1.set_ylabel(\"Precision\", fontsize=12)\n",
    "ax1.set_title(\"Courbe Precision-Recall\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.legend(loc=\"best\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Graphique 2 : F1-Score en fonction du seuil\n",
    "ax2 = axes[1]\n",
    "ax2.plot(thresholds, f1_scores, \"g-\", linewidth=2)\n",
    "ax2.axvline(\n",
    "    x=best_threshold,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Seuil optimal = {best_threshold:.3f}\",\n",
    ")\n",
    "ax2.scatter([best_threshold], [best_f1], s=200, c=\"red\", marker=\"*\", zorder=5)\n",
    "ax2.set_xlabel(\"Seuil de décision\", fontsize=12)\n",
    "ax2.set_ylabel(\"F1-Score\", fontsize=12)\n",
    "ax2.set_title(\"F1-Score en fonction du seuil\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.legend(loc=\"best\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n SEUIL OPTIMAL IDENTIFIÉ\")\n",
    "print(f\"   Seuil : {best_threshold:.3f}\")\n",
    "print(f\"   Precision : {best_precision:.3f}\")\n",
    "print(f\"   Recall : {best_recall:.3f}\")\n",
    "print(f\"   F1-Score : {best_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.4 Application du seuil optimal et matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Prédictions avec le seuil par défaut (0.5)\n",
    "y_test_pred_default = pipeline_best.predict(X_test)\n",
    "\n",
    "# Prédictions avec le seuil optimal (en numérique: 1 = Parti, 0 = Resté)\n",
    "y_test_pred_optimal = np.where(y_test_proba_parti >= best_threshold, 1, 0)\n",
    "\n",
    "# Comparaison des matrices de confusion\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Seuil par défaut (labels numériques, display_labels pour l'affichage)\n",
    "cm_default = confusion_matrix(y_test, y_test_pred_default, labels=[0, 1])\n",
    "disp1 = ConfusionMatrixDisplay(cm_default, display_labels=[\"Resté\", \"Parti\"])\n",
    "disp1.plot(ax=axes[0], cmap=\"Blues\", values_format=\"d\")\n",
    "axes[0].set_title(\"Seuil par défaut (0.5)\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Seuil optimal\n",
    "cm_optimal = confusion_matrix(y_test, y_test_pred_optimal, labels=[0, 1])\n",
    "disp2 = ConfusionMatrixDisplay(cm_optimal, display_labels=[\"Resté\", \"Parti\"])\n",
    "disp2.plot(ax=axes[1], cmap=\"Greens\", values_format=\"d\")\n",
    "axes[1].set_title(\n",
    "    f\"Seuil optimal ({best_threshold:.3f})\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Métriques comparées\n",
    "print(\"\\n📊 COMPARAISON DES SEUILS\")\n",
    "print(f\"\\n{'Métrique':<20} {'Seuil 0.5':>15} {'Seuil optimal':>15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# pos_label=1 car 1 = Parti (classe positive)\n",
    "recall_default = recall_score(y_test, y_test_pred_default, pos_label=1)\n",
    "recall_optimal = recall_score(y_test, y_test_pred_optimal, pos_label=1)\n",
    "print(f\"{'Recall (Parti)':<20} {recall_default:>15.3f} {recall_optimal:>15.3f}\")\n",
    "\n",
    "precision_default = precision_score(\n",
    "    y_test, y_test_pred_default, pos_label=1, zero_division=0\n",
    ")\n",
    "precision_optimal = precision_score(\n",
    "    y_test, y_test_pred_optimal, pos_label=1, zero_division=0\n",
    ")\n",
    "print(\n",
    "    f\"{'Precision (Parti)':<20} {precision_default:>15.3f} {precision_optimal:>15.3f}\"\n",
    ")\n",
    "\n",
    "f1_default = f1_score(y_test, y_test_pred_default, pos_label=1)\n",
    "f1_optimal = f1_score(y_test, y_test_pred_optimal, pos_label=1)\n",
    "print(f\"{'F1-Score (Parti)':<20} {f1_default:>15.3f} {f1_optimal:>15.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635763f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 4 : Gestion du déséquilibre des classes\n",
    "\n",
    "### Résultats comparatifs des techniques\n",
    "\n",
    "| Technique                          | Recall    | Precision | F1-Score  | ROC-AUC   |\n",
    "| ---------------------------------- | --------- | --------- | --------- | --------- |\n",
    "| **Logistic Regression (balanced)** | **0.722** | 0.379     | **0.497** | **0.828** |\n",
    "| Random Forest (balanced)           | 0.131     | 0.896     | 0.225     | 0.812     |\n",
    "| Random Forest + SMOTE              | 0.261     | 0.699     | 0.374     | 0.820     |\n",
    "| Random Forest + Undersampling      | 0.696     | 0.356     | 0.471     | 0.806     |\n",
    "| RF (balanced + calibrated)         | 0.282     | 0.728     | 0.392     | 0.809     |\n",
    "\n",
    "**Meilleur modèle** : **Logistic Regression avec class_weight='balanced'** (F1=0.497, Recall=72.2%, ROC-AUC=0.828)\n",
    "\n",
    "### Découverte majeure : Optimisation du seuil de décision\n",
    "\n",
    "Le **seuil de décision optimal (0.230)** apporte une amélioration spectaculaire :\n",
    "\n",
    "| Métrique      | Seuil 0.5 (défaut) | Seuil 0.230 (optimal) | Amélioration |\n",
    "| ------------- | ------------------ | --------------------- | ------------ |\n",
    "| **Recall**    | 0.085              | **0.638**             | +650%        |\n",
    "| **Precision** | 0.444              | 0.484                 | +9%          |\n",
    "| **F1-Score**  | 0.143              | **0.550**             | +285%        |\n",
    "\n",
    "**Impact concret** :\n",
    "\n",
    "- Seuil 0.5 → Détecte seulement **4 départs sur 47** (91.5% manqués ❌)\n",
    "- Seuil 0.230 → Détecte **30 départs sur 47** (36.2% manqués ✅)\n",
    "\n",
    "### Conclusions clés\n",
    "\n",
    "1. **Logistic Regression > Random Forest** pour ce problème (meilleur F1 et recall)\n",
    "2. **L'ajustement du seuil** est plus efficace que SMOTE ou Undersampling\n",
    "3. **Undersampling** donne le meilleur recall brut (0.696) mais perd en precision\n",
    "4. **Random Forest** tend à l'overfitting (train=100%, test beaucoup plus bas)\n",
    "\n",
    "### 📋 Recommandations pour TechNova Partners\n",
    "\n",
    "| Stratégie RH                                 | Seuil     | Conséquence                                        |\n",
    "| -------------------------------------------- | --------- | -------------------------------------------------- |\n",
    "| **Détection maximale** (coût turnover élevé) | 0.15-0.20 | Plus de fausses alertes, moins de départs manqués  |\n",
    "| **Équilibre** (recommandé)                   | **0.230** | F1 optimal (0.550), bon compromis                  |\n",
    "| **Actions ciblées** (ressources limitées)    | 0.40-0.50 | Alertes très fiables mais certains départs manqués |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188002a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Partie 5 : Fine-tuning et Interprétabilité (SHAP)\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. **Fine-tuning** : Optimiser les hyperparamètres avec GridSearchCV\n",
    "2. **Comparaison de modèles** : Random Forest vs LightGBM, class_weight balanced vs non\n",
    "3. **Calibration des probabilités** : CalibratedClassifierCV pour des probabilités plus fiables\n",
    "4. **Vérification des probabilités** : S'assurer qu'on obtient bien des valeurs proches de 0 et 1\n",
    "5. **SHAP** : Interprétabilité globale (Beeswarm) et locale (Waterfall)\n",
    "\n",
    "### Pourquoi SHAP ?\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est basé sur la **théorie des jeux** de Lloyd Shapley (Prix Nobel d'économie 2012).\n",
    "\n",
    "- **Mathématiquement juste** : C'est la seule méthode qui satisfait toutes les propriétés d'équité\n",
    "- **Interprétable** : Permet de comprendre l'impact de chaque feature sur la prédiction\n",
    "- **Fiable** : Plus robuste que LIME ou d'autres méthodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179d80a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 22. Imports et préparation Partie 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Installation de LightGBM et SHAP si nécessaire\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    print(\"✅ LightGBM importé\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ LightGBM non installé\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "\n",
    "    print(\"✅ SHAP importé\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ SHAP non installé\")\n",
    "\n",
    "print(\"\\nImports Partie 5 chargés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a15638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28.1 GridSearchCV sur LightGBM (meilleur compromis généralement)\n",
    "print(\"FINE-TUNING AVEC GRIDSEARCHCV\")\n",
    "\n",
    "# Pipeline avec preprocessing\n",
    "pipeline_lgb = SkPipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", lgb.LGBMClassifier(random_state=42, verbose=-1, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_depth\": [3, 5, 7, None],\n",
    "    \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "    \"classifier__num_leaves\": [15, 31, 63],\n",
    "}\n",
    "\n",
    "# Scorer personnalisé (F1 sur classe positive)\n",
    "\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# GridSearchCV avec validation croisée stratifiée\n",
    "print(\"\\n🔄 Recherche des meilleurs hyperparamètres (peut prendre quelques minutes)...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_lgb,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Meilleurs paramètres trouvés:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\n📊 Meilleur score F1 (CV): {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions avec le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "y_proba_optimized = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "print(\"\\nMétriques sur le jeu de test:\")\n",
    "print(f\"   Recall:     {recall_score(y_test, y_pred_optimized, pos_label=1):.3f}\")\n",
    "print(\n",
    "    f\"   Precision:  {precision_score(y_test, y_pred_optimized, pos_label=1, zero_division=0):.3f}\"\n",
    ")\n",
    "print(f\"   F1-Score:   {f1_score(y_test, y_pred_optimized, pos_label=1):.3f}\")\n",
    "print(f\"   ROC-AUC:    {roc_auc_score(y_test, y_proba_optimized):.3f}\")\n",
    "\n",
    "# Vérification des probabilités\n",
    "print(\"\\nDistribution des probabilités:\")\n",
    "print(f\"   Min: {y_proba_optimized.min():.4f}\")\n",
    "print(f\"   Max: {y_proba_optimized.max():.4f}\")\n",
    "print(f\"   Mean: {y_proba_optimized.mean():.4f}\")\n",
    "print(f\"   Proba > 0.9: {(y_proba_optimized > 0.9).sum()} observations\")\n",
    "print(f\"   Proba >= 0.99: {(y_proba_optimized >= 0.99).sum()} observations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699de05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 23. Interprétabilité avec SHAP\n",
    "\n",
    "### Pourquoi SHAP ?\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est basé sur les **valeurs de Shapley** de la théorie des jeux :\n",
    "\n",
    "- **Mathématiquement juste** : Seule méthode qui respecte toutes les propriétés d'équité (efficacité, symétrie, linéarité, nullité)\n",
    "- **Interprétable** : Chaque feature reçoit une \"contribution\" à la prédiction\n",
    "- **Global et local** : Permet de comprendre le modèle dans son ensemble ET chaque prédiction individuelle\n",
    "\n",
    "### Types d'analyses\n",
    "\n",
    "1. **Beeswarm Plot** (global) : Vue d'ensemble de l'importance de chaque feature\n",
    "2. **Permutation Importance** (global) : Comparaison avec méthode sklearn\n",
    "3. **Waterfall Plot** (local) : Explication d'une prédiction individuelle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc00a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le preprocessor et le classifier du meilleur modèle\n",
    "preprocessor_fitted = best_model.named_steps[\"preprocessor\"]\n",
    "classifier_fitted = best_model.named_steps[\"classifier\"]\n",
    "\n",
    "# Transformer les données de test\n",
    "X_test_transformed = preprocessor_fitted.transform(X_test)\n",
    "\n",
    "# Récupérer les noms des features après transformation\n",
    "# Note: get_feature_names_out() sans argument utilise les noms appris lors du fit\n",
    "cat_feature_names = (\n",
    "    preprocessor_fitted.named_transformers_[\"cat\"].get_feature_names_out().tolist()\n",
    ")\n",
    "num_feature_names = numeric_cols.copy()\n",
    "all_feature_names = num_feature_names + cat_feature_names\n",
    "\n",
    "print(f\"Nombre de features après transformation: {len(all_feature_names)}\")\n",
    "print(f\"   - Features numériques: {len(num_feature_names)}\")\n",
    "print(f\"   - Features catégorielles (après OHE): {len(cat_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calcul des SHAP values (TreeExplainer pour LightGBM)...\")\n",
    "\n",
    "# TreeExplainer est optimisé pour les modèles à base d'arbres\n",
    "explainer = shap.TreeExplainer(classifier_fitted)\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Pour classification binaire, shap_values peut être une liste [classe_0, classe_1]\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]  # On prend la classe positive (Parti)\n",
    "\n",
    "print(\"SHAP values calculées\")\n",
    "print(f\"   Shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ce598",
   "metadata": {},
   "source": [
    "### 23.1 Feature Importance Globale - Beeswarm Plot\n",
    "\n",
    "Le **Beeswarm Plot** montre :\n",
    "\n",
    "- **Axe Y** : Les features triées par importance\n",
    "- **Axe X** : L'impact sur la prédiction (SHAP value)\n",
    "- **Couleur** : La valeur de la feature (rouge = élevée, bleu = basse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5eee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SHAP BEESWARM PLOT - IMPORTANCE GLOBALE\")\n",
    "\n",
    "# Créer un DataFrame avec les noms de features\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_test_df, plot_type=\"dot\", show=False, max_display=20)\n",
    "plt.title(\n",
    "    \"SHAP Beeswarm Plot - Impact des features sur la probabilité de départ\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterprétation:\")\n",
    "print(\"   - Plus une feature est haute, plus elle impacte la prédiction\")\n",
    "print(\"   - Rouge = valeur élevée de la feature, Bleu = valeur basse\")\n",
    "print(\"   - Points à droite = augmentent la probabilité de départ\")\n",
    "print(\"   - Points à gauche = diminuent la probabilité de départ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f4017",
   "metadata": {},
   "source": [
    "### 23.2 Feature Importance Locale - Waterfall Plot\n",
    "\n",
    "Le **Waterfall Plot** explique UNE prédiction individuelle :\n",
    "\n",
    "- Comment chaque feature a contribué à passer de la valeur de base (moyenne) à la prédiction finale\n",
    "- Utile pour expliquer une décision à un manager RH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daade1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver des exemples intéressants\n",
    "# 1. Un employé prédit comme \"Parti\" avec haute confiance (y_pred=1, proba élevée)\n",
    "# 2. Un employé prédit comme \"Resté\" avec haute confiance\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Indices des vrais positifs (Parti correctement prédit)\n",
    "true_positives = np.where((y_test == 1) & (y_pred_test == 1))[0]\n",
    "# Indices des vrais négatifs (Resté correctement prédit)\n",
    "true_negatives = np.where((y_test == 0) & (y_pred_test == 0))[0]\n",
    "\n",
    "print(\"\\nExemples disponibles:\")\n",
    "print(f\"   Vrais Positifs (Parti bien prédit): {len(true_positives)}\")\n",
    "print(f\"   Vrais Négatifs (Resté bien prédit): {len(true_negatives)}\")\n",
    "\n",
    "# Créer un objet Explanation pour les waterfall plots\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values,\n",
    "    base_values=np.full(\n",
    "        len(shap_values),\n",
    "        explainer.expected_value\n",
    "        if not hasattr(explainer.expected_value, \"__len__\")\n",
    "        else explainer.expected_value[1],\n",
    "    ),\n",
    "    data=X_test_transformed,\n",
    "    feature_names=all_feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.7 Waterfall - Exemple d'un employé \"Parti\" (classe 1)\n",
    "if len(true_positives) > 0:\n",
    "    idx_parti = true_positives[0]\n",
    "    proba_parti = y_proba_optimized[idx_parti]\n",
    "\n",
    "    print(\"\\nEXEMPLE 1: Employé PARTI (correctement prédit)\")\n",
    "    print(f\"   Index: {idx_parti}\")\n",
    "    print(f\"   Probabilité de départ: {proba_parti:.3f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.plots.waterfall(explanation[idx_parti], max_display=15, show=False)\n",
    "    plt.title(\n",
    "        f\"Waterfall Plot - Employé Parti (proba={proba_parti:.3f})\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Aucun vrai positif trouvé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30c2d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 5 : Fine-tuning et Interprétabilité\n",
    "\n",
    "### Comparaison des modèles (test set)\n",
    "\n",
    "| Modèle | class_weight | Recall | Precision | F1 | ROC-AUC | Proba Range |\n",
    "|--------|--------------|--------|-----------|-----|---------|-------------|\n",
    "| Random Forest | None | 0.064 | 0.375 | 0.109 | 0.782 | [0.00, 0.88] |\n",
    "| Random Forest | balanced | 0.085 | 0.444 | 0.143 | 0.797 | [0.00, 0.81] |\n",
    "| LightGBM | None | 0.234 | 0.550 | 0.328 | 0.786 | [0.00, 0.99] |\n",
    "| LightGBM | balanced | 0.298 | 0.424 | 0.350 | 0.798 | [0.00, 1.00] |\n",
    "| **LightGBM (GridSearchCV)** | **balanced** | **0.511** | **0.436** | **0.471** | **0.800** | **[0.00, 1.00]** |\n",
    "\n",
    "### 🔧 Meilleurs hyperparamètres (GridSearchCV)\n",
    "\n",
    "```\n",
    "learning_rate: 0.1\n",
    "max_depth: 3\n",
    "n_estimators: 200\n",
    "num_leaves: 15\n",
    "class_weight: balanced\n",
    "```\n",
    "\n",
    "### Observations clés\n",
    "\n",
    "1. **class_weight='balanced'** améliore le recall de +27% (RF: 0.064→0.085, LGB: 0.234→0.298)\n",
    "2. **LightGBM surpasse Random Forest** : F1 de 0.350 vs 0.143 (avec balanced)\n",
    "3. **GridSearchCV** améliore le recall de 0.298 à **0.511** (+71%)\n",
    "4. **Probabilités calibrées** : après calibration, les probabilités atteignent 1.0 (vs 0.99 avant)\n",
    "\n",
    "### SHAP - Top 5 Features les plus impactantes\n",
    "\n",
    "1. **heure_supplementaires_Oui** - Faire des heures sup **augmente fortement** le risque de départ\n",
    "2. **revenu_mensuel** - Un salaire **bas** augmente le risque de départ\n",
    "3. **satisfaction_employee_equilibre_pro_perso** - Faible équilibre vie pro/perso → risque accru\n",
    "4. **annes_sous_responsable_actuel** - Peu d'années sous le même manager → risque accru\n",
    "5. **nombre_participation_pee** - Faible participation au PEE → risque accru\n",
    "\n",
    "### Comparaison SHAP vs Permutation Importance\n",
    "\n",
    "**5 features communes dans le Top 10** des deux méthodes :\n",
    "- `heure_supplementaires_Oui`\n",
    "- `satisfaction_employee_equilibre_pro_perso`\n",
    "- `frequence_deplacement_Frequent`\n",
    "- `nombre_participation_pee`\n",
    "- `annes_sous_responsable_actuel`\n",
    "\n",
    "**Pourquoi SHAP ?** SHAP est basé sur les **valeurs de Shapley** issues de la théorie des jeux. Il garantit une répartition **équitable et mathématiquement juste** de la contribution de chaque feature à la prédiction, contrairement à d'autres méthodes d'interprétabilité.\n",
    "\n",
    "### Recommandations métier pour TechNova Partners\n",
    "\n",
    "1. **Heures supplémentaires** : Mettre en place un suivi strict et limiter les heures sup récurrentes\n",
    "2. **Politique salariale** : Réviser les grilles de salaires pour les employés sous-payés\n",
    "3. **Équilibre vie pro/perso** : Proposer du télétravail, horaires flexibles\n",
    "4. **Stabilité managériale** : Accompagner les changements de responsable\n",
    "5. **Engagement financier** : Promouvoir le Plan Épargne Entreprise (PEE)\n",
    "\n",
    "### Conclusion générale\n",
    "\n",
    "Le modèle **LightGBM optimisé** permet de :\n",
    "- **Identifier** les employés à risque de départ avec un **Recall de 51.1%** (seuil par défaut)\n",
    "- **Comprendre** les facteurs de départ grâce à **SHAP** (heures sup, salaire, équilibre pro/perso)\n",
    "- **Prioriser** les actions RH avec des **probabilités calibrées** (range 0-100%)\n",
    "- **Amélioration potentielle** : ajuster le seuil de décision pour augmenter le recall si nécessaire\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technova-attrition-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
