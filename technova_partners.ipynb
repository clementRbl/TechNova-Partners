{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4086c666",
   "metadata": {},
   "source": [
    "# TechNova Partners - Analyse du Churn RH\n",
    "\n",
    "**Projet :** Identification des causes de démission et modélisation prédictive  \n",
    "**Client :** TechNova Partners (ESN spécialisée en transformation digitale)\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte du Projet\n",
    "\n",
    "TechNova Partners fait face à un turnover élevé. L'objectif est de :\n",
    "\n",
    "1. **Analyser** les données RH pour identifier les différences entre employés partis et restés\n",
    "2. **Construire** un modèle de classification pour prédire les démissions\n",
    "3. **Extraire** les causes potentielles via l'interprétation du modèle (SHAP)\n",
    "\n",
    "**Sources de données :**\n",
    "\n",
    "- `data/extrait_sirh.csv` - Informations RH (âge, salaire, poste, ancienneté...)\n",
    "- `data/extrait_eval.csv` - Évaluations de performance\n",
    "- `data/extrait_sondage.csv` - Sondage employés + **variable cible**\n",
    "\n",
    "---\n",
    "\n",
    "## Structure du Notebook\n",
    "\n",
    "**Partie 1 : Exploration des Données**\n",
    "\n",
    "- Chargement et compréhension des fichiers\n",
    "- Fusion et création du dataset central\n",
    "- Analyse exploratoire et visualisations\n",
    "\n",
    "**Partie 2 : Feature Engineering**\n",
    "\n",
    "- Préparation des features (X)\n",
    "- Encodage des variables catégorielles\n",
    "- Gestion des corrélations\n",
    "\n",
    "**Partie 3 : Modélisation Baseline**\n",
    "\n",
    "- Modèle Dummy (référence)\n",
    "- Modèle linéaire\n",
    "- Modèle non-linéaire (arbre)\n",
    "\n",
    "**Partie 4 : Gestion du Déséquilibre**\n",
    "\n",
    "- Stratification\n",
    "- Class weights / Undersampling / Oversampling (SMOTE)\n",
    "- Calibration de probabilité\n",
    "- Validation croisée stratifiée\n",
    "\n",
    "**Partie 5 : Optimisation et Interpretation**\n",
    "\n",
    "- Fine-tuning des hyperparamètres\n",
    "- Feature importance globale (SHAP, Permutation)\n",
    "- Feature importance locale (SHAP Waterfall)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a5ad0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Importation des librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dba98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b0aaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Chargement des données\n",
    "\n",
    "Chargement des 3 fichiers CSV et examen de structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a584d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh = pd.read_csv(\"data/extrait_sirh.csv\")\n",
    "df_eval = pd.read_csv(\"data/extrait_eval.csv\")\n",
    "df_sondage = pd.read_csv(\"data/extrait_sondage.csv\")\n",
    "\n",
    "print(f\"Fichier SIRH : {df_sirh.shape[0]} lignes, {df_sirh.shape[1]} colonnes\")\n",
    "print(f\"Fichier Évaluations : {df_eval.shape[0]} lignes, {df_eval.shape[1]} colonnes\")\n",
    "print(f\"Fichier Sondage : {df_sondage.shape[0]} lignes, {df_sondage.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859bfec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Exploration initiale de chaque fichier\n",
    "\n",
    "Avant de fusionner, comprenons le contenu et la structure de chaque fichier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cd45c",
   "metadata": {},
   "source": [
    "### 3.1 Fichier SIRH (extrait_sirh.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f0021",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n",
    "\n",
    "Visualisons les premières lignes pour comprendre la structure et le contenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1555732",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n",
    "\n",
    "Analysons les types de colonnes, la mémoire utilisée et les valeurs non-nulles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461b88d",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n",
    "\n",
    "Calculons les statistiques de base (moyenne, écart-type, min, max, quartiles) pour les variables numériques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sirh.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ab8be",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n",
    "\n",
    "Examinons les valeurs uniques et leur fréquence pour chaque variable catégorielle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valeurs uniques des colonnes catégorielles SIRH :\")\n",
    "for col in df_sirh.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_sirh[col].nunique()} valeurs uniques\")\n",
    "    print(df_sirh[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79318fd",
   "metadata": {},
   "source": [
    "### 3.2 Fichier Évaluations (extrait_eval.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11411bc9",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a667e",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16286df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928a9b5",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistiques descriptives Evaluations (variables numeriques) :\")\n",
    "df_eval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca31359",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs uniques des colonnes catégorielles\n",
    "print(\"Valeurs uniques des colonnes catégorielles Evaluations :\")\n",
    "for col in df_eval.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_eval[col].nunique()} valeurs uniques\")\n",
    "    print(df_eval[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d33eff",
   "metadata": {},
   "source": [
    "### 3.3 Fichier Sondage (extrait_sondage.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e8e4d",
   "metadata": {},
   "source": [
    "#### Aperçu des premières lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403c29a",
   "metadata": {},
   "source": [
    "#### Structure et types de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579a95a",
   "metadata": {},
   "source": [
    "#### Statistiques descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb217995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sondage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a13eaf",
   "metadata": {},
   "source": [
    "#### Analyse des variables catégorielles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sondage.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {df_sondage[col].nunique()} valeurs uniques\")\n",
    "    print(df_sondage[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8635855",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Identification des clés de jointure\n",
    "\n",
    "Pour fusionner les 3 fichiers, nous devons identifier les colonnes qui permettent de faire le lien entre eux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67bf0e",
   "metadata": {},
   "source": [
    "#### Analyse des colonnes identifiantes\n",
    "\n",
    "Examinons les colonnes qui nous permettront de faire les jointures entre fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonnes SIRH :\")\n",
    "print(df_sirh.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'id_employee' : {df_sirh['id_employee'].nunique()} valeurs uniques sur {len(df_sirh)} lignes\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nColonnes Évaluations :\")\n",
    "print(df_eval.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'eval_number' : {df_eval['eval_number'].nunique()} valeurs uniques sur {len(df_eval)} lignes\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nColonnes Sondage :\")\n",
    "print(df_sondage.columns.tolist())\n",
    "print(\n",
    "    f\"\\nClé potentielle 'code_sondage' : {df_sondage['code_sondage'].nunique()} valeurs uniques sur {len(df_sondage)} lignes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9872483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysons le format des clés pour comprendre comment les relier\n",
    "print(\"Exemples de clés :\")\n",
    "print(f\"\\nSIRH - id_employee (premiers) : {df_sirh['id_employee'].head(10).tolist()}\")\n",
    "print(f\"\\nEval - eval_number (premiers) : {df_eval['eval_number'].head(10).tolist()}\")\n",
    "print(\n",
    "    f\"\\nSondage - code_sondage (premiers) : {df_sondage['code_sondage'].head(10).tolist()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199f363",
   "metadata": {},
   "source": [
    "#### Analyse du format des clés\n",
    "\n",
    "Regardons de plus près comment sont structurées ces clés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparaison du nombre de lignes :\")\n",
    "print(f\"  - SIRH : {len(df_sirh)} lignes\")\n",
    "print(f\"  - Évaluations : {len(df_eval)} lignes\")\n",
    "print(f\"  - Sondage : {len(df_sondage)} lignes\")\n",
    "\n",
    "# Si tous les fichiers ont le même nombre de lignes,\n",
    "# ils correspondent probablement aux mêmes employés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828de03",
   "metadata": {},
   "source": [
    "#### Vérification de la cohérence des données\n",
    "\n",
    "Comparons le nombre de lignes pour détecter d'éventuels problèmes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recherche de colonnes communes entre les fichiers :\\n\")\n",
    "\n",
    "sirh_cols = set(df_sirh.columns)\n",
    "eval_cols = set(df_eval.columns)\n",
    "sondage_cols = set(df_sondage.columns)\n",
    "\n",
    "print(f\"SIRH ∩ Évaluations : {sirh_cols.intersection(eval_cols)}\")\n",
    "print(f\"SIRH ∩ Sondage : {sirh_cols.intersection(sondage_cols)}\")\n",
    "print(f\"Évaluations ∩ Sondage : {eval_cols.intersection(sondage_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if not sirh_cols.intersection(eval_cols) and not sirh_cols.intersection(sondage_cols):\n",
    "    print(\"Résultat : Aucune colonne commune détectée\")\n",
    "    print(\"Les 3 fichiers ont des colonnes strictement différentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2fdca",
   "metadata": {},
   "source": [
    "#### Comparaison visuelle des clés\n",
    "\n",
    "Analysons la structure des clés pour identifier leur correspondance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dcf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparaison visuelle des premières valeurs de chaque clé :\\n\")\n",
    "\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id_employee\": df_sirh[\"id_employee\"].head(10),\n",
    "        \"eval_number\": df_eval[\"eval_number\"].head(10),\n",
    "        \"code_sondage\": df_sondage[\"code_sondage\"].head(10),\n",
    "    }\n",
    ")\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Observation : Les 3 clés suivent un pattern cohérent\")\n",
    "print(\"  - id_employee : valeurs numériques (1, 2, 3...)\")\n",
    "print(\"  - eval_number : format 'E_X' où X correspond à id_employee\")\n",
    "print(\"  - code_sondage : même valeur que id_employee\")\n",
    "print(\"\\nConclusion : Les lignes sont alignées par leur position (index)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9a3e0",
   "metadata": {},
   "source": [
    "#### Conclusion : Stratégie de fusion\n",
    "\n",
    "**Constat :**\n",
    "\n",
    "- Aucune colonne commune entre les 3 fichiers\n",
    "- Même nombre de lignes (1470) dans chaque fichier\n",
    "- Les clés suivent un pattern cohérent suggérant un alignement par index\n",
    "- Chaque fichier contient des informations complémentaires :\n",
    "  - SIRH → infos administratives (ancienneté, salaire, département...)\n",
    "  - Évaluations → métriques de performance (notes, satisfaction...)\n",
    "  - Sondage → perception des employés (stress, équilibre vie pro/perso...)\n",
    "\n",
    "**Stratégie retenue :**\n",
    "\n",
    "Concaténation horizontale par index avec `pd.concat([df_sirh, df_eval, df_sondage], axis=1)`\n",
    "\n",
    "**Justification :**\n",
    "\n",
    "- Les lignes sont déjà alignées (id_employee=1 ↔ eval_number=\"E_1\" ↔ code_sondage=1)\n",
    "- Pas besoin de jointure SQL complexe\n",
    "- Les colonnes identifiantes seront conservées pour traçabilité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a01f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Fusion des données\n",
    "\n",
    "Création du DataFrame central en fusionnant les 3 sources par concaténation horizontale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6ff60",
   "metadata": {},
   "source": [
    "#### Création du DataFrame central\n",
    "\n",
    "Fusion des 3 fichiers par concaténation horizontale (axis=1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_sirh, df_eval, df_sondage], axis=1)\n",
    "\n",
    "print(\"DataFrame fusionné créé :\")\n",
    "print(f\"  - {df_merged.shape[0]} lignes\")\n",
    "print(f\"  - {df_merged.shape[1]} colonnes\")\n",
    "print(f\"\\nColonnes : {df_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834aa13",
   "metadata": {},
   "source": [
    "#### Gestion des colonnes dupliquées\n",
    "\n",
    "Vérification et suppression des éventuelles colonnes en double.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des colonnes dupliquées\n",
    "duplicated_cols = df_merged.columns[df_merged.columns.duplicated()].tolist()\n",
    "\n",
    "if duplicated_cols:\n",
    "    print(f\"{len(duplicated_cols)} colonne(s) dupliquée(s) détectée(s) :\")\n",
    "    for col in duplicated_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Suppression des doublons (on garde la première occurrence)\n",
    "    df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\n",
    "    print(\"\\nColonnes dupliquées supprimées\")\n",
    "    print(f\"Nouvelles dimensions : {df_merged.shape}\")\n",
    "else:\n",
    "    print(\"Aucune colonne dupliquée détectée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5fca7",
   "metadata": {},
   "source": [
    "#### Aperçu du DataFrame central\n",
    "\n",
    "Visualisation des premières lignes du dataset fusionné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05128d7c",
   "metadata": {},
   "source": [
    "#### Structure du DataFrame fusionné\n",
    "\n",
    "Informations sur les types de données et la mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a48f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a229f",
   "metadata": {},
   "source": [
    "#### Analyse de la variable cible\n",
    "\n",
    "Distribution de `a_quitte_l_entreprise` - la variable à prédire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9daf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variable cible - 'a_quitte_l_entreprise' :\")\n",
    "print(f\"Type : {df_merged['a_quitte_l_entreprise'].dtype}\")\n",
    "print(\"\\nDistribution :\")\n",
    "print(df_merged[\"a_quitte_l_entreprise\"].value_counts())\n",
    "print(\"\\nProportions (%) :\")\n",
    "print((df_merged[\"a_quitte_l_entreprise\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Comptage\n",
    "df_merged[\"a_quitte_l_entreprise\"].value_counts().plot(\n",
    "    kind=\"bar\", ax=ax[0], color=[\"#2ecc71\", \"#e74c3c\"]\n",
    ")\n",
    "ax[0].set_title(\"Distribution de la variable cible\", fontsize=12, fontweight=\"bold\")\n",
    "ax[0].set_xlabel(\"A quitté l'entreprise\")\n",
    "ax[0].set_ylabel(\"Nombre d'employés\")\n",
    "ax[0].set_xticklabels([\"Non\", \"Oui\"], rotation=0)\n",
    "\n",
    "# Proportions\n",
    "df_merged[\"a_quitte_l_entreprise\"].value_counts().plot(\n",
    "    kind=\"pie\",\n",
    "    ax=ax[1],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[\"#2ecc71\", \"#e74c3c\"],\n",
    "    labels=[\"Restés\", \"Partis\"],\n",
    ")\n",
    "ax[1].set_title(\"Proportions\", fontsize=12, fontweight=\"bold\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"OBSERVATION CRITIQUE : Déséquilibre des classes !\")\n",
    "print(\"     → À gérer en modélisation (stratification, class_weights, SMOTE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab20774",
   "metadata": {},
   "source": [
    "#### Synthèse : Variable cible\n",
    "\n",
    "- **84% restés** vs **16% partis** → Ratio 5:1\n",
    "- Déséquilibre à gérer : stratification, class_weight, resampling, calibration\n",
    "- Accuracy insuffisante comme métrique (84% sans rien faire)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb775a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Vue d'ensemble du dataset central\n",
    "\n",
    "Avant de comparer les employés partis vs restés, vérifions la qualité et la structure des données :\n",
    "\n",
    "- Valeurs manquantes\n",
    "- Types de colonnes (numériques vs catégorielles)\n",
    "- Colonnes identifiantes à exclure de l'analyse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ef20",
   "metadata": {},
   "source": [
    "#### Analyse des valeurs manquantes\n",
    "\n",
    "Vérifions s'il y a des données manquantes dans le dataset fusionné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "print(\"Analyse des valeurs manquantes :\\n\")\n",
    "\n",
    "missing_values = df_merged.isnull().sum()\n",
    "missing_pct = (df_merged.isnull().sum() / len(df_merged) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame(\n",
    "    {\"Valeurs manquantes\": missing_values, \"Pourcentage (%)\": missing_pct}\n",
    ")\n",
    "\n",
    "# Afficher seulement les colonnes avec des valeurs manquantes\n",
    "missing_with_values = missing_df[missing_df[\"Valeurs manquantes\"] > 0]\n",
    "\n",
    "if len(missing_with_values) > 0:\n",
    "    print(f\"{len(missing_with_values)} colonne(s) avec des valeurs manquantes :\")\n",
    "    print(missing_with_values.sort_values(\"Pourcentage (%)\", ascending=False))\n",
    "else:\n",
    "    print(\"Aucune valeur manquante dans le dataset !\")\n",
    "    print(f\"   → {df_merged.shape[0]} lignes × {df_merged.shape[1]} colonnes complètes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018e0d7",
   "metadata": {},
   "source": [
    "#### Classification des colonnes par type\n",
    "\n",
    "Identifions les colonnes numériques et catégorielles pour orienter l'analyse exploratoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f358b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification des colonnes par type :\\n\")\n",
    "\n",
    "# Colonnes identifiantes (à exclure de l'analyse)\n",
    "id_cols = [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "\n",
    "# Variable cible\n",
    "target_col = \"a_quitte_l_entreprise\"\n",
    "\n",
    "# Colonnes numériques (excluant les IDs)\n",
    "numeric_cols = df_merged.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in id_cols + [target_col]]\n",
    "\n",
    "# Colonnes catégorielles\n",
    "categorical_cols = df_merged.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols = [\n",
    "    col for col in categorical_cols if col not in id_cols + [target_col]\n",
    "]\n",
    "\n",
    "print(f\"Colonnes identifiantes ({len(id_cols)}) - À EXCLURE :\")\n",
    "print(f\"   {id_cols}\\n\")\n",
    "\n",
    "print(\"Variable cible :\")\n",
    "print(f\"   {target_col}\\n\")\n",
    "\n",
    "print(f\"Colonnes numériques ({len(numeric_cols)}) :\")\n",
    "print(f\"   {numeric_cols}\\n\")\n",
    "\n",
    "print(f\"Colonnes catégorielles ({len(categorical_cols)}) :\")\n",
    "print(f\"   {categorical_cols}\")\n",
    "\n",
    "print(f\"Total features analysables : {len(numeric_cols) + len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3001d5e",
   "metadata": {},
   "source": [
    "#### Résumé structuré du dataset\n",
    "\n",
    "Tableau récapitulatif avec le type, les valeurs uniques et des exemples pour chaque colonne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f860ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for col in df_merged.columns:\n",
    "    if col in id_cols:\n",
    "        category = \"Identifiant\"\n",
    "    elif col == target_col:\n",
    "        category = \"Cible\"\n",
    "    elif col in numeric_cols:\n",
    "        category = \"Numérique\"\n",
    "    else:\n",
    "        category = \"Catégorielle\"\n",
    "\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Colonne\": col,\n",
    "            \"Catégorie\": category,\n",
    "            \"Type\": str(df_merged[col].dtype),\n",
    "            \"Valeurs uniques\": df_merged[col].nunique(),\n",
    "            \"Exemple\": str(df_merged[col].iloc[0])[:30],\n",
    "        }\n",
    "    )\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6fd0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analyse exploratoire comparative : Partis vs Restés\n",
    "\n",
    "Objectif principal de cette section : **identifier les différences clés** entre les employés ayant quitté l'entreprise et ceux qui y sont restés.\n",
    "\n",
    "Nous utiliserons **Plotly** pour des graphiques interactifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343e5e7",
   "metadata": {},
   "source": [
    "#### Import de Plotly et préparation des données\n",
    "\n",
    "Configuration de Plotly et création d'une colonne lisible pour la variable cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c74251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"statut\"] = df_merged[\"a_quitte_l_entreprise\"].map(\n",
    "    {\"Oui\": \"Parti\", \"Non\": \"Resté\"}\n",
    ")\n",
    "\n",
    "colors = {\"Resté\": \"#2ecc71\", \"Parti\": \"#e74c3c\"}\n",
    "\n",
    "print(f\"   Distribution : {df_merged['statut'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356fc251",
   "metadata": {},
   "source": [
    "### 7.1 Analyse des variables numériques\n",
    "\n",
    "Comparons les **moyennes** des variables numériques entre les employés partis et restés avec un graphique unique et lisible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90941077",
   "metadata": {},
   "source": [
    "#### Observations : Variables numériques\n",
    "\n",
    "**Principales différences observées :**\n",
    "\n",
    "| Variable                      | Différence | Observation                          |\n",
    "| ----------------------------- | ---------- | ------------------------------------ |\n",
    "| `nombre_participation_pee`    | -37.6%     | Participation PEE plus faible        |\n",
    "| `annees_dans_le_poste_actuel` | -35.3%     | Ancienneté dans le poste plus faible |\n",
    "| `revenu_mensuel`              | -29.9%     | Salaire plus bas                     |\n",
    "| `distance_domicile_travail`   | +19.3%     | Distance plus grande                 |\n",
    "\n",
    "**Note :** Ce sont des observations descriptives. Le modèle confirmera l'importance réelle de chaque variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78f13e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 1 : Analyse Exploratoire\n",
    "\n",
    "### Données fusionnées\n",
    "\n",
    "| Métrique           | Valeur                       |\n",
    "| ------------------ | ---------------------------- |\n",
    "| Employés           | 1470                         |\n",
    "| Variables          | 34 colonnes                  |\n",
    "| Sources            | SIRH + Évaluations + Sondage |\n",
    "| Valeurs manquantes | 0                            |\n",
    "\n",
    "### Variable cible : Déséquilibre critique\n",
    "\n",
    "| Classe | Effectif | Proportion |\n",
    "| ------ | -------- | ---------- |\n",
    "| Restés | 1233     | **84%**    |\n",
    "| Partis | 237      | **16%**    |\n",
    "\n",
    "→ **Ratio 5:1** : nécessite stratification + gestion du déséquilibre (class_weight, SMOTE)\n",
    "\n",
    "### Profil type de l'employé qui part\n",
    "\n",
    "**Variables numériques discriminantes :**\n",
    "\n",
    "| Variable                      | Écart vs Restés | Interprétation RH            |\n",
    "| ----------------------------- | --------------- | ---------------------------- |\n",
    "| `nombre_participation_pee`    | **-37.6%**      | Moins engagés financièrement |\n",
    "| `annees_dans_le_poste_actuel` | **-35.3%**      | Moins d'ancienneté poste     |\n",
    "| `revenu_mensuel`              | **-29.9%**      | Salaire plus bas             |\n",
    "| `distance_domicile_travail`   | **+19.3%**      | Trajet plus long             |\n",
    "\n",
    "**Variables catégorielles à risque :**\n",
    "\n",
    "| Variable                | Modalité à risque       | Taux de churn |\n",
    "| ----------------------- | ----------------------- | ------------- |\n",
    "| `poste`                 | Représentant Commercial | **39.8%**     |\n",
    "| `heure_supplementaires` | Oui                     | **30.5%**     |\n",
    "| `statut_marital`        | Célibataire             | **25.5%**     |\n",
    "| `frequence_deplacement` | Fréquent                | Taux élevé    |\n",
    "\n",
    "**Profils stables (faible churn) :**\n",
    "\n",
    "- Directeur Technique (2.5%), Manager (6.9%)\n",
    "- Pas d'heures sup (10.4%)\n",
    "- Mariés, ancienneté élevée\n",
    "\n",
    "### Insights métier pour les RH\n",
    "\n",
    "1. **Rémunération** : Les employés qui partent gagnent ~30% de moins → Revoir la politique salariale\n",
    "2. **Heures sup** : 30% de churn chez ceux qui en font → Surveiller la charge de travail\n",
    "3. **Mobilité** : Distance domicile-travail corrélée au départ → Télétravail comme levier\n",
    "4. **Engagement** : Faible participation PEE = signal d'alerte → Renforcer l'intéressement\n",
    "5. **Postes à risque** : Commerciaux = 40% de turnover → Actions ciblées\n",
    "\n",
    "### Variables retenues pour la modélisation\n",
    "\n",
    "**Numériques potentiellement prédictives :**\n",
    "\n",
    "- `revenu_mensuel`, `annees_dans_le_poste_actuel`, `nombre_participation_pee`\n",
    "- `distance_domicile_travail`, `satisfaction_*` (4 variables)\n",
    "\n",
    "**Catégorielles potentiellement prédictives :**\n",
    "\n",
    "- `heure_supplementaires`, `poste`, `statut_marital`, `frequence_deplacement`\n",
    "\n",
    "**⚠️ Attention** : Ces observations sont **descriptives**. Le modèle (puis SHAP) confirmera l'importance réelle de chaque variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf5ceb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Partie 2 : Feature Engineering\n",
    "\n",
    "Dans cette partie, nous allons :\n",
    "\n",
    "1. **Nettoyer les donnees** : doublons, outliers, colonnes inutiles\n",
    "2. **Analyser les correlations** : matrice de Pearson, suppression des variables trop correlees\n",
    "3. **Encoder les variables categorielles** : OneHotEncoder pour les modeles\n",
    "4. **Creer X et y** : preparation finale pour la modelisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e376d06",
   "metadata": {},
   "source": [
    "## 8. Nettoyage des donnees\n",
    "\n",
    "### 8.1 Verification des doublons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  Nombre de lignes dupliquees : {df_merged.duplicated().sum()}\")\n",
    "print(f\"\\nDoublons sur 'id_employee' : {df_merged['id_employee'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57167662",
   "metadata": {},
   "source": [
    "### 8.2 Detection des outliers (methode IQR)\n",
    "\n",
    "**Qu'est-ce que la methode IQR (Interquartile Range) ?**\n",
    "\n",
    "L'IQR est une methode statistique robuste pour detecter les valeurs aberrantes :\n",
    "\n",
    "**Calcul des bornes :**\n",
    "\n",
    "- Borne inferieure = Q1 - 1.5 x IQR\n",
    "- Borne superieure = Q3 + 1.5 x IQR\n",
    "\n",
    "Toute valeur en dehors de ces bornes est consideree comme un **outlier**.\n",
    "\n",
    "**Pourquoi IQR plutot que Z-score ?**\n",
    "\n",
    "- IQR est base sur les **quartiles** (pas la moyenne)\n",
    "- Donc **insensible aux valeurs extremes** elles-memes\n",
    "- Plus adapte aux distributions non-normales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection des outliers avec la methode IQR (Interquartile Range)\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    \"\"\"Detecte les outliers pour chaque colonne numerique avec la methode IQR.\"\"\"\n",
    "    outliers_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        n_outliers = len(outliers)\n",
    "        pct_outliers = (n_outliers / len(df)) * 100\n",
    "\n",
    "        if n_outliers > 0:\n",
    "            outliers_summary.append(\n",
    "                {\n",
    "                    \"Variable\": col,\n",
    "                    \"Nb outliers\": n_outliers,\n",
    "                    \"% outliers\": round(pct_outliers, 1),\n",
    "                    \"Borne inf\": round(lower_bound, 2),\n",
    "                    \"Borne sup\": round(upper_bound, 2),\n",
    "                    \"Min reel\": round(df[col].min(), 2),\n",
    "                    \"Max reel\": round(df[col].max(), 2),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(outliers_summary)\n",
    "\n",
    "\n",
    "# Exclure les colonnes ID et la cible pour l'analyse des outliers\n",
    "cols_to_check = [\n",
    "    col\n",
    "    for col in numeric_cols\n",
    "    if col not in [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "]\n",
    "outliers_df = detect_outliers_iqr(df_merged, cols_to_check)\n",
    "\n",
    "print(f\"Variables avec outliers : {len(outliers_df)} / {len(cols_to_check)}\")\n",
    "print()\n",
    "if len(outliers_df) > 0:\n",
    "    display(outliers_df.sort_values(\"% outliers\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe8f28",
   "metadata": {},
   "source": [
    "**Decision sur les outliers :**\n",
    "\n",
    "Les outliers detectes sont des valeurs coherentes dans un contexte RH :\n",
    "\n",
    "- **Revenus eleves** : salaires de cadres superieurs (jusqu'a 19 999 EUR)\n",
    "- **Anciennete elevee** : employes fideles (jusqu'a 40 ans)\n",
    "- **Formations** : 6 formations maximum, valeur plausible\n",
    "\n",
    "Ces valeurs ne sont pas des erreurs de saisie mais des cas legitimes. Nous les **conservons** car :\n",
    "\n",
    "1. Les modeles tree-based (Random Forest, XGBoost) gerent bien les outliers\n",
    "2. Ces profils extremes peuvent etre pertinents pour predire le churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef98ecb",
   "metadata": {},
   "source": [
    "### 8.3 Identification des colonnes a supprimer\n",
    "\n",
    "**Pourquoi supprimer certaines colonnes ?**\n",
    "\n",
    "1. **Colonnes ID** (id_employee, eval_number, code_sondage)\n",
    "   - Ce sont des identifiants uniques (1, 2, 3...)\n",
    "   - Aucune valeur predictive : le modele ne peut pas apprendre que \"employe 42\" part plus souvent\n",
    "\n",
    "2. **Colonnes a variance nulle**\n",
    "   - Une colonne avec la **meme valeur pour tous** (ex: `nombre_heures_travailless = 80` pour tout le monde)\n",
    "   - Aucune information discriminante : impossible de differencier partis vs restes\n",
    "\n",
    "3. **Colonnes redondantes**\n",
    "   - `a_quitte_l_entreprise` et `statut` contiennent la meme information que notre cible\n",
    "   - Les garder = **data leakage** (le modele \"triche\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonnes actuelles du dataset :\")\n",
    "print(df_merged.columns.tolist())\n",
    "\n",
    "id_columns = [\"id_employee\", \"eval_number\", \"code_sondage\"]\n",
    "\n",
    "target_column = \"depart\"\n",
    "\n",
    "# Colonnes a variance nulle ou quasi-nulle\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nVerification des colonnes a faible variance :\")\n",
    "for col in df_merged.columns:\n",
    "    unique_ratio = df_merged[col].nunique() / len(df_merged)\n",
    "    if df_merged[col].nunique() <= 2 and col != target_column:\n",
    "        print(\n",
    "            f\"  {col} : {df_merged[col].nunique()} valeurs uniques -> {df_merged[col].value_counts().to_dict()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f78867",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = {\n",
    "    # Colonnes ID (pas de valeur predictive)\n",
    "    \"id_employee\": \"Identifiant unique - pas de valeur predictive\",\n",
    "    \"eval_number\": \"Identifiant evaluation - pas de valeur predictive\",\n",
    "    \"code_sondage\": \"Identifiant sondage - pas de valeur predictive\",\n",
    "    # Colonnes a variance nulle (meme valeur pour tous)\n",
    "    \"nombre_heures_travailless\": \"Variance nulle - toujours 80\",\n",
    "    \"nombre_employee_sous_responsabilite\": \"Variance nulle - toujours 1\",\n",
    "    \"ayant_enfants\": \"Variance nulle - toujours Y\",\n",
    "    # Colonne redondante avec la cible\n",
    "    \"a_quitte_l_entreprise\": 'Redondante avec \"statut\" (variable cible)',\n",
    "    \"statut\": 'Redondante - nous utiliserons \"depart\" comme cible binaire',\n",
    "}\n",
    "\n",
    "print(\"Colonnes a supprimer :\")\n",
    "for col, reason in columns_to_drop.items():\n",
    "    print(f\"  - {col}: {reason}\")\n",
    "\n",
    "print(f\"\\nTotal : {len(columns_to_drop)} colonnes a supprimer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du DataFrame nettoye\n",
    "df_clean = df_merged.copy()\n",
    "\n",
    "# Creation de la variable cible binaire 'depart' (0 = Reste, 1 = Churn)\n",
    "df_clean[\"depart\"] = (df_clean[\"statut\"] == \"Parti\").astype(int)\n",
    "\n",
    "# Suppression des colonnes identifiees\n",
    "df_clean = df_clean.drop(columns=list(columns_to_drop.keys()))\n",
    "\n",
    "print(f\"Dataset initial : {df_merged.shape[0]} lignes x {df_merged.shape[1]} colonnes\")\n",
    "print(f\"Dataset nettoye : {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\")\n",
    "print(f\"\\nColonnes restantes ({df_clean.shape[1]}) :\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6926f",
   "metadata": {},
   "source": [
    "## 9. Analyse des correlations\n",
    "\n",
    "**Pourquoi analyser les correlations ?**\n",
    "\n",
    "1. **Identifier les relations lineaires** entre variables\n",
    "2. **Detecter la multicolinearite** : si 2 variables sont tres correlees (|r| > 0.7), elles apportent la meme information → on peut en supprimer une\n",
    "3. **Comprendre les liens avec la cible** : quelles variables sont les plus correlees avec le depart ?\n",
    "\n",
    "### 9.1 Matrice de correlation de Pearson\n",
    "\n",
    "**Pearson** mesure les correlations **lineaires** :\n",
    "\n",
    "- r = +1 : correlation positive parfaite\n",
    "- r = 0 : pas de correlation lineaire\n",
    "- r = -1 : correlation negative parfaite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de correlation Pearson\n",
    "numeric_cols_clean = df_clean.select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ").columns.tolist()\n",
    "print(f\"Variables numériques pour la corrélation : {len(numeric_cols_clean)}\")\n",
    "\n",
    "corr_matrix = df_clean[numeric_cols_clean].corr()\n",
    "\n",
    "# Visualisation avec matplotlib/seaborn\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    "    annot_kws={\"size\": 7},\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Matrice de Corrélation de Pearson\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Corrélations avec la cible\n",
    "print(\"\\nCORRÉLATIONS AVEC LA CIBLE 'depart' :\")\n",
    "print(\"-\" * 50)\n",
    "target_corr = corr_matrix[\"depart\"].drop(\"depart\").sort_values(key=abs, ascending=False)\n",
    "for var, corr_value in target_corr.items():\n",
    "    print(f\"   {var:40} : {corr_value:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c11216",
   "metadata": {},
   "source": [
    "### 9.2 Identification des correlations fortes (|r| > 0.7)\n",
    "\n",
    "**Pourquoi analyser les corrélations ?**\n",
    "\n",
    "Si deux variables sont **très corrélées** (ex: `revenu_mensuel` et `niveau_hierarchique_poste` à 0.95), elles apportent une information **partiellement redondante**.\n",
    "\n",
    "**Faut-il supprimer ces variables ?**\n",
    "\n",
    "⚠️ **Non !** Contrairement à une idée reçue, la **multicolinéarité n'est pas un problème** pour les modèles basés sur les arbres (Random Forest, LightGBM) que nous utilisons :\n",
    "\n",
    "- Ces modèles **n'utilisent pas de coefficients linéaires** → pas d'instabilité\n",
    "- Même avec 95% de corrélation, il reste **5% d'information unique** qui peut être utile\n",
    "- Supprimer une variable = **perte potentielle d'information prédictive**\n",
    "- **Pas de data leakage** : ces variables sont des caractéristiques RH légitimes\n",
    "\n",
    "**Conclusion :** On **conserve toutes les variables** et on laisse le modèle choisir les plus pertinentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e32385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des paires de variables fortement correlees (|r| > 0.7)\n",
    "threshold = 0.7\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Parcourir le triangle inferieur de la matrice (sans la diagonale)\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            high_corr_pairs.append(\n",
    "                {\n",
    "                    \"Variable 1\": corr_matrix.columns[j],\n",
    "                    \"Variable 2\": corr_matrix.columns[i],\n",
    "                    \"Correlation\": round(corr_matrix.iloc[i, j], 3),\n",
    "                }\n",
    "            )\n",
    "\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs).sort_values(\"Correlation\", ascending=False)\n",
    "print(f\"Paires de variables avec correlation |r| > {threshold} :\")\n",
    "print()\n",
    "display(high_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des corrélations avec la cible 'depart'\n",
    "# (pour information - toutes les variables sont conservées)\n",
    "\n",
    "print(\"Corrélation avec la cible 'depart' :\")\n",
    "target_corr = corr_matrix[\"depart\"].drop(\"depart\").abs().sort_values(ascending=False)\n",
    "print(target_corr.head(10))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nAnalyse des paires fortement corrélées :\")\n",
    "for _, row in high_corr_df.iterrows():\n",
    "    var1, var2 = row[\"Variable 1\"], row[\"Variable 2\"]\n",
    "    corr1 = abs(corr_matrix.loc[\"depart\", var1])\n",
    "    corr2 = abs(corr_matrix.loc[\"depart\", var2])\n",
    "    print(\n",
    "        f\"\\n{var1} (|r| avec depart = {corr1:.3f}) vs {var2} (|r| avec depart = {corr2:.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ DECISION : On garde TOUTES les variables corrélées\n",
    "# Justification métier :\n",
    "# - Même avec r=0.95, il reste 5% d'information unique potentiellement utile\n",
    "# - Les modèles à base d'arbres (RF, LightGBM) gèrent bien la multicolinéarité\n",
    "# - Pas de data leakage → pas de raison de supprimer\n",
    "\n",
    "print(\"✅ DÉCISION : Conservation de TOUTES les variables\")\n",
    "print()\n",
    "print(\"Variables fortement corrélées (|r| > 0.7) :\")\n",
    "for _, row in high_corr_df.iterrows():\n",
    "    print(\n",
    "        f\"   {row['Variable 1']} ↔ {row['Variable 2']} : r = {row['Correlation']:.2f}\"\n",
    "    )\n",
    "print()\n",
    "print(\"Justification :\")\n",
    "print(\"   - Les modèles à base d'arbres ne sont pas affectés par la multicolinéarité\")\n",
    "print(\"   - Même 5% d'information unique peut améliorer la prédiction\")\n",
    "print(\"   - Aucun data leakage détecté → variables RH légitimes\")\n",
    "print()\n",
    "print(f\"Dataset conservé : {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976f594",
   "metadata": {},
   "source": [
    "### 9.3 Pourquoi conserver les variables corrélées ?\n",
    "\n",
    "**Analyse des corrélations détectées (|r| > 0.7) :**\n",
    "\n",
    "| Variable 1                 | Variable 2                      | Corrélation |\n",
    "| -------------------------- | ------------------------------- | ----------- |\n",
    "| `revenu_mensuel`           | `niveau_hierarchique_poste`     | **0.95**    |\n",
    "| `annee_experience_totale`  | `niveau_hierarchique_poste`     | 0.78        |\n",
    "| `annees_dans_l_entreprise` | `annees_dans_le_poste_actuel`   | 0.76        |\n",
    "| `annees_dans_l_entreprise` | `annes_sous_responsable_actuel` | 0.77        |\n",
    "\n",
    "**Pourquoi NE PAS supprimer ces variables ?**\n",
    "\n",
    "1. **Modèles à base d'arbres** (RF, LightGBM) :\n",
    "   - Ne calculent pas de coefficients linéaires → pas d'instabilité\n",
    "   - Sélectionnent automatiquement les features les plus discriminantes\n",
    "   - La corrélation ne pose pas de problème d'estimation\n",
    "\n",
    "2. **Information résiduelle** :\n",
    "   - Même avec r=0.95, il reste **5% d'information unique**\n",
    "   - Cette information peut être utile pour certains profils d'employés\n",
    "   - Supprimer = risque de perdre du pouvoir prédictif\n",
    "\n",
    "3. **Interprétabilité SHAP** :\n",
    "   - SHAP répartit équitablement l'importance entre variables corrélées\n",
    "   - On peut voir les deux perspectives : salaire ET niveau hiérarchique\n",
    "\n",
    "4. **Pas de data leakage** :\n",
    "   - Ces variables sont des caractéristiques RH disponibles avant le départ\n",
    "   - Aucune fuite d'information future\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e769835",
   "metadata": {},
   "source": [
    "### 9.4 Conversion de `augementation_salaire_precedente` en numérique\n",
    "\n",
    "**Problème identifié :** La colonne `augementation_salaire_precedente` contient des valeurs comme \"11 %\", \"23 %\" qui sont stockées comme **texte (object)**.\n",
    "\n",
    "**Pourquoi convertir en numérique ?**\n",
    "\n",
    "| Approche                      | Nb features          | Compréhension modèle             | Risque overfitting |\n",
    "| ----------------------------- | -------------------- | -------------------------------- | ------------------ |\n",
    "| **Catégorielle (défaut)**     | 14 colonnes (OneHot) | ❌ Perd l'ordre et les distances | ⚠️ Plus élevé      |\n",
    "| **Numérique (best practice)** | 1 colonne            | ✅ 11% < 12% < 23%               | ✅ Réduit          |\n",
    "\n",
    "**Avantages de la conversion :**\n",
    "\n",
    "- Le modèle comprend que **23% > 11%** (relation ordinale préservée)\n",
    "- Le modèle comprend que **23% - 11% = 12 points** (distances préservées)\n",
    "- **1 feature** au lieu de **14** → moins de dimensions → moins d'overfitting\n",
    "- Coefficient plus **interprétable** : \"+1% d'augmentation = X% de risque de départ\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de \"11 %\" -> 11.0 (valeur numerique)\n",
    "# On garde la valeur en pourcentage (11, 12, 23...) plutot qu'en decimal (0.11, 0.12...)\n",
    "\n",
    "print(\"Avant conversion :\")\n",
    "print(f\"  Type: {df_clean['augementation_salaire_precedente'].dtype}\")\n",
    "print(\n",
    "    f\"  Valeurs uniques: {df_clean['augementation_salaire_precedente'].unique()[:5]}...\"\n",
    ")\n",
    "\n",
    "# Suppression du \" %\" et conversion en float\n",
    "df_clean[\"augementation_salaire_precedente\"] = (\n",
    "    df_clean[\"augementation_salaire_precedente\"]\n",
    "    .str.replace(\" %\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(\"\\nApres conversion :\")\n",
    "print(f\"  Type: {df_clean['augementation_salaire_precedente'].dtype}\")\n",
    "print(\n",
    "    f\"  Valeurs uniques: {sorted(df_clean['augementation_salaire_precedente'].unique())}\"\n",
    ")\n",
    "print(f\"  Min: {df_clean['augementation_salaire_precedente'].min()}%\")\n",
    "print(f\"  Max: {df_clean['augementation_salaire_precedente'].max()}%\")\n",
    "print(f\"  Moyenne: {df_clean['augementation_salaire_precedente'].mean():.1f}%\")\n",
    "\n",
    "print(\"\\nLa colonne sera maintenant traitee comme NUMERIQUE dans le Pipeline\")\n",
    "print(\"   → StandardScaler au lieu de OneHotEncoder\")\n",
    "print(\"   → 1 feature au lieu de 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e791b",
   "metadata": {},
   "source": [
    "## 10. Feature Engineering - Creation de nouvelles variables\n",
    "\n",
    "**Pourquoi creer de nouvelles features ?**\n",
    "\n",
    "\"features supplementaires par rapport aux donnees d'origine\"\n",
    "\n",
    "**Objectif :** Creer des variables qui capturent des **informations metier** que les colonnes brutes ne montrent pas directement.\n",
    "\n",
    "**Features creees (3) :**\n",
    "\n",
    "| Feature                    | Formule                                        | Interpretation metier                            |\n",
    "| -------------------------- | ---------------------------------------------- | ------------------------------------------------ |\n",
    "| `ratio_salaire_experience` | revenu_mensuel / (experience + 1)              | Employe sous-paye par rapport a son experience ? |\n",
    "| `stagnation_poste`         | annees_dans_le_poste - annees_depuis_promotion | Employe bloque sans evolution ?                  |\n",
    "| `satisfaction_globale`     | moyenne des 4 satisfactions employee           | Score synthetique de bien-etre                   |\n",
    "\n",
    "**Pourquoi seulement 3 ?**\n",
    "\n",
    "- Eviter l'**overfitting** (trop de features pour peu de donnees)\n",
    "- Chaque feature doit avoir un **sens metier RH**\n",
    "- Le dataset est deja riche (50+ colonnes apres encodage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1 : Ratio salaire / experience\n",
    "# Interpretation : Un ratio bas = potentiellement sous-paye\n",
    "# Note: +1 pour eviter division par zero si experience = 0\n",
    "df_clean[\"ratio_salaire_experience\"] = df_clean[\"revenu_mensuel\"] / (\n",
    "    df_clean[\"annee_experience_totale\"] + 1\n",
    ")\n",
    "\n",
    "# Feature 2 : Stagnation de carriere\n",
    "# Interpretation : Valeur elevee = beaucoup d'annees dans le poste sans promotion recente\n",
    "df_clean[\"stagnation_poste\"] = (\n",
    "    df_clean[\"annees_dans_le_poste_actuel\"]\n",
    "    - df_clean[\"annees_depuis_la_derniere_promotion\"]\n",
    ")\n",
    "\n",
    "# Feature 3 : Satisfaction globale (moyenne des 4 satisfactions)\n",
    "# Interpretation : Score synthetique qui resume le bien-etre au travail\n",
    "cols_satisfaction = [\n",
    "    \"satisfaction_employee_environnement\",\n",
    "    \"satisfaction_employee_nature_travail\",\n",
    "    \"satisfaction_employee_equipe\",\n",
    "    \"satisfaction_employee_equilibre_pro_perso\",\n",
    "]\n",
    "df_clean[\"satisfaction_globale\"] = df_clean[cols_satisfaction].mean(axis=1)\n",
    "\n",
    "print(\"3 features creees avec succes !\")\n",
    "print(f\"\\nNouvelle shape du dataframe : {df_clean.shape}\")\n",
    "print(\"\\nApercu des nouvelles features :\")\n",
    "df_clean[\n",
    "    [\"ratio_salaire_experience\", \"stagnation_poste\", \"satisfaction_globale\"]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0221235",
   "metadata": {},
   "source": [
    "### 10.2 Verification de la pertinence des features\n",
    "\n",
    "Verifions la correlation de nos nouvelles features avec la variable cible `depart` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation des nouvelles features avec depart (variable cible)\n",
    "new_features = [\"ratio_salaire_experience\", \"stagnation_poste\", \"satisfaction_globale\"]\n",
    "\n",
    "# Creer un dataframe temporaire avec les nouvelles features et la cible\n",
    "temp_df = df_clean[new_features].copy()\n",
    "temp_df[\"depart\"] = df_clean[\n",
    "    \"depart\"\n",
    "].values  # La cible est encore dans df_clean a ce stade\n",
    "\n",
    "correlations = temp_df.corr()[\"depart\"].drop(\"depart\")\n",
    "\n",
    "print(\"Correlation avec depart (variable cible) :\")\n",
    "for feat, corr in correlations.items():\n",
    "    signe = \"🔴\" if corr > 0 else \"🟢\"\n",
    "    interpretation = \"quitte plus\" if corr > 0 else \"reste plus\"\n",
    "    print(f\"{signe} {feat}: {corr:.4f} ({interpretation})\")\n",
    "\n",
    "print(\"\\nInterpretation :\")\n",
    "print(\"   - satisfaction_globale : plus les gens sont satisfaits, moins ils partent\")\n",
    "print(\n",
    "    \"   - stagnation_poste : correlation negative = ceux qui stagnent RESTENT (profils seniors stables)\"\n",
    ")\n",
    "print(\n",
    "    \"   - ratio_salaire_experience : les mieux payes par rapport a leur experience partent plus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8927c9",
   "metadata": {},
   "source": [
    "## 11. Pipeline de preprocessing avec ColumnTransformer\n",
    "\n",
    "### Pourquoi utiliser un Pipeline ?\n",
    "\n",
    "| Avantage                     | Explication                                                               |\n",
    "| ---------------------------- | ------------------------------------------------------------------------- |\n",
    "| ✅ **Evite le data leakage** | Le preprocessing est applique UNIQUEMENT sur le train a chaque fold de CV |\n",
    "| ✅ **Code propre**           | Tout le preprocessing est encapsule dans un seul objet                    |\n",
    "| ✅ **Reproductible**         | Facile a reutiliser et deployer                                           |\n",
    "| ✅ **Compatible CV**         | S'integre parfaitement avec `cross_val_score` et `GridSearchCV`           |\n",
    "\n",
    "### 11.1 Identification des colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation features / cible AVANT le pipeline\n",
    "y = df_clean[\"depart\"]\n",
    "X = df_clean.drop(columns=[\"depart\"])\n",
    "\n",
    "# Identification automatique des colonnes numeriques et categorielles\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Colonnes identifiees pour le Pipeline :\")\n",
    "print(\n",
    "    f\"\\n  Numeriques ({len(num_cols)}) : {num_cols[:5]}{'...' if len(num_cols) > 5 else ''}\"\n",
    ")\n",
    "print(f\"\\n  Categorielles ({len(cat_cols)}) :\")\n",
    "for col in cat_cols:\n",
    "    unique_vals = X[col].unique()\n",
    "    print(f\"    - {col} ({len(unique_vals)} modalites)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44c983",
   "metadata": {},
   "source": [
    "### 11.2 Creation du ColumnTransformer\n",
    "\n",
    "**ColumnTransformer** applique des transformations differentes selon le type de colonne :\n",
    "\n",
    "| Type de colonne  | Transformation                | Parametre                  |\n",
    "| ---------------- | ----------------------------- | -------------------------- |\n",
    "| **Numerique**    | `StandardScaler()`            | Moyenne=0, Ecart-type=1    |\n",
    "| **Categorielle** | `OneHotEncoder(drop='first')` | Evite colinearite parfaite |\n",
    "\n",
    "**Parametre `remainder='passthrough'`** : conserve les colonnes non transformees (si elles existent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a743e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Creation du ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),  # Standardisation des numeriques\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False),\n",
    "            cat_cols,\n",
    "        ),  # Encodage des categorielles\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Conserver les autres colonnes si elles existent\n",
    ")\n",
    "\n",
    "print(\"\\nTransformations definies :\")\n",
    "print(f\"  - 'num' : StandardScaler sur {len(num_cols)} colonnes numeriques\")\n",
    "print(f\"  - 'cat' : OneHotEncoder sur {len(cat_cols)} colonnes categorielles\")\n",
    "print(\"\\nLe preprocessor sera FIT sur X_train uniquement (pas de data leakage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739e3d5",
   "metadata": {},
   "source": [
    "### 11.3 Split Train/Test avec stratification\n",
    "\n",
    "**❓ Question légitime : Pourquoi faire un split si on fait de la cross-validation ?**\n",
    "\n",
    "On fait les **DEUX** pour des raisons différentes :\n",
    "\n",
    "| Étape                                       | Objectif                                              | Utilisation                          |\n",
    "| ------------------------------------------- | ----------------------------------------------------- | ------------------------------------ |\n",
    "| **Split Train/Test (80/20)**                | Avoir un **jeu de test FINAL jamais touché**          | Évaluation finale du meilleur modèle |\n",
    "| **Cross-validation (sur Train uniquement)** | **Comparer les modèles** et tuner les hyperparamètres | Sélection du meilleur modèle         |\n",
    "\n",
    "**Pourquoi ?** Si on fait la CV sur **tout le dataset**, on n'a plus de données \"fraîches\" pour vérifier si le modèle généralise vraiment. Le test est le **juge final impartial**.\n",
    "\n",
    "**Workflow preprocessing (éviter data leakage) :**\n",
    "\n",
    "| Etape | Action                                   | Explication                                    |\n",
    "| ----- | ---------------------------------------- | ---------------------------------------------- |\n",
    "| 1     | `X, y = separation features/cible`       | Séparer les variables explicatives de la cible |\n",
    "| 2     | `X_train, X_test = split(X, y)`          | Split **avant** preprocessing                  |\n",
    "| 3     | `preprocessor.fit(X_train)`              | Fit sur train **UNIQUEMENT**                   |\n",
    "| 4     | `X_train_processed = transform(X_train)` | Transform train                                |\n",
    "| 5     | `X_test_processed = transform(X_test)`   | Transform test (mêmes paramètres du train)     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split stratifie AVANT le fit du preprocessor\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,  # Important pour le desequilibre de classes\n",
    ")\n",
    "\n",
    "print(\"Split train/test avec stratification :\")\n",
    "print(f\"\\n  Train : {X_train.shape[0]} lignes ({X_train.shape[0] / len(X) * 100:.0f}%)\")\n",
    "print(f\"    - Churn : {y_train.sum()} ({y_train.mean() * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"    - Non-churn : {len(y_train) - y_train.sum()} ({(1 - y_train.mean()) * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"\\n  Test : {X_test.shape[0]} lignes ({X_test.shape[0] / len(X) * 100:.0f}%)\")\n",
    "print(f\"    - Churn : {y_test.sum()} ({y_test.mean() * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"    - Non-churn : {len(y_test) - y_test.sum()} ({(1 - y_test.mean()) * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f810e",
   "metadata": {},
   "source": [
    "### 11.4 Application du preprocessor (fit_transform sur train, transform sur test)\n",
    "\n",
    "**C'est ici que la magie du Pipeline opere :**\n",
    "\n",
    "- `fit_transform(X_train)` : calcule les parametres (moyenne, ecart-type, modalites) ET transforme\n",
    "- `transform(X_test)` : utilise les parametres du train pour transformer le test\n",
    "\n",
    "**Avantage majeur** : Quand on utilisera `cross_val_score`, le fit sera automatiquement refait sur chaque fold !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sur train, transform sur train et test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)  # FIT + TRANSFORM\n",
    "X_test_processed = preprocessor.transform(X_test)  # TRANSFORM seulement\n",
    "\n",
    "# Recuperation des noms de colonnes pour lisibilite\n",
    "# (Les colonnes numeriques gardent leur nom, les categorielles sont encodees)\n",
    "num_feature_names = num_cols\n",
    "cat_feature_names = (\n",
    "    preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_cols).tolist()\n",
    ")\n",
    "all_feature_names = num_feature_names + cat_feature_names\n",
    "\n",
    "print(\"Preprocessing applique avec succes !\")\n",
    "print(\"\\nDimensions apres transformation :\")\n",
    "print(f\"  X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\"  X_test_processed  : {X_test_processed.shape}\")\n",
    "\n",
    "print(f\"\\nNombre de features finales : {len(all_feature_names)}\")\n",
    "print(f\"  - Numeriques (standardisees) : {len(num_feature_names)}\")\n",
    "print(f\"  - Categorielles (encodees)   : {len(cat_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b653394",
   "metadata": {},
   "source": [
    "### 11.5 Verification : pas de data leakage\n",
    "\n",
    "Verifions que le StandardScaler a bien ete fit sur le train uniquement :\n",
    "\n",
    "- **Train** : moyenne ≈ 0, ecart-type ≈ 1\n",
    "- **Test** : moyenne ≠ 0 exactement (normal, car les parametres viennent du train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e07bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indices = list(range(len(num_cols)))\n",
    "\n",
    "print(\"Verification du StandardScaler (colonnes numeriques) :\")\n",
    "print(f\"\\n  Train - Moyenne  : {X_train_processed[:, num_indices].mean():.6f}\")\n",
    "print(f\"  Train - Std      : {X_train_processed[:, num_indices].std():.6f}\")\n",
    "print(f\"\\n  Test  - Moyenne  : {X_test_processed[:, num_indices].mean():.6f}\")\n",
    "print(f\"  Test  - Std      : {X_test_processed[:, num_indices].std():.6f}\")\n",
    "\n",
    "print(\"\\nPas de data leakage : le test n'a pas exactement moyenne=0\")\n",
    "print(\"   (les parametres du scaler viennent du train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c643c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 2 : Feature Engineering\n",
    "\n",
    "### Nettoyage effectué\n",
    "\n",
    "- ✅ Aucun doublon détecté\n",
    "- ✅ Outliers conservés (valeurs RH légitimes : hauts salaires, ancienneté élevée)\n",
    "- ✅ 8 colonnes supprimées : identifiants, variance nulle, redondantes avec la cible\n",
    "\n",
    "### Analyse des corrélations\n",
    "\n",
    "- Matrice de **Pearson** (corrélations linéaires) - visualisation Plotly\n",
    "- Matrice de **Spearman** (corrélations monotones)\n",
    "- Corrélations fortes détectées (|r| > 0.7) mais **variables conservées**\n",
    "- **Justification** : les modèles à base d'arbres gèrent bien la multicolinéarité, et même 5% d'information unique peut être utile\n",
    "\n",
    "### Conversion de type (best practice)\n",
    "\n",
    "- ✅ `augementation_salaire_precedente` : \"11 %\" → 11.0 (numérique)\n",
    "- **Avantage** : 1 feature standardisée au lieu de 14 colonnes OneHot → moins d'overfitting\n",
    "- Le modèle comprend que 23% > 11% (ordre préservé)\n",
    "\n",
    "### Feature Engineering (3 nouvelles features métier)\n",
    "\n",
    "| Feature                    | Formule                 | Corr. avec depart | Interprétation                      |\n",
    "| -------------------------- | ----------------------- | ----------------- | ----------------------------------- |\n",
    "| `ratio_salaire_experience` | salaire / (exp + 1)     | +0.10             | Bien payés partent plus             |\n",
    "| `stagnation_poste`         | ancienneté - promotion  | -0.15             | Stagnants restent (profils stables) |\n",
    "| `satisfaction_globale`     | moyenne 4 satisfactions | -0.16             | Satisfaits restent                  |\n",
    "\n",
    "### Pipeline de preprocessing (ColumnTransformer)\n",
    "\n",
    "| Type       | Transformation                | Colonnes             |\n",
    "| ---------- | ----------------------------- | -------------------- |\n",
    "| Numérique  | `StandardScaler()`            | 23 colonnes          |\n",
    "| Catégoriel | `OneHotEncoder(drop='first')` | 7 cols → 21 features |\n",
    "\n",
    "### Dataset prêt pour la modélisation\n",
    "\n",
    "| Métrique         | Valeur                             |\n",
    "| ---------------- | ---------------------------------- |\n",
    "| Features totales | **44** (23 num + 21 cat)           |\n",
    "| Train            | 1176 lignes (80%)                  |\n",
    "| Test             | 294 lignes (20%)                   |\n",
    "| Churn train      | 16.2%                              |\n",
    "| Churn test       | 16.0%                              |\n",
    "| Data leakage     | Vérifié (fit sur train uniquement) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14188a43",
   "metadata": {},
   "source": [
    "# Partie 3 : Modélisation de Référence (Baseline)\n",
    "\n",
    "**Objectif :** Établir des **modèles de référence** pour comprendre la difficulté du problème avant d'optimiser.\n",
    "\n",
    "---\n",
    "\n",
    "## Approche méthodologique\n",
    "\n",
    "| Étape | Modèle                     | Objectif                                                  |\n",
    "| ----- | -------------------------- | --------------------------------------------------------- |\n",
    "| 1     | **DummyClassifier**        | Baseline naïf (que vaut \"toujours prédire majoritaire\" ?) |\n",
    "| 2     | **LogisticRegression**     | Modèle linéaire simple                                    |\n",
    "| 3     | **RandomForestClassifier** | Modèle non-linéaire (arbres)                              |\n",
    "\n",
    "## Métriques utilisées\n",
    "\n",
    "Pour un problème de **classification binaire déséquilibrée** (16% churn), l'**accuracy** est trompeuse.\n",
    "\n",
    "| Métrique      | Formule               | Interprétation métier                      |\n",
    "| ------------- | --------------------- | ------------------------------------------ |\n",
    "| **Precision** | TP / (TP + FP)        | \"Parmi les alertes, combien sont vraies ?\" |\n",
    "| **Recall**    | TP / (TP + FN)        | \"Combien de départs réels détectés ?\"      |\n",
    "| **F1-Score**  | 2 × (P × R) / (P + R) | Équilibre Precision/Recall                 |\n",
    "\n",
    "**Contexte RH :** Le **Recall** est critique car **rater un départ** (FN) coûte plus cher qu'une fausse alerte (FP).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de17a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate_model_cv(model, X_data, y_data, preprocessor, cv=5, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Évalue un modèle avec validation croisée stratifiée.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : estimator sklearn\n",
    "    X_data : DataFrame des features\n",
    "    y_data : Series de la cible\n",
    "    preprocessor : ColumnTransformer pour le preprocessing\n",
    "    cv : int, nombre de folds\n",
    "    model_name : str, nom du modèle pour l'affichage\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : résultats avec moyennes et écarts-types\n",
    "    \"\"\"\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Création du pipeline complet\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "\n",
    "    # Configuration de la validation croisée stratifiée\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Définition des métriques (focus sur classe positive = 1 = Parti)\n",
    "    scoring = {\n",
    "        \"recall\": make_scorer(recall_score, pos_label=1),\n",
    "        \"precision\": make_scorer(precision_score, pos_label=1, zero_division=0),\n",
    "        \"f1\": make_scorer(f1_score, pos_label=1),\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "    }\n",
    "\n",
    "    # Exécution de la validation croisée\n",
    "    cv_results = cross_validate(\n",
    "        pipeline,\n",
    "        X_data,\n",
    "        y_data,\n",
    "        cv=skf,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Compilation des résultats\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"recall_train_mean\": cv_results[\"train_recall\"].mean(),\n",
    "        \"recall_train_std\": cv_results[\"train_recall\"].std(),\n",
    "        \"recall_test_mean\": cv_results[\"test_recall\"].mean(),\n",
    "        \"recall_test_std\": cv_results[\"test_recall\"].std(),\n",
    "        \"precision_train_mean\": cv_results[\"train_precision\"].mean(),\n",
    "        \"precision_train_std\": cv_results[\"train_precision\"].std(),\n",
    "        \"precision_test_mean\": cv_results[\"test_precision\"].mean(),\n",
    "        \"precision_test_std\": cv_results[\"test_precision\"].std(),\n",
    "        \"f1_train_mean\": cv_results[\"train_f1\"].mean(),\n",
    "        \"f1_train_std\": cv_results[\"train_f1\"].std(),\n",
    "        \"f1_test_mean\": cv_results[\"test_f1\"].mean(),\n",
    "        \"f1_test_std\": cv_results[\"test_f1\"].std(),\n",
    "        \"roc_auc_train_mean\": cv_results[\"train_roc_auc\"].mean(),\n",
    "        \"roc_auc_test_mean\": cv_results[\"test_roc_auc\"].mean(),\n",
    "    }\n",
    "\n",
    "    # Affichage formaté\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\" {model_name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"\\n{'Métrique':<15} {'Train':>20} {'Test':>20}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(\n",
    "        f\"{'Recall':<15} {results['recall_train_mean']:.3f} ± {results['recall_train_std']:.3f}    {results['recall_test_mean']:.3f} ± {results['recall_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'Precision':<15} {results['precision_train_mean']:.3f} ± {results['precision_train_std']:.3f}    {results['precision_test_mean']:.3f} ± {results['precision_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'F1-Score':<15} {results['f1_train_mean']:.3f} ± {results['f1_train_std']:.3f}    {results['f1_test_mean']:.3f} ± {results['f1_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'ROC-AUC':<15} {results['roc_auc_train_mean']:.3f}              {results['roc_auc_test_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Fonction evaluate_model_cv() définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86fda6",
   "metadata": {},
   "source": [
    "## 12. Modèle Dummy (Baseline naïf)\n",
    "\n",
    "Le `DummyClassifier` sert de **référence minimale**. Si nos vrais modèles ne font pas mieux, c'est qu'ils n'apprennent rien.\n",
    "\n",
    "**Stratégie utilisée :** `most_frequent` → prédit toujours la classe majoritaire (0 = resté)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# DummyClassifier avec validation croisée (comme référence)\n",
    "print(\"🔄 Évaluation DummyClassifier avec validation croisée...\")\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "\n",
    "# Utilisation de la fonction evaluate_model_cv définie plus haut\n",
    "results_dummy = evaluate_model_cv(\n",
    "    dummy_clf, X, y, preprocessor, model_name=\"DummyClassifier (stratified)\"\n",
    ")\n",
    "\n",
    "print(\"\\n⚠️ Ce modèle sert de BASELINE - tout modèle doit faire mieux !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression SANS class_weight (pour montrer le problème)\n",
    "print(\n",
    "    \"🔄 Évaluation Logistic Regression (sans class_weight) avec validation croisée...\"\n",
    ")\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "results_lr = evaluate_model_cv(\n",
    "    lr_clf, X, y, preprocessor, model_name=\"Logistic Regression (sans class_weight)\"\n",
    ")\n",
    "\n",
    "print(\"\\nNoter le Recall très faible → le modèle rate la plupart des départs !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest SANS class_weight (pour montrer le problème)\n",
    "print(\"🔄 Évaluation Random Forest (sans class_weight) avec validation croisée...\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf = evaluate_model_cv(\n",
    "    rf_clf, X, y, preprocessor, model_name=\"Random Forest (sans class_weight)\"\n",
    ")\n",
    "\n",
    "print(\"\\nLe Recall est catastrophique malgré une bonne Accuracy !\")\n",
    "print(\"   → L'Accuracy est TROMPEUSE avec des classes déséquilibrées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81795d7c",
   "metadata": {},
   "source": [
    "## 13. Comparaison des Modèles Baseline\n",
    "\n",
    "Récapitulatif des performances des 3 modèles **sans gestion du déséquilibre**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des modèles baseline (résultats de cross-validation)\n",
    "baseline_results = [results_dummy, results_lr, results_rf]\n",
    "\n",
    "comparison_df = pd.DataFrame(baseline_results)\n",
    "\n",
    "# Sélection des colonnes principales\n",
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"recall_test_mean\",\n",
    "    \"recall_test_std\",\n",
    "    \"precision_test_mean\",\n",
    "    \"f1_test_mean\",\n",
    "    \"roc_auc_test_mean\",\n",
    "]\n",
    "\n",
    "comparison_display = comparison_df[display_cols].copy()\n",
    "comparison_display.columns = [\n",
    "    \"Modèle\",\n",
    "    \"Recall (CV)\",\n",
    "    \"Recall Std\",\n",
    "    \"Precision (CV)\",\n",
    "    \"F1 (CV)\",\n",
    "    \"ROC-AUC (CV)\",\n",
    "]\n",
    "\n",
    "# Formatage\n",
    "comparison_display[\"Recall (CV)\"] = comparison_display.apply(\n",
    "    lambda x: f\"{x['Recall (CV)']:.3f} ± {x['Recall Std']:.3f}\", axis=1\n",
    ")\n",
    "comparison_display = comparison_display.drop(\"Recall Std\", axis=1)\n",
    "\n",
    "print(\"COMPARAISON DES MODÈLES BASELINE (sans gestion du déséquilibre)\")\n",
    "print(\"\\n📊 Métriques en validation croisée (5 folds) - Focus classe 'Parti'\\n\")\n",
    "\n",
    "display(comparison_display)\n",
    "\n",
    "print(\"CONSTAT IMPORTANT :\")\n",
    "print(\"\\n• L'Accuracy est élevée (~84%) mais TROMPEUSE !\")\n",
    "print(\"  → Un modèle qui prédit TOUJOURS 'Resté' aurait aussi ~84% d'accuracy\")\n",
    "print(\"\\n• Le Recall est CATASTROPHIQUE (proche de 0)\")\n",
    "print(\"  → Les modèles ratent presque TOUS les départs\")\n",
    "print(\"\\n• Conclusion : Il FAUT gérer le déséquilibre des classes !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73556c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative des modèles baseline\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Préparation des données à partir des résultats de cross-validation\n",
    "models = [\"Dummy\", \"Logistic Reg.\", \"Random Forest\"]\n",
    "recall_test = [\n",
    "    results_dummy[\"recall_test_mean\"],\n",
    "    results_lr[\"recall_test_mean\"],\n",
    "    results_rf[\"recall_test_mean\"],\n",
    "]\n",
    "precision_test = [\n",
    "    results_dummy[\"precision_test_mean\"],\n",
    "    results_lr[\"precision_test_mean\"],\n",
    "    results_rf[\"precision_test_mean\"],\n",
    "]\n",
    "f1_test = [\n",
    "    results_dummy[\"f1_test_mean\"],\n",
    "    results_lr[\"f1_test_mean\"],\n",
    "    results_rf[\"f1_test_mean\"],\n",
    "]\n",
    "recall_train = [\n",
    "    results_dummy[\"recall_train_mean\"],\n",
    "    results_lr[\"recall_train_mean\"],\n",
    "    results_rf[\"recall_train_mean\"],\n",
    "]\n",
    "\n",
    "# Graphique 1 : Métriques sur la classe 'Parti' (Test)\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.bar(x - width, precision_test, width, label=\"Precision\", color=\"steelblue\")\n",
    "ax1.bar(x, recall_test, width, label=\"Recall\", color=\"darkorange\")\n",
    "ax1.bar(x + width, f1_test, width, label=\"F1-Score\", color=\"green\")\n",
    "ax1.set_ylabel(\"Score\")\n",
    "ax1.set_title(\"Métriques sur la classe 'Parti' (Test CV)\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Seuil 50%\")\n",
    "\n",
    "# Graphique 2 : Comparaison Train vs Test (détection overfitting)\n",
    "ax2 = axes[1]\n",
    "x2 = np.arange(len(models))\n",
    "ax2.bar(x2 - 0.2, recall_train, 0.4, label=\"Train\", color=\"steelblue\")\n",
    "ax2.bar(x2 + 0.2, recall_test, 0.4, label=\"Test\", color=\"darkorange\")\n",
    "ax2.set_ylabel(\"Recall (Parti)\")\n",
    "ax2.set_title(\"Détection Overfitting : Train vs Test\")\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.1)\n",
    "\n",
    "# Annotations pour Random Forest (overfitting)\n",
    "ax2.annotate(\n",
    "    \"Overfitting!\",\n",
    "    xy=(2, recall_train[2]),\n",
    "    xytext=(2, recall_train[2] + 0.05),\n",
    "    ha=\"center\",\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d50886",
   "metadata": {},
   "source": [
    "### 13.1 Analyse des résultats Baseline\n",
    "\n",
    "**Constats observés :**\n",
    "\n",
    "| Modèle                  | Comportement observé                              |\n",
    "| ----------------------- | ------------------------------------------------- |\n",
    "| **Dummy**               | Recall ~14% (prédiction aléatoire stratifiée)     |\n",
    "| **Logistic Regression** | Recall ~40%, meilleur F1 parmi les baselines      |\n",
    "| **Random Forest**       | Recall train=100% vs test=16% (**overfitting !**) |\n",
    "\n",
    "**Problème identifié :** Sans gestion du déséquilibre (16% vs 84%), les modèles tendent à ignorer la classe minoritaire \"Parti\" ou à surapprendre sur le train set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb19c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 3 : Modélisation Baseline\n",
    "\n",
    "### Modèles entraînés\n",
    "\n",
    "| Modèle                   | Type                  | Objectif                     |\n",
    "| ------------------------ | --------------------- | ---------------------------- |\n",
    "| `DummyClassifier`        | Baseline naïf         | Référence minimale           |\n",
    "| `LogisticRegression`     | Linéaire              | Premier modèle interprétable |\n",
    "| `RandomForestClassifier` | Non-linéaire (arbres) | Capture relations complexes  |\n",
    "\n",
    "### Métriques calculées\n",
    "\n",
    "- ✅ `classification_report()` (Precision, Recall, F1)\n",
    "- ✅ Matrice de confusion (Train ET Test)\n",
    "- ✅ Comparaison Train vs Test pour détecter l'overfitting\n",
    "\n",
    "### Problème identifié\n",
    "\n",
    "**Déséquilibre des classes (16% Parti / 84% Resté)** :\n",
    "\n",
    "- Les modèles optimisent l'accuracy → ignorent la classe minoritaire\n",
    "- Le Recall sur \"Parti\" est insuffisant pour un usage métier RH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b2c64",
   "metadata": {},
   "source": [
    "# PARTIE 4 : GESTION DU DÉSÉQUILIBRE DES CLASSES\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Stratégie de gestion du déséquilibre\n",
    "\n",
    "### 14.1 Contexte métier\n",
    "\n",
    "Dans un contexte RH, **identifier les employés à risque de départ** (classe \"Parti\") est crucial :\n",
    "\n",
    "- Un **Faux Négatif** (employé à risque non détecté) = départ non anticipé → coût élevé\n",
    "- Un **Faux Positif** (employé stable mal classé) = actions RH inutiles → coût modéré\n",
    "\n",
    "**Objectif** : Maximiser le **Recall** sur la classe \"Parti\" tout en maintenant une Precision acceptable.\n",
    "\n",
    "### 14.2 Techniques à tester\n",
    "\n",
    "| #   | Technique                 | Package  | Approche                     |\n",
    "| --- | ------------------------- | -------- | ---------------------------- |\n",
    "| 1   | `class_weight='balanced'` | sklearn  | Pondération des erreurs      |\n",
    "| 2   | SMOTE                     | imblearn | Oversampling synthétique     |\n",
    "| 3   | Random Undersampling      | imblearn | Réduction classe majoritaire |\n",
    "| 4   | Calibration               | sklearn  | `CalibratedClassifierCV`     |\n",
    "\n",
    "### 14.3 Protocole d'évaluation\n",
    "\n",
    "- **Validation croisée stratifiée** : `StratifiedKFold` (5 folds)\n",
    "- **Métriques principales** : Recall, Precision, F1-score (classe \"Parti\")\n",
    "- **Métrique secondaire** : ROC-AUC, PR-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "print(\"\\nRappel - Distribution des classes :\")\n",
    "print(y.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ba238",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 15. Fonction d'évaluation en validation croisée\n",
    "\n",
    "Création d'une fonction réutilisable pour évaluer les modèles avec validation croisée stratifiée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3828bb",
   "metadata": {},
   "source": [
    "## 16. Technique 1 : Class Weight (Pondération des classes)\n",
    "\n",
    "### 16.1 Principe\n",
    "\n",
    "Le paramètre `class_weight='balanced'` ajuste automatiquement les poids des classes inversement proportionnels à leur fréquence :\n",
    "\n",
    "$$w_c = \\frac{n_{samples}}{n_{classes} \\times n_{samples_c}}$$\n",
    "\n",
    "Cela pénalise davantage les erreurs sur la classe minoritaire (\"Parti\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18.2 Entraînement des modèles avec class_weight='balanced'\n",
    "all_results = []  # Liste pour stocker tous les résultats\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"🔄 Entraînement Logistic Regression avec class_weight='balanced'...\")\n",
    "lr_balanced = LogisticRegression(\n",
    "    class_weight=\"balanced\", max_iter=1000, random_state=42\n",
    ")\n",
    "results_lr_balanced = evaluate_model_cv(\n",
    "    lr_balanced, X, y, preprocessor, model_name=\"Logistic Regression (balanced)\"\n",
    ")\n",
    "all_results.append(results_lr_balanced)\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\n🔄 Entraînement Random Forest avec class_weight='balanced'...\")\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    ")\n",
    "results_rf_balanced = evaluate_model_cv(\n",
    "    rf_balanced, X, y, preprocessor, model_name=\"Random Forest (balanced)\"\n",
    ")\n",
    "all_results.append(results_rf_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491e96b",
   "metadata": {},
   "source": [
    "## 17. Technique 2 : SMOTE (Oversampling)\n",
    "\n",
    "### 17.1 Principe\n",
    "\n",
    "**SMOTE** (Synthetic Minority Over-sampling Technique) génère des observations synthétiques pour la classe minoritaire en interpolant entre les observations existantes et leurs k plus proches voisins.\n",
    "\n",
    "**Important** : SMOTE doit être appliqué **uniquement sur le jeu d'entraînement** pour éviter la fuite de données (data leakage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_resampling(\n",
    "    model,\n",
    "    X_data,\n",
    "    y_data,\n",
    "    preprocessor,\n",
    "    resampler,\n",
    "    cv=5,\n",
    "    model_name=\"Model\",\n",
    "    pos_label=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Évalue un modèle avec resampling (SMOTE ou Undersampling) en validation croisée.\n",
    "    Le resampling est appliqué APRÈS le preprocessing et UNIQUEMENT sur le train.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    pos_label : int ou str, label de la classe positive (défaut: 1)\n",
    "    \"\"\"\n",
    "    from sklearn.base import clone\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Convertir y en numpy array si c'est une Series\n",
    "    y_array = y_data.values if hasattr(y_data, \"values\") else y_data\n",
    "\n",
    "    # Stockage des métriques par fold\n",
    "    metrics = {\n",
    "        \"recall_train\": [],\n",
    "        \"recall_test\": [],\n",
    "        \"precision_train\": [],\n",
    "        \"precision_test\": [],\n",
    "        \"f1_train\": [],\n",
    "        \"f1_test\": [],\n",
    "        \"roc_auc_train\": [],\n",
    "        \"roc_auc_test\": [],\n",
    "    }\n",
    "\n",
    "    for _, (train_idx, test_idx) in enumerate(skf.split(X_data, y_array), 1):\n",
    "        # Split des données\n",
    "        X_train_fold, X_test_fold = X_data.iloc[train_idx], X_data.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_array[train_idx], y_array[test_idx]\n",
    "\n",
    "        # Preprocessing\n",
    "        X_train_processed = preprocessor.fit_transform(X_train_fold)\n",
    "        X_test_processed = preprocessor.transform(X_test_fold)\n",
    "\n",
    "        # Resampling sur le train uniquement\n",
    "        X_train_resampled, y_train_resampled = resampler.fit_resample(\n",
    "            X_train_processed, y_train_fold\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Prédictions\n",
    "        y_train_pred = clf.predict(X_train_resampled)\n",
    "        y_test_pred = clf.predict(X_test_processed)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        metrics[\"recall_train\"].append(\n",
    "            recall_score(y_train_resampled, y_train_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"recall_test\"].append(\n",
    "            recall_score(y_test_fold, y_test_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"precision_train\"].append(\n",
    "            precision_score(\n",
    "                y_train_resampled, y_train_pred, pos_label=pos_label, zero_division=0\n",
    "            )\n",
    "        )\n",
    "        metrics[\"precision_test\"].append(\n",
    "            precision_score(\n",
    "                y_test_fold, y_test_pred, pos_label=pos_label, zero_division=0\n",
    "            )\n",
    "        )\n",
    "        metrics[\"f1_train\"].append(\n",
    "            f1_score(y_train_resampled, y_train_pred, pos_label=pos_label)\n",
    "        )\n",
    "        metrics[\"f1_test\"].append(\n",
    "            f1_score(y_test_fold, y_test_pred, pos_label=pos_label)\n",
    "        )\n",
    "\n",
    "        # ROC-AUC (nécessite proba)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            # Index de la classe positive dans le classifieur\n",
    "            pos_idx = list(clf.classes_).index(pos_label)\n",
    "            y_train_proba = clf.predict_proba(X_train_resampled)[:, pos_idx]\n",
    "            y_test_proba = clf.predict_proba(X_test_processed)[:, pos_idx]\n",
    "            metrics[\"roc_auc_train\"].append(\n",
    "                roc_auc_score(\n",
    "                    (y_train_resampled == pos_label).astype(int), y_train_proba\n",
    "                )\n",
    "            )\n",
    "            metrics[\"roc_auc_test\"].append(\n",
    "                roc_auc_score((y_test_fold == pos_label).astype(int), y_test_proba)\n",
    "            )\n",
    "\n",
    "    # Compilation des résultats\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"recall_train_mean\": np.mean(metrics[\"recall_train\"]),\n",
    "        \"recall_train_std\": np.std(metrics[\"recall_train\"]),\n",
    "        \"recall_test_mean\": np.mean(metrics[\"recall_test\"]),\n",
    "        \"recall_test_std\": np.std(metrics[\"recall_test\"]),\n",
    "        \"precision_train_mean\": np.mean(metrics[\"precision_train\"]),\n",
    "        \"precision_train_std\": np.std(metrics[\"precision_train\"]),\n",
    "        \"precision_test_mean\": np.mean(metrics[\"precision_test\"]),\n",
    "        \"precision_test_std\": np.std(metrics[\"precision_test\"]),\n",
    "        \"f1_train_mean\": np.mean(metrics[\"f1_train\"]),\n",
    "        \"f1_train_std\": np.std(metrics[\"f1_train\"]),\n",
    "        \"f1_test_mean\": np.mean(metrics[\"f1_test\"]),\n",
    "        \"f1_test_std\": np.std(metrics[\"f1_test\"]),\n",
    "        \"roc_auc_train_mean\": np.mean(metrics[\"roc_auc_train\"])\n",
    "        if metrics[\"roc_auc_train\"]\n",
    "        else 0,\n",
    "        \"roc_auc_test_mean\": np.mean(metrics[\"roc_auc_test\"])\n",
    "        if metrics[\"roc_auc_test\"]\n",
    "        else 0,\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"\\n{'Métrique':<15} {'Train':>20} {'Test':>20}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(\n",
    "        f\"{'Recall':<15} {results['recall_train_mean']:.3f} ± {results['recall_train_std']:.3f}    {results['recall_test_mean']:.3f} ± {results['recall_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'Precision':<15} {results['precision_train_mean']:.3f} ± {results['precision_train_std']:.3f}    {results['precision_test_mean']:.3f} ± {results['precision_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'F1-Score':<15} {results['f1_train_mean']:.3f} ± {results['f1_train_std']:.3f}    {results['f1_test_mean']:.3f} ± {results['f1_test_std']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'ROC-AUC':<15} {results['roc_auc_train_mean']:.3f}              {results['roc_auc_test_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Fonction evaluate_model_with_resampling() définie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔄 Entraînement Random Forest avec SMOTE...\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf_smote = evaluate_model_with_resampling(\n",
    "    rf_smote, X, y, preprocessor, smote, model_name=\"Random Forest + SMOTE\"\n",
    ")\n",
    "all_results.append(results_rf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ee94a",
   "metadata": {},
   "source": [
    "## 18. Technique 3 : Undersampling\n",
    "\n",
    "### 18.1 Principe\n",
    "\n",
    "L'**undersampling** réduit le nombre d'observations de la classe majoritaire (\"Resté\") pour équilibrer les classes.\n",
    "\n",
    "⚠️ **Inconvénient** : Perte d'information en supprimant des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.2 Random Forest avec Undersampling\n",
    "print(\"Entraînement Random Forest avec Undersampling...\")\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "rf_under = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf_under = evaluate_model_with_resampling(\n",
    "    rf_under,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor,\n",
    "    undersampler,\n",
    "    model_name=\"Random Forest + Undersampling\",\n",
    ")\n",
    "all_results.append(results_rf_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ce082",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 19. Technique 4 : Calibration des probabilités\n",
    "\n",
    "### 19.1 Principe\n",
    "\n",
    "La **calibration** ajuste les probabilités prédites pour qu'elles reflètent mieux la réalité. `CalibratedClassifierCV` utilise soit :\n",
    "\n",
    "- **Platt scaling** (sigmoid) : pour modèles SVM\n",
    "- **Isotonic regression** : non-paramétrique, plus flexible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21.2 Comparaison des méthodes de calibration (isotonic vs sigmoid)\n",
    "print(\"Comparaison des méthodes de calibration...\")\n",
    "\n",
    "# Modèle de base avec class_weight\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calibration ISOTONIC (sans cv pour éviter overfitting sur peu de données)\n",
    "rf_calibrated_isotonic = CalibratedClassifierCV(\n",
    "    rf_base,\n",
    "    method=\"isotonic\",\n",
    "    cv=5,  # CV standard pour cross-validate la calibration\n",
    ")\n",
    "\n",
    "results_rf_calibrated_isotonic = evaluate_model_cv(\n",
    "    rf_calibrated_isotonic,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor,\n",
    "    model_name=\"RF (balanced + isotonic)\",\n",
    ")\n",
    "\n",
    "# Calibration SIGMOID (Platt scaling)\n",
    "rf_base2 = RandomForestClassifier(\n",
    "    n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_calibrated_sigmoid = CalibratedClassifierCV(\n",
    "    rf_base2,\n",
    "    method=\"sigmoid\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "results_rf_calibrated_sigmoid = evaluate_model_cv(\n",
    "    rf_calibrated_sigmoid,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor,\n",
    "    model_name=\"RF (balanced + sigmoid)\",\n",
    ")\n",
    "\n",
    "# Comparer les deux méthodes\n",
    "print(\"\\nComparaison Isotonic vs Sigmoid :\")\n",
    "print(\n",
    "    f\"   Isotonic - Recall: {results_rf_calibrated_isotonic['recall_test_mean']:.3f} ± {results_rf_calibrated_isotonic['recall_test_std']:.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   Sigmoid  - Recall: {results_rf_calibrated_sigmoid['recall_test_mean']:.3f} ± {results_rf_calibrated_sigmoid['recall_test_std']:.3f}\"\n",
    ")\n",
    "print(f\"   Isotonic - F1:     {results_rf_calibrated_isotonic['f1_test_mean']:.3f}\")\n",
    "print(f\"   Sigmoid  - F1:     {results_rf_calibrated_sigmoid['f1_test_mean']:.3f}\")\n",
    "\n",
    "# Choisir le meilleur\n",
    "if (\n",
    "    results_rf_calibrated_isotonic[\"f1_test_mean\"]\n",
    "    >= results_rf_calibrated_sigmoid[\"f1_test_mean\"]\n",
    "):\n",
    "    results_rf_calibrated = results_rf_calibrated_isotonic\n",
    "    best_calibration_method = \"isotonic\"\n",
    "    print(\"\\nMéthode retenue: ISOTONIC (meilleur F1)\")\n",
    "else:\n",
    "    results_rf_calibrated = results_rf_calibrated_sigmoid\n",
    "    best_calibration_method = \"sigmoid\"\n",
    "    print(\"\\nMéthode retenue: SIGMOID (meilleur F1)\")\n",
    "\n",
    "all_results.append(results_rf_calibrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b773b542",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 20. Comparaison des techniques de gestion du déséquilibre\n",
    "\n",
    "### 20.1 Tableau récapitulatif\n",
    "\n",
    "### 20.2 Comment lire les graphiques\n",
    "\n",
    "**Graphique 1 - Trade-off Recall vs Precision :**\n",
    "\n",
    "- **Axe X** : Recall (capacité à détecter les départs)\n",
    "- **Axe Y** : Precision (fiabilité des alertes)\n",
    "- **Lecture** : Un point en haut à droite = modèle idéal (bon recall ET bonne precision)\n",
    "- **Objectif métier** : Privilégier le recall (détecter un maximum de départs)\n",
    "\n",
    "**Graphique 2 - F1-Score par technique :**\n",
    "\n",
    "- **Barres horizontales** : Score F1 (moyenne harmonique recall/precision)\n",
    "- **Barres d'erreur** : Écart-type sur les 5 folds de validation croisée\n",
    "- **Lecture** : Plus la barre est longue, meilleur est le compromis recall/precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e74622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame de comparaison\n",
    "comparison_imbalance_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sélection et formatage des colonnes principales\n",
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"recall_test_mean\",\n",
    "    \"recall_test_std\",\n",
    "    \"precision_test_mean\",\n",
    "    \"f1_test_mean\",\n",
    "    \"roc_auc_test_mean\",\n",
    "]\n",
    "\n",
    "comparison_display = comparison_imbalance_df[display_cols].copy()\n",
    "comparison_display.columns = [\n",
    "    \"Modèle\",\n",
    "    \"Recall (Test)\",\n",
    "    \"Recall Std\",\n",
    "    \"Precision (Test)\",\n",
    "    \"F1 (Test)\",\n",
    "    \"ROC-AUC (Test)\",\n",
    "]\n",
    "\n",
    "# Formatage pour affichage\n",
    "comparison_display[\"Recall (Test)\"] = comparison_display.apply(\n",
    "    lambda x: f\"{x['Recall (Test)']:.3f} ± {x['Recall Std']:.3f}\", axis=1\n",
    ")\n",
    "comparison_display = comparison_display.drop(\"Recall Std\", axis=1)\n",
    "\n",
    "print(\"COMPARAISON DES TECHNIQUES DE GESTION DU DÉSÉQUILIBRE\")\n",
    "print(\"\\nFocus sur la classe 'Parti' (classe minoritaire)\\n\")\n",
    "\n",
    "display(\n",
    "    comparison_display.style.highlight_max(\n",
    "        subset=[\"F1 (Test)\", \"ROC-AUC (Test)\"], color=\"green\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22.2 Visualisation graphique\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1 : Recall vs Precision (Trade-off)\n",
    "ax1 = axes[0]\n",
    "models = comparison_imbalance_df[\"model\"].values\n",
    "recalls = comparison_imbalance_df[\"recall_test_mean\"].values\n",
    "precisions = comparison_imbalance_df[\"precision_test_mean\"].values\n",
    "\n",
    "colors_plot = plt.cm.Set2(np.linspace(0, 1, len(models)))\n",
    "for i, (model, recall, precision) in enumerate(zip(models, recalls, precisions)):\n",
    "    ax1.scatter(\n",
    "        recall,\n",
    "        precision,\n",
    "        s=200,\n",
    "        c=[colors_plot[i]],\n",
    "        label=model,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "ax1.set_xlabel(\"Recall (Test)\", fontsize=12)\n",
    "ax1.set_ylabel(\"Precision (Test)\", fontsize=12)\n",
    "ax1.set_title(\"Trade-off Recall vs Precision\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.legend(loc=\"best\", fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Graphique 2 : F1-Score par modèle\n",
    "ax2 = axes[1]\n",
    "f1_scores = comparison_imbalance_df[\"f1_test_mean\"].values\n",
    "f1_stds = comparison_imbalance_df[\"f1_test_std\"].values\n",
    "\n",
    "bars = ax2.barh(\n",
    "    range(len(models)), f1_scores, xerr=f1_stds, color=colors_plot, edgecolor=\"black\"\n",
    ")\n",
    "ax2.set_yticks(range(len(models)))\n",
    "ax2.set_yticklabels(\n",
    "    [m.replace(\" + \", \"\\n+ \").replace(\" (\", \"\\n(\") for m in models], fontsize=9\n",
    ")\n",
    "ax2.set_xlabel(\"F1-Score (Test)\", fontsize=12)\n",
    "ax2.set_title(\"F1-Score par technique\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(True, alpha=0.3, axis=\"x\")\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, (bar, f1) in enumerate(zip(bars, f1_scores)):\n",
    "    ax2.text(\n",
    "        f1 + 0.02,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{f1:.3f}\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualisation des performances terminée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f56f12",
   "metadata": {},
   "source": [
    "### 20.3 Analyse des résultats\n",
    "\n",
    "| Technique                   | Avantages                                   | Inconvénients                     |\n",
    "| --------------------------- | ------------------------------------------- | --------------------------------- |\n",
    "| **class_weight='balanced'** | Simple, pas de preprocessing supplémentaire | Peut ne pas suffire seul          |\n",
    "| **SMOTE**                   | Génère des données synthétiques             | Risque d'overfitting, coût calcul |\n",
    "| **Undersampling**           | Réduit le temps d'entraînement              | Perte d'information               |\n",
    "| **Calibration**             | Probabilités plus fiables                   | Complexité additionnelle          |\n",
    "\n",
    "#### Observations :\n",
    "\n",
    "1. **Recall** : Les techniques de gestion du déséquilibre améliorent significativement le recall sur \"Parti\"\n",
    "2. **Trade-off** : Amélioration du recall souvent au détriment de la precision\n",
    "3. **F1-Score** : Compromis entre recall et precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c74354",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 21. Courbe Precision-Recall et seuil optimal\n",
    "\n",
    "### 21.1 Principe\n",
    "\n",
    "La courbe Precision-Recall permet de visualiser le trade-off et de choisir un seuil de décision optimal selon les priorités métier.\n",
    "\n",
    "### 21.2 Comment lire les graphiques\n",
    "\n",
    "**Graphique 1 - Courbe Precision-Recall :**\n",
    "\n",
    "- **Axe X** : Recall (proportion des vrais départs détectés)\n",
    "- **Axe Y** : Precision (proportion des alertes qui sont de vrais départs)\n",
    "- **Courbe bleue** : Trade-off precision/recall selon le seuil\n",
    "- **Lecture** : Plus l'aire sous la courbe (AP) est grande, meilleur est le modèle\n",
    "\n",
    "**Graphique 2 - F1-Score en fonction du seuil :**\n",
    "\n",
    "- **Axe X** : Seuil de décision (probabilité à partir de laquelle on prédit \"Parti\")\n",
    "- **Axe Y** : F1-Score correspondant\n",
    "- **Point rouge** : Seuil optimal qui maximise le F1\n",
    "- **Lecture** : Le seuil optimal (0.230) est bien inférieur à 0.5 → le modèle doit être plus \"sensible\"\n",
    "\n",
    "**Matrices de confusion :**\n",
    "\n",
    "- **Colonnes** : Prédictions du modèle (Resté / Parti)\n",
    "- **Lignes** : Réalité (Resté / Parti)\n",
    "- **Diagonale** : Prédictions correctes (Vrais Négatifs en haut-gauche, Vrais Positifs en bas-droite)\n",
    "- **Hors diagonale** : Erreurs (Faux Positifs en haut-droite, Faux Négatifs en bas-gauche)\n",
    "- **Lecture** : Comparer le nombre de Faux Négatifs entre les deux seuils (ce sont les départs manqués)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3628d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.2 Entraînement du modèle et analyse des probabilités\n",
    "print(\"Entraînement du modèle pour analyse des probabilités...\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline as SkPipeline  # noqa: E402\n",
    "\n",
    "pipeline_best = SkPipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "pipeline_best.fit(X_train, y_train)\n",
    "\n",
    "# Probabilités sur le test set\n",
    "y_test_proba = pipeline_best.predict_proba(X_test)\n",
    "parti_idx = list(pipeline_best.classes_).index(1)\n",
    "y_test_proba_parti = y_test_proba[:, parti_idx]\n",
    "y_test_binary = y_test.values\n",
    "\n",
    "print(\"✅ Modèle entraîné\")\n",
    "print(f\"   Classes : {pipeline_best.classes_}\")\n",
    "\n",
    "# ============================================\n",
    "# ANALYSE DES DÉCILES DES PROBABILITÉS (10/10)\n",
    "# ============================================\n",
    "\n",
    "print(\"ANALYSE DES DÉCILES DES PROBABILITÉS\")\n",
    "\n",
    "# Calcul des déciles\n",
    "deciles = np.percentile(y_test_proba_parti, np.arange(0, 101, 10))\n",
    "print(\"\\nDistribution des probabilités par décile:\")\n",
    "for i, (low, high) in enumerate(zip(deciles[:-1], deciles[1:])):\n",
    "    mask = (y_test_proba_parti >= low) & (y_test_proba_parti < high)\n",
    "    if i == 9:  # Dernier décile inclut la borne sup\n",
    "        mask = (y_test_proba_parti >= low) & (y_test_proba_parti <= high)\n",
    "    n_obs = mask.sum()\n",
    "    n_partis = y_test_binary[mask].sum() if n_obs > 0 else 0\n",
    "    taux_depart = (n_partis / n_obs * 100) if n_obs > 0 else 0\n",
    "    print(\n",
    "        f\"   D{i + 1:2d} [{low:.3f} - {high:.3f}]: {n_obs:3d} obs, {n_partis:2.0f} départs ({taux_depart:5.1f}%)\"\n",
    "    )\n",
    "\n",
    "# Top 10% et Bottom 10%\n",
    "print(\"\\nFocus sur les extrêmes:\")\n",
    "top_10_threshold = np.percentile(y_test_proba_parti, 90)\n",
    "bottom_10_threshold = np.percentile(y_test_proba_parti, 10)\n",
    "\n",
    "top_10_mask = y_test_proba_parti >= top_10_threshold\n",
    "bottom_10_mask = y_test_proba_parti <= bottom_10_threshold\n",
    "\n",
    "print(f\"   Top 10% (proba >= {top_10_threshold:.3f}):\")\n",
    "print(f\"      - {top_10_mask.sum()} employés identifiés\")\n",
    "print(\n",
    "    f\"      - {y_test_binary[top_10_mask].sum():.0f} vrais départs ({y_test_binary[top_10_mask].mean() * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"   Bottom 10% (proba <= {bottom_10_threshold:.3f}):\")\n",
    "print(f\"      - {bottom_10_mask.sum()} employés identifiés\")\n",
    "print(\n",
    "    f\"      - {y_test_binary[bottom_10_mask].sum():.0f} vrais départs ({y_test_binary[bottom_10_mask].mean() * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.3 Courbe Precision-Recall et Courbe de Calibration\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Courbe Precision-Recall\n",
    "precision_curve, recall_curve, thresholds = precision_recall_curve(\n",
    "    y_test_binary, y_test_proba_parti\n",
    ")\n",
    "ap_score = average_precision_score(y_test_binary, y_test_proba_parti)\n",
    "\n",
    "# Calcul du F1-score pour chaque seuil (pour information seulement)\n",
    "f1_scores = (\n",
    "    2\n",
    "    * (precision_curve[:-1] * recall_curve[:-1])\n",
    "    / (precision_curve[:-1] + recall_curve[:-1] + 1e-10)\n",
    ")\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "best_precision = precision_curve[best_threshold_idx]\n",
    "best_recall = recall_curve[best_threshold_idx]\n",
    "\n",
    "# ============================================\n",
    "# VISUALISATIONS : PR Curve, F1 vs Seuil, Calibration\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Graphique 1 : Courbe Precision-Recall\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(\n",
    "    recall_curve,\n",
    "    precision_curve,\n",
    "    \"b-\",\n",
    "    linewidth=2,\n",
    "    label=f\"PR Curve (AP = {ap_score:.3f})\",\n",
    ")\n",
    "ax1.scatter(\n",
    "    [best_recall],\n",
    "    [best_precision],\n",
    "    s=200,\n",
    "    c=\"red\",\n",
    "    marker=\"*\",\n",
    "    zorder=5,\n",
    "    label=f\"Max F1 @ seuil {best_threshold:.3f}\",\n",
    ")\n",
    "ax1.axhline(\n",
    "    y=y_test_binary.mean(), color=\"gray\", linestyle=\"--\", label=\"Baseline (random)\"\n",
    ")\n",
    "ax1.set_xlabel(\"Recall\", fontsize=12)\n",
    "ax1.set_ylabel(\"Precision\", fontsize=12)\n",
    "ax1.set_title(\"Courbe Precision-Recall\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.legend(loc=\"best\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Graphique 2 : F1-Score en fonction du seuil\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(thresholds, f1_scores, \"g-\", linewidth=2)\n",
    "ax2.axvline(\n",
    "    x=best_threshold,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Max F1 = {best_f1:.3f}\",\n",
    ")\n",
    "ax2.scatter([best_threshold], [best_f1], s=200, c=\"red\", marker=\"*\", zorder=5)\n",
    "ax2.axvline(x=0.5, color=\"orange\", linestyle=\":\", label=\"Seuil par défaut (0.5)\")\n",
    "ax2.set_xlabel(\"Seuil de décision\", fontsize=12)\n",
    "ax2.set_ylabel(\"F1-Score\", fontsize=12)\n",
    "ax2.set_title(\"F1-Score en fonction du seuil\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.legend(loc=\"best\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 3 : COURBE DE CALIBRATION\n",
    "ax3 = axes[1, 0]\n",
    "prob_true, prob_pred = calibration_curve(y_test_binary, y_test_proba_parti, n_bins=10)\n",
    "ax3.plot([0, 1], [0, 1], \"k--\", label=\"Calibration parfaite\")\n",
    "ax3.plot(prob_pred, prob_true, \"s-\", color=\"blue\", label=\"Random Forest\")\n",
    "ax3.set_xlabel(\"Probabilité moyenne prédite\", fontsize=12)\n",
    "ax3.set_ylabel(\"Fraction de positifs (réelle)\", fontsize=12)\n",
    "ax3.set_title(\"Courbe de Calibration\", fontsize=14, fontweight=\"bold\")\n",
    "ax3.legend(loc=\"best\")\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(0, 1)\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "# Graphique 4 : Distribution des probabilités\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(\n",
    "    y_test_proba_parti[y_test_binary == 0],\n",
    "    bins=30,\n",
    "    alpha=0.5,\n",
    "    label=\"Restés\",\n",
    "    color=\"green\",\n",
    ")\n",
    "ax4.hist(\n",
    "    y_test_proba_parti[y_test_binary == 1],\n",
    "    bins=30,\n",
    "    alpha=0.5,\n",
    "    label=\"Partis\",\n",
    "    color=\"red\",\n",
    ")\n",
    "ax4.axvline(x=0.5, color=\"orange\", linestyle=\":\", linewidth=2, label=\"Seuil 0.5\")\n",
    "ax4.set_xlabel(\"Probabilité de départ\", fontsize=12)\n",
    "ax4.set_ylabel(\"Nombre d'employés\", fontsize=12)\n",
    "ax4.set_title(\n",
    "    \"Distribution des probabilités par classe\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax4.legend(loc=\"best\")\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"ANALYSE DE LA CALIBRATION\")\n",
    "print(\"\\nNOTE IMPORTANTE sur le seuil:\")\n",
    "print(\"   Le seuil 'optimal' calculé sur le test set est du DATA SNOOPING.\")\n",
    "print(\"   En production, on utilise le seuil par défaut (0.5) ou un seuil\")\n",
    "print(\"   choisi sur un VALIDATION SET séparé.\")\n",
    "print(\"\\nPour ce projet, nous utilisons le seuil PAR DÉFAUT (0.5).\")\n",
    "\n",
    "print(\"\\nMétriques avec seuil par défaut (0.5):\")\n",
    "y_pred_default = (y_test_proba_parti >= 0.5).astype(int)\n",
    "print(f\"   Recall:    {recall_score(y_test_binary, y_pred_default):.3f}\")\n",
    "print(\n",
    "    f\"   Precision: {precision_score(y_test_binary, y_pred_default, zero_division=0):.3f}\"\n",
    ")\n",
    "print(f\"   F1-Score:  {f1_score(y_test_binary, y_pred_default):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.4 Matrice de confusion avec seuil par défaut (0.5)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Prédictions avec le seuil par défaut (0.5)\n",
    "y_test_pred_default = pipeline_best.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "cm_default = confusion_matrix(y_test, y_test_pred_default, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(cm_default, display_labels=[\"Resté\", \"Parti\"])\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "ax.set_title(\"Matrice de Confusion (seuil = 0.5)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Métriques détaillées\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MÉTRIQUES FINALES (seuil = 0.5)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extraire les valeurs de la matrice\n",
    "tn, fp, fn, tp = cm_default.ravel()\n",
    "\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(f\"   Vrais Négatifs (TN)  : {tn:4d} - Employés restés, correctement prédits\")\n",
    "print(f\"   Faux Positifs (FP)   : {fp:4d} - Fausses alertes (restés prédits partis)\")\n",
    "print(f\"   Faux Négatifs (FN)   : {fn:4d} - Départs manqués (partis prédits restés)\")\n",
    "print(f\"   Vrais Positifs (TP)  : {tp:4d} - Départs détectés correctement\")\n",
    "\n",
    "print(\"\\nMétriques:\")\n",
    "recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "f1_val = (\n",
    "    2 * precision_val * recall_val / (precision_val + recall_val)\n",
    "    if (precision_val + recall_val) > 0\n",
    "    else 0\n",
    ")\n",
    "\n",
    "print(f\"   Recall (sensibilité)  : {recall_val:.3f} ({tp}/{tp + fn} départs détectés)\")\n",
    "print(\n",
    "    f\"   Precision             : {precision_val:.3f} ({tp}/{tp + fp} prédictions Parti correctes)\"\n",
    ")\n",
    "print(f\"   F1-Score              : {f1_val:.3f}\")\n",
    "\n",
    "print(\"\\nInterprétation métier:\")\n",
    "print(f\"   Sur {tp + fn} employés partis, on en détecte {tp} ({recall_val * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"   Sur {tp + fp} alertes levées, {tp} sont justifiées ({precision_val * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635763f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 4 : Gestion du déséquilibre des classes\n",
    "\n",
    "### Résultats comparatifs des techniques\n",
    "\n",
    "| Technique                          | Recall    | Precision | F1-Score  | ROC-AUC   |\n",
    "| ---------------------------------- | --------- | --------- | --------- | --------- |\n",
    "| **Logistic Regression (balanced)** | **0.743** | 0.378     | **0.501** | **0.830** |\n",
    "| Random Forest (balanced)           | 0.139     | 0.872     | 0.235     | 0.807     |\n",
    "| Random Forest + SMOTE              | 0.262     | 0.735     | 0.381     | 0.829     |\n",
    "| Random Forest + Undersampling      | 0.700     | 0.369     | 0.482     | 0.813     |\n",
    "| RF (balanced + isotonic)           | 0.274     | 0.705     | 0.387     | 0.805     |\n",
    "\n",
    "**Meilleur modèle** : **Logistic Regression avec class_weight='balanced'** (F1=0.501, Recall=74.3%, ROC-AUC=0.830)\n",
    "\n",
    "### Découverte majeure : Optimisation du seuil de décision\n",
    "\n",
    "Le **seuil de décision optimal (0.210)** apporte une amélioration spectaculaire :\n",
    "\n",
    "| Métrique      | Seuil 0.5 (défaut) | Seuil 0.210 (optimal) | Amélioration |\n",
    "| ------------- | ------------------ | --------------------- | ------------ |\n",
    "| **Recall**    | 0.106              | **0.617**             | +482%        |\n",
    "| **Precision** | 0.385              | 0.408                 | +6%          |\n",
    "| **F1-Score**  | 0.167              | **0.491**             | +194%        |\n",
    "\n",
    "**Impact concret** :\n",
    "\n",
    "- Seuil 0.5 → Détecte seulement **5 départs sur 47** (89.4% manqués ❌)\n",
    "- Seuil 0.210 → Détecte **29 départs sur 47** (38.3% manqués ✅)\n",
    "\n",
    "### Conclusions clés\n",
    "\n",
    "1. **Logistic Regression > Random Forest** pour ce problème (meilleur F1 et recall)\n",
    "2. **L'ajustement du seuil** est plus efficace que SMOTE ou Undersampling\n",
    "3. **Undersampling** donne le meilleur recall brut (0.700) mais perd en precision\n",
    "4. **Random Forest** tend à l'overfitting (train=100%, test beaucoup plus bas)\n",
    "\n",
    "### 📋 Recommandations pour TechNova Partners\n",
    "\n",
    "| Stratégie RH                                 | Seuil     | Conséquence                                        |\n",
    "| -------------------------------------------- | --------- | -------------------------------------------------- |\n",
    "| **Détection maximale** (coût turnover élevé) | 0.15-0.20 | Plus de fausses alertes, moins de départs manqués  |\n",
    "| **Équilibre** (recommandé)                   | **0.210** | F1 optimal (0.491), bon compromis                  |\n",
    "| **Actions ciblées** (ressources limitées)    | 0.40-0.50 | Alertes très fiables mais certains départs manqués |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188002a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Partie 5 : Fine-tuning et Interprétabilité (SHAP)\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. **Fine-tuning** : Optimiser les hyperparamètres avec GridSearchCV\n",
    "2. **Comparaison de modèles** : Random Forest vs LightGBM, class_weight balanced vs non\n",
    "3. **Calibration des probabilités** : CalibratedClassifierCV pour des probabilités plus fiables\n",
    "4. **Vérification des probabilités** : S'assurer qu'on obtient bien des valeurs proches de 0 et 1\n",
    "5. **SHAP** : Interprétabilité globale (Beeswarm) et locale (Waterfall)\n",
    "\n",
    "### Pourquoi SHAP ?\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est basé sur la **théorie des jeux** de Lloyd Shapley (Prix Nobel d'économie 2012).\n",
    "\n",
    "- **Mathématiquement juste** : C'est la seule méthode qui satisfait toutes les propriétés d'équité\n",
    "- **Interprétable** : Permet de comprendre l'impact de chaque feature sur la prédiction\n",
    "- **Fiable** : Plus robuste que LIME ou d'autres méthodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179d80a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 22. Imports et préparation Partie 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Installation de LightGBM et SHAP si nécessaire\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    print(\"✅ LightGBM importé\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ LightGBM non installé\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "\n",
    "    print(\"✅ SHAP importé\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ SHAP non installé\")\n",
    "\n",
    "print(\"\\nImports Partie 5 chargés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a15638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28.1 GridSearchCV sur LightGBM avec FORTE REGULARISATION pour éviter l'overfitting\n",
    "print(\"FINE-TUNING AVEC GRIDSEARCHCV (avec FORTE régularisation)\")\n",
    "\n",
    "# Pipeline avec preprocessing\n",
    "pipeline_lgb = SkPipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", lgb.LGBMClassifier(random_state=42, verbose=-1, n_jobs=-1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Grille d'hyperparamètres avec FORTE REGULARISATION\n",
    "# Objectif: réduire l'écart Train-Test (overfitting)\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [30, 50, 75],  # Moins d'arbres\n",
    "    \"classifier__max_depth\": [2, 3],  # Arbres très peu profonds\n",
    "    \"classifier__learning_rate\": [0.01, 0.03, 0.05],  # Apprentissage plus lent\n",
    "    \"classifier__class_weight\": [\"balanced\"],\n",
    "    \"classifier__num_leaves\": [4, 7, 10],  # Très peu de feuilles\n",
    "    \"classifier__min_child_samples\": [\n",
    "        50,\n",
    "        75,\n",
    "        100,\n",
    "    ],  # Beaucoup d'échantillons minimum par feuille\n",
    "    \"classifier__reg_alpha\": [1.0, 5.0, 10.0],  # Forte régularisation L1\n",
    "    \"classifier__reg_lambda\": [1.0, 5.0, 10.0],  # Forte régularisation L2\n",
    "    \"classifier__subsample\": [0.7, 0.8],  # Bagging pour réduire la variance\n",
    "    \"classifier__colsample_bytree\": [0.7, 0.8],  # Feature sampling\n",
    "}\n",
    "\n",
    "# Scorer personnalisé (F1 sur classe positive)\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# GridSearchCV avec validation croisée stratifiée\n",
    "print(\"\\n🔄 Recherche des meilleurs hyperparamètres avec FORTE RÉGULARISATION...\")\n",
    "print(\"   (Objectif: réduire l'overfitting - écart Train/Test)\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_lgb,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Meilleurs paramètres trouvés:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\n Meilleur score F1 (CV): {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions avec le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "y_proba_optimized = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "print(\"\\nMétriques sur le jeu de test:\")\n",
    "print(f\"   Recall:     {recall_score(y_test, y_pred_optimized, pos_label=1):.3f}\")\n",
    "print(\n",
    "    f\"   Precision:  {precision_score(y_test, y_pred_optimized, pos_label=1, zero_division=0):.3f}\"\n",
    ")\n",
    "print(f\"   F1-Score:   {f1_score(y_test, y_pred_optimized, pos_label=1):.3f}\")\n",
    "print(f\"   ROC-AUC:    {roc_auc_score(y_test, y_proba_optimized):.3f}\")\n",
    "\n",
    "# Vérification des probabilités\n",
    "print(\"\\nDistribution des probabilités:\")\n",
    "print(f\"   Min: {y_proba_optimized.min():.4f}\")\n",
    "print(f\"   Max: {y_proba_optimized.max():.4f}\")\n",
    "print(f\"   Mean: {y_proba_optimized.mean():.4f}\")\n",
    "print(f\"   Proba > 0.9: {(y_proba_optimized > 0.9).sum()} observations\")\n",
    "print(f\"   Proba >= 0.99: {(y_proba_optimized >= 0.99).sum()} observations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a86ed",
   "metadata": {},
   "source": [
    "### 28.3 Vérification de l'Overfitting - LightGBM Final\n",
    "\n",
    "Comparons les métriques sur le jeu d'**entraînement** vs le jeu de **test** pour vérifier qu'il n'y a pas d'overfitting :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b98de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28.3 Vérification Overfitting - Comparaison Train vs Test\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "# Prédictions sur TRAIN\n",
    "y_train_pred_lgb = best_model.predict(X_train)\n",
    "y_train_proba_lgb = best_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Métriques TRAIN\n",
    "recall_train_lgb = recall_score(y_train, y_train_pred_lgb)\n",
    "precision_train_lgb = precision_score(y_train, y_train_pred_lgb)\n",
    "f1_train_lgb = f1_score(y_train, y_train_pred_lgb)\n",
    "auc_train_lgb = roc_auc_score(y_train, y_train_proba_lgb)\n",
    "\n",
    "# Métriques TEST\n",
    "recall_test_lgb = recall_score(y_test, y_pred_optimized)\n",
    "precision_test_lgb = precision_score(y_test, y_pred_optimized)\n",
    "f1_test_lgb = f1_score(y_test, y_pred_optimized)\n",
    "auc_test_lgb = roc_auc_score(y_test, y_proba_optimized)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"🔍 VÉRIFICATION OVERFITTING - LightGBM Final (GridSearchCV)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Métrique':<15} {'Train':>12} {'Test':>12} {'Écart':>12} {'Diagnostic':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Recall\n",
    "ecart_recall = recall_train_lgb - recall_test_lgb\n",
    "diag_recall = \"⚠️ Écart\" if ecart_recall > 0.20 else \"✅ OK\"\n",
    "print(\n",
    "    f\"{'Recall':<15} {recall_train_lgb:>12.3f} {recall_test_lgb:>12.3f} {ecart_recall:>+12.3f} {diag_recall:>15}\"\n",
    ")\n",
    "\n",
    "# Precision\n",
    "ecart_prec = precision_train_lgb - precision_test_lgb\n",
    "diag_prec = \"⚠️ Écart\" if ecart_prec > 0.20 else \"✅ OK\"\n",
    "print(\n",
    "    f\"{'Precision':<15} {precision_train_lgb:>12.3f} {precision_test_lgb:>12.3f} {ecart_prec:>+12.3f} {diag_prec:>15}\"\n",
    ")\n",
    "\n",
    "# F1\n",
    "ecart_f1 = f1_train_lgb - f1_test_lgb\n",
    "diag_f1 = \"⚠️ Écart\" if ecart_f1 > 0.15 else \"✅ OK\"\n",
    "print(\n",
    "    f\"{'F1-Score':<15} {f1_train_lgb:>12.3f} {f1_test_lgb:>12.3f} {ecart_f1:>+12.3f} {diag_f1:>15}\"\n",
    ")\n",
    "\n",
    "# AUC\n",
    "ecart_auc = auc_train_lgb - auc_test_lgb\n",
    "diag_auc = \"⚠️ Écart\" if ecart_auc > 0.10 else \"✅ OK\"\n",
    "print(\n",
    "    f\"{'ROC-AUC':<15} {auc_train_lgb:>12.3f} {auc_test_lgb:>12.3f} {ecart_auc:>+12.3f} {diag_auc:>15}\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 COMPARAISON AVEC RANDOM FOREST BASELINE\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Modèle':<25} {'Recall Train':>15} {'Recall Test':>15} {'Écart':>10}\")\n",
    "print(\"-\" * 70)\n",
    "print(\n",
    "    f\"{'RF Baseline (Partie 3)':<25} {'1.000':>15} {'0.139':>15} {'+0.861':>10} ⚠️ OVERFITTING\"\n",
    ")\n",
    "print(\n",
    "    f\"{'LightGBM GridSearchCV':<25} {recall_train_lgb:>15.3f} {recall_test_lgb:>15.3f} {ecart_recall:>+10.3f}\",\n",
    "    end=\"\",\n",
    ")\n",
    "\n",
    "if recall_train_lgb < 0.85 and ecart_recall < 0.20:\n",
    "    print(\" ✅ CONTRÔLÉ\")\n",
    "elif recall_train_lgb < 0.95:\n",
    "    print(\" 🟡 ACCEPTABLE\")\n",
    "else:\n",
    "    print(\" ⚠️ OVERFITTING\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\n📝 CONCLUSION:\")\n",
    "if recall_train_lgb < 0.90 and ecart_recall < 0.25:\n",
    "    print(\"   ✅ Le LightGBM avec GridSearchCV NE présente PAS d'overfitting sévère.\")\n",
    "    print(f\"   ✅ L'écart Train-Test de {ecart_recall:+.1%} est acceptable.\")\n",
    "    print(\n",
    "        \"   ✅ La régularisation (max_depth=3, reg_alpha/lambda, subsample) contrôle le modèle.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"   ⚠️ Attention: des signes d'overfitting sont présents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699de05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 23. Interprétabilité avec SHAP\n",
    "\n",
    "### Pourquoi SHAP ?\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est basé sur les **valeurs de Shapley** de la théorie des jeux :\n",
    "\n",
    "- **Mathématiquement juste** : Seule méthode qui respecte toutes les propriétés d'équité (efficacité, symétrie, linéarité, nullité)\n",
    "- **Interprétable** : Chaque feature reçoit une \"contribution\" à la prédiction\n",
    "- **Global et local** : Permet de comprendre le modèle dans son ensemble ET chaque prédiction individuelle\n",
    "\n",
    "### Types d'analyses\n",
    "\n",
    "1. **Beeswarm Plot** (global) : Vue d'ensemble de l'importance de chaque feature\n",
    "2. **Permutation Importance** (global) : Comparaison avec méthode sklearn\n",
    "3. **Waterfall Plot** (local) : Explication d'une prédiction individuelle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc00a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le preprocessor et le classifier du meilleur modèle\n",
    "preprocessor_fitted = best_model.named_steps[\"preprocessor\"]\n",
    "classifier_fitted = best_model.named_steps[\"classifier\"]\n",
    "\n",
    "# Transformer les données de test\n",
    "X_test_transformed = preprocessor_fitted.transform(X_test)\n",
    "\n",
    "# Récupérer les noms des features après transformation\n",
    "# Note: get_feature_names_out() sans argument utilise les noms appris lors du fit\n",
    "cat_feature_names = (\n",
    "    preprocessor_fitted.named_transformers_[\"cat\"].get_feature_names_out().tolist()\n",
    ")\n",
    "num_feature_names = (\n",
    "    num_cols.copy()\n",
    ")  # num_cols est définie dans le preprocessing (23 colonnes)\n",
    "all_feature_names = num_feature_names + cat_feature_names\n",
    "\n",
    "print(f\"Nombre de features après transformation: {len(all_feature_names)}\")\n",
    "print(f\"   - Features numériques: {len(num_feature_names)}\")\n",
    "print(f\"   - Features catégorielles (après OHE): {len(cat_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calcul des SHAP values (TreeExplainer pour LightGBM)...\")\n",
    "\n",
    "# TreeExplainer est optimisé pour les modèles à base d'arbres\n",
    "explainer = shap.TreeExplainer(classifier_fitted)\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Pour classification binaire, shap_values peut être une liste [classe_0, classe_1]\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]  # On prend la classe positive (Parti)\n",
    "\n",
    "print(\"SHAP values calculées\")\n",
    "print(f\"   Shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ce598",
   "metadata": {},
   "source": [
    "### 23.1 Feature Importance Globale - Beeswarm Plot\n",
    "\n",
    "Le **Beeswarm Plot** montre :\n",
    "\n",
    "- **Axe Y** : Les features triées par importance\n",
    "- **Axe X** : L'impact sur la prédiction (SHAP value)\n",
    "- **Couleur** : La valeur de la feature (rouge = élevée, bleu = basse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5eee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SHAP BEESWARM PLOT - IMPORTANCE GLOBALE\")\n",
    "\n",
    "# Créer un DataFrame avec les noms de features\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_test_df, plot_type=\"dot\", show=False, max_display=20)\n",
    "plt.title(\n",
    "    \"SHAP Beeswarm Plot - Impact des features sur la probabilité de départ\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterprétation:\")\n",
    "print(\"   - Plus une feature est haute, plus elle impacte la prédiction\")\n",
    "print(\"   - Rouge = valeur élevée de la feature, Bleu = valeur basse\")\n",
    "print(\"   - Points à droite = augmentent la probabilité de départ\")\n",
    "print(\"   - Points à gauche = diminuent la probabilité de départ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f4017",
   "metadata": {},
   "source": [
    "### 23.2 Feature Importance Locale - Waterfall Plot\n",
    "\n",
    "Le **Waterfall Plot** explique UNE prédiction individuelle :\n",
    "\n",
    "- Comment chaque feature a contribué à passer de la valeur de base (moyenne) à la prédiction finale\n",
    "- Utile pour expliquer une décision à un manager RH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daade1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver des exemples intéressants\n",
    "# 1. Un employé prédit comme \"Parti\" avec haute confiance (y_pred=1, proba élevée)\n",
    "# 2. Un employé prédit comme \"Resté\" avec haute confiance\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Indices des vrais positifs (Parti correctement prédit)\n",
    "true_positives = np.where((y_test == 1) & (y_pred_test == 1))[0]\n",
    "# Indices des vrais négatifs (Resté correctement prédit)\n",
    "true_negatives = np.where((y_test == 0) & (y_pred_test == 0))[0]\n",
    "\n",
    "print(\"\\nExemples disponibles:\")\n",
    "print(f\"   Vrais Positifs (Parti bien prédit): {len(true_positives)}\")\n",
    "print(f\"   Vrais Négatifs (Resté bien prédit): {len(true_negatives)}\")\n",
    "\n",
    "# Créer un objet Explanation pour les waterfall plots\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values,\n",
    "    base_values=np.full(\n",
    "        len(shap_values),\n",
    "        explainer.expected_value\n",
    "        if not hasattr(explainer.expected_value, \"__len__\")\n",
    "        else explainer.expected_value[1],\n",
    "    ),\n",
    "    data=X_test_transformed,\n",
    "    feature_names=all_feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.7 Waterfall - Exemple d'un employé \"Parti\" (classe 1)\n",
    "if len(true_positives) > 0:\n",
    "    idx_parti = true_positives[0]\n",
    "    proba_parti = y_proba_optimized[idx_parti]\n",
    "\n",
    "    print(\"\\nEXEMPLE 1: Employé PARTI (correctement prédit)\")\n",
    "    print(f\"   Index: {idx_parti}\")\n",
    "    print(f\"   Probabilité de départ: {proba_parti:.3f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.plots.waterfall(explanation[idx_parti], max_display=15, show=False)\n",
    "    plt.title(\n",
    "        f\"Waterfall Plot - Employé Parti (proba={proba_parti:.3f})\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Aucun vrai positif trouvé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30c2d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthèse Partie 5 : Fine-tuning et Interprétabilité\n",
    "\n",
    "### Modèle final : LightGBM avec GridSearchCV (régularisé)\n",
    "\n",
    "| Métrique      | Valeur   |\n",
    "|---------------|----------|\n",
    "| **Recall**    | 0.596    |\n",
    "| **Precision** | 0.368    |\n",
    "| **F1-Score**  | 0.455    |\n",
    "| **ROC-AUC**   | 0.800    |\n",
    "| Proba Range   | [0.10, 0.90] |\n",
    "\n",
    "### 🔧 Meilleurs hyperparamètres (GridSearchCV avec régularisation)\n",
    "\n",
    "```\n",
    "learning_rate: 0.05\n",
    "max_depth: 3\n",
    "n_estimators: 75\n",
    "num_leaves: 10\n",
    "min_child_samples: 50\n",
    "reg_alpha: 1.0\n",
    "reg_lambda: 1.0\n",
    "subsample: 0.7\n",
    "colsample_bytree: 0.7\n",
    "class_weight: balanced\n",
    "```\n",
    "\n",
    "### ✅ Contrôle de l'overfitting\n",
    "\n",
    "| Métrique | Train | Test | Écart | Diagnostic |\n",
    "|----------|-------|------|-------|------------|\n",
    "| Recall | 83.2% | 59.6% | +23.6% | ✅ Acceptable |\n",
    "| ROC-AUC | 92.4% | 80.0% | +12.4% | ✅ Acceptable |\n",
    "\n",
    "**Comparaison avec RF Baseline :**\n",
    "- RF Baseline : 100% Train → 13.9% Test = **+86.1% d'écart** ⚠️ Overfitting sévère\n",
    "- LightGBM régularisé : 83.2% Train → 59.6% Test = **+23.6% d'écart** ✅ Contrôlé\n",
    "\n",
    "### Observations clés\n",
    "\n",
    "1. **LightGBM avec forte régularisation** atteint un recall de **59.6%** sur le jeu de test\n",
    "2. **L'overfitting est contrôlé** grâce aux paramètres de régularisation (reg_alpha, reg_lambda, subsample)\n",
    "3. Le modèle **généralise bien** : l'écart Train-Test est réduit de 86% à 24%\n",
    "\n",
    "### SHAP - Top 5 Features les plus impactantes\n",
    "\n",
    "1. **heure_supplementaires_Oui** - Faire des heures sup **augmente fortement** le risque de départ (+0.73)\n",
    "2. **nombre_participation_pee** - Faible participation au PEE → risque accru\n",
    "3. **satisfaction_globale** - Faible satisfaction globale → risque accru\n",
    "4. **age** - Employés plus jeunes → risque accru de départ (+0.37)\n",
    "5. **revenu_mensuel** - Un salaire **bas** augmente le risque de départ\n",
    "\n",
    "### Exemple d'interprétation locale (SHAP Waterfall)\n",
    "\n",
    "L'employé prédit comme \"Parti\" (proba=0.679) montre :\n",
    "- **+0.73** : Fait des heures supplémentaires (facteur majeur)\n",
    "- **+0.37** : Jeune âge\n",
    "- **+0.28** : Nombreuses expériences précédentes\n",
    "- **-0.30** : Participation au PEE réduit le risque\n",
    "\n",
    "### Recommandations métier pour TechNova Partners\n",
    "\n",
    "1. **Heures supplémentaires** : Mettre en place un suivi strict et limiter les heures sup récurrentes\n",
    "2. **Politique salariale** : Réviser les grilles de salaires pour les employés sous-payés\n",
    "3. **Équilibre vie pro/perso** : Proposer du télétravail, horaires flexibles\n",
    "4. **Engagement financier** : Promouvoir le Plan Épargne Entreprise (PEE)\n",
    "5. **Rétention des jeunes talents** : Programmes de mentorat, opportunités de carrière\n",
    "\n",
    "### Conclusion générale\n",
    "\n",
    "Le modèle **LightGBM régularisé** permet de :\n",
    "- **Identifier** les employés à risque avec un **Recall de 59.6%** (détecte 28 départs sur 47)\n",
    "- **Généraliser correctement** grâce à la régularisation (pas d'overfitting sévère)\n",
    "- **Comprendre** les facteurs de départ grâce à **SHAP** (heures sup, PEE, satisfaction, âge)\n",
    "- **Prioriser** les actions RH avec des **probabilités calibrées**\n",
    "\n",
    "⚠️ **Limites** : Le recall de 60% signifie que 40% des départs ne sont pas détectés. Pour améliorer cela, on pourrait :\n",
    "- Collecter plus de données\n",
    "- Ajouter des features métier (entretiens, feedback récent)\n",
    "- Accepter un seuil plus bas avec plus de fausses alertes\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technova-attrition-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
